{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from os import path\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers, losses, optimizers, metrics, callbacks, Model, Input, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=9048)]\n",
    "    )\n",
    "\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 10\n",
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.load(\"resnet_output.npy\")\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_index</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>9995.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>9996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>9997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>9998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>9999.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       real_index       name\n",
       "0               0      1.png\n",
       "1               1     10.png\n",
       "2               2    100.png\n",
       "3               3   1000.png\n",
       "4               4  10000.png\n",
       "...           ...        ...\n",
       "49995       49995   9995.png\n",
       "49996       49996   9996.png\n",
       "49997       49997   9997.png\n",
       "49998       49998   9998.png\n",
       "49999       49999   9999.png\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = list(os.walk(path.join(os.getcwd(), '..', 'cifar-10', 'train', 'train_images'), topdown=False))[0][2]\n",
    "filenames = pd.DataFrame(filenames, columns=[\"name\"]).reset_index(names=\"real_index\")\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>codes</th>\n",
       "      <th>real_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002.png</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003.png</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>9994.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>9996.png</td>\n",
       "      <td>3</td>\n",
       "      <td>49996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>9997.png</td>\n",
       "      <td>9</td>\n",
       "      <td>49997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>9998.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>9999.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  codes  real_index\n",
       "0          1.png      6           0\n",
       "1        100.png      1           2\n",
       "2      10001.png      1           5\n",
       "3      10002.png      6           6\n",
       "4      10003.png      6           7\n",
       "...          ...    ...         ...\n",
       "34995   9994.png      1       49994\n",
       "34996   9996.png      3       49996\n",
       "34997   9997.png      9       49997\n",
       "34998   9998.png      1       49998\n",
       "34999   9999.png      1       49999\n",
       "\n",
       "[35000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df = pd.read_csv(path.join(os.getcwd(), '..', 'train_val_test', 'train.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "train_labels_df = train_labels_df.merge(filenames, on=[\"name\"])\n",
    "train_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>codes</th>\n",
       "      <th>real_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.png</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.png</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10014.png</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10029.png</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9961.png</td>\n",
       "      <td>8</td>\n",
       "      <td>49958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>9977.png</td>\n",
       "      <td>3</td>\n",
       "      <td>49975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>998.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>9986.png</td>\n",
       "      <td>0</td>\n",
       "      <td>49985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>9995.png</td>\n",
       "      <td>6</td>\n",
       "      <td>49995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  codes  real_index\n",
       "0        10.png      3           1\n",
       "1      1000.png      5           3\n",
       "2     10000.png      5           4\n",
       "3     10014.png      6          19\n",
       "4     10029.png      7          35\n",
       "...         ...    ...         ...\n",
       "4995   9961.png      8       49958\n",
       "4996   9977.png      3       49975\n",
       "4997    998.png      1       49978\n",
       "4998   9986.png      0       49985\n",
       "4999   9995.png      6       49995\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels_df = pd.read_csv(path.join(os.getcwd(), '..', 'train_val_test', 'val.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "val_labels_df = val_labels_df.merge(filenames, on=[\"name\"])\n",
    "val_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>codes</th>\n",
       "      <th>real_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10008.png</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.png</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10012.png</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015.png</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10021.png</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9971.png</td>\n",
       "      <td>3</td>\n",
       "      <td>49969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9981.png</td>\n",
       "      <td>6</td>\n",
       "      <td>49980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9983.png</td>\n",
       "      <td>3</td>\n",
       "      <td>49982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9984.png</td>\n",
       "      <td>0</td>\n",
       "      <td>49983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>999.png</td>\n",
       "      <td>3</td>\n",
       "      <td>49989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  codes  real_index\n",
       "0     10008.png      6          12\n",
       "1      1001.png      9          14\n",
       "2     10012.png      3          17\n",
       "3     10015.png      5          20\n",
       "4     10021.png      0          27\n",
       "...         ...    ...         ...\n",
       "9995   9971.png      3       49969\n",
       "9996   9981.png      6       49980\n",
       "9997   9983.png      3       49982\n",
       "9998   9984.png      0       49983\n",
       "9999    999.png      3       49989\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_df = pd.read_csv(path.join(os.getcwd(), '..', 'train_val_test', 'test.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "test_labels_df = test_labels_df.merge(filenames, on=[\"name\"])\n",
    "test_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not train_labels_df.real_index.isin(test_labels_df).any()\n",
    "assert not train_labels_df.real_index.isin(val_labels_df).any()\n",
    "assert not test_labels_df.real_index.isin(val_labels_df).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 2048), (5000, 2048), (10000, 2048))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = dataset[train_labels_df.real_index, :], tf.one_hot(train_labels_df.codes, N_CLASS)\n",
    "val_x, val_y = dataset[val_labels_df.real_index, :], tf.one_hot(val_labels_df.codes, N_CLASS)\n",
    "test_x, test_y = dataset[test_labels_df.real_index, :], tf.one_hot(test_labels_df.codes, N_CLASS)\n",
    "train_x.shape, val_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "Training will be repeated 10 times with different weights initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2048)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              4196352   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2048)             8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,225,034\n",
      "Trainable params: 4,220,938\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(regularizer=None):\n",
    "    input_layer = Input(shape=(2048))\n",
    "    x = layers.Dense(2048, activation=\"relu\", kernel_regularizer=regularizer)(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    output = layers.Dense(N_CLASS, kernel_regularizer=regularizer, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "model = create_model(regularizer=regularizers.L1())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizers_ = [\n",
    "    regularizers.L1(),\n",
    "    regularizers.L2(),\n",
    "    regularizers.L1L2()\n",
    "]\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, min_lr=0.00001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.2801 - categorical_accuracy: 0.8928 - categorical_crossentropy: 0.3527\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6026 - categorical_accuracy: 0.9100 - categorical_crossentropy: 0.3059\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.5226 - categorical_accuracy: 0.8409 - categorical_crossentropy: 0.4777\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5832 - categorical_accuracy: 0.9113 - categorical_crossentropy: 0.2885\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5883 - categorical_accuracy: 0.9083 - categorical_crossentropy: 0.3042\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5923 - categorical_accuracy: 0.9109 - categorical_crossentropy: 0.2904\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5990 - categorical_accuracy: 0.9082 - categorical_crossentropy: 0.2962\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5721 - categorical_accuracy: 0.9084 - categorical_crossentropy: 0.2998\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3.2090 - categorical_accuracy: 0.8731 - categorical_crossentropy: 0.4106\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5937 - categorical_accuracy: 0.9110 - categorical_crossentropy: 0.2925\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4138 - categorical_accuracy: 0.8985 - categorical_crossentropy: 0.2940\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3601 - categorical_accuracy: 0.9100 - categorical_crossentropy: 0.2737\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3226 - categorical_accuracy: 0.9210 - categorical_crossentropy: 0.2538\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3363 - categorical_accuracy: 0.9136 - categorical_crossentropy: 0.2608\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3233 - categorical_accuracy: 0.9153 - categorical_crossentropy: 0.2612\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3394 - categorical_accuracy: 0.9152 - categorical_crossentropy: 0.2727\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3424 - categorical_accuracy: 0.9183 - categorical_crossentropy: 0.2569\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3184 - categorical_accuracy: 0.9209 - categorical_crossentropy: 0.2578\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3725 - categorical_accuracy: 0.9102 - categorical_crossentropy: 0.2691\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3276 - categorical_accuracy: 0.9198 - categorical_crossentropy: 0.2567\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3123 - categorical_accuracy: 0.9239 - categorical_crossentropy: 0.3123\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3290 - categorical_accuracy: 0.9278 - categorical_crossentropy: 0.3290\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3044 - categorical_accuracy: 0.9284 - categorical_crossentropy: 0.3044\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2977 - categorical_accuracy: 0.9263 - categorical_crossentropy: 0.2977\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3314 - categorical_accuracy: 0.9276 - categorical_crossentropy: 0.3314\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3193 - categorical_accuracy: 0.9265 - categorical_crossentropy: 0.3193\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3314 - categorical_accuracy: 0.9242 - categorical_crossentropy: 0.3314\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3111 - categorical_accuracy: 0.9253 - categorical_crossentropy: 0.3111\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3236 - categorical_accuracy: 0.9255 - categorical_crossentropy: 0.3236\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3033 - categorical_accuracy: 0.9261 - categorical_crossentropy: 0.3033\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(10))\n",
    "results = []\n",
    "for regularizer in regularizers_:\n",
    "    for seed in TRAINING_SEEDS:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(SEED)\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        model = create_model(regularizer=regularizer)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "            loss=losses.CategoricalCrossentropy(),\n",
    "            metrics=[metrics.CategoricalAccuracy(), metrics.CategoricalCrossentropy()]\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            x=train_x, y=train_y,\n",
    "            epochs=200,\n",
    "            batch_size=512,\n",
    "            validation_data=(val_x, val_y),\n",
    "            shuffle=True,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=0\n",
    "        )\n",
    "        eval_results = model.evaluate(x=test_x, batch_size=512, y=test_y)\n",
    "\n",
    "        results += [{\n",
    "            'seed': seed,\n",
    "            'regularizer': regularizer.__class__.__name__,\n",
    "            'results': dict(zip(model.metrics_names, eval_results))\n",
    "        }]\n",
    "        gc.collect()\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results = pd.concat([results.drop([\"results\"], axis=1), results[\"results\"].apply(pd.Series)], axis=1)\n",
    "results.to_csv('l1_l2_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>regularizer</th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>categorical_crossentropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>L1</td>\n",
       "      <td>1.280071</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.352705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.602628</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.305946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>L1</td>\n",
       "      <td>5.522645</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>0.477656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.583234</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.288536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.588320</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.304202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.592329</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.290358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.296166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.572063</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.299819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>L1</td>\n",
       "      <td>3.208997</td>\n",
       "      <td>0.8731</td>\n",
       "      <td>0.410642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.593729</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.292527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.413751</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.293960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.360143</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.273693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.322604</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.253822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.336289</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.260797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.323317</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.261212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.339405</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.272692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.256895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.318449</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.257754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.372459</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.269080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.327609</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.256735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.312314</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>0.312314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.329021</td>\n",
       "      <td>0.9278</td>\n",
       "      <td>0.329021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.304362</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>0.304362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.297683</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.297683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.331446</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.331446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.319277</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.319277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.331426</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.331426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.311145</td>\n",
       "      <td>0.9253</td>\n",
       "      <td>0.311145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.323573</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>0.323573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>L1L2</td>\n",
       "      <td>0.303297</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.303297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seed regularizer      loss  categorical_accuracy  categorical_crossentropy\n",
       "0      0          L1  1.280071                0.8928                  0.352705\n",
       "1      1          L1  0.602628                0.9100                  0.305946\n",
       "2      2          L1  5.522645                0.8409                  0.477656\n",
       "3      3          L1  0.583234                0.9113                  0.288536\n",
       "4      4          L1  0.588320                0.9083                  0.304202\n",
       "5      5          L1  0.592329                0.9109                  0.290358\n",
       "6      6          L1  0.598997                0.9082                  0.296166\n",
       "7      7          L1  0.572063                0.9084                  0.299819\n",
       "8      8          L1  3.208997                0.8731                  0.410642\n",
       "9      9          L1  0.593729                0.9110                  0.292527\n",
       "10     0          L2  0.413751                0.8985                  0.293960\n",
       "11     1          L2  0.360143                0.9100                  0.273693\n",
       "12     2          L2  0.322604                0.9210                  0.253822\n",
       "13     3          L2  0.336289                0.9136                  0.260797\n",
       "14     4          L2  0.323317                0.9153                  0.261212\n",
       "15     5          L2  0.339405                0.9152                  0.272692\n",
       "16     6          L2  0.342355                0.9183                  0.256895\n",
       "17     7          L2  0.318449                0.9209                  0.257754\n",
       "18     8          L2  0.372459                0.9102                  0.269080\n",
       "19     9          L2  0.327609                0.9198                  0.256735\n",
       "20     0        L1L2  0.312314                0.9239                  0.312314\n",
       "21     1        L1L2  0.329021                0.9278                  0.329021\n",
       "22     2        L1L2  0.304362                0.9284                  0.304362\n",
       "23     3        L1L2  0.297683                0.9263                  0.297683\n",
       "24     4        L1L2  0.331446                0.9276                  0.331446\n",
       "25     5        L1L2  0.319277                0.9265                  0.319277\n",
       "26     6        L1L2  0.331426                0.9242                  0.331426\n",
       "27     7        L1L2  0.311145                0.9253                  0.311145\n",
       "28     8        L1L2  0.323573                0.9255                  0.323573\n",
       "29     9        L1L2  0.303297                0.9261                  0.303297"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_74 (InputLayer)       [(None, 2048)]            0         \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 2048)              4196352   \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 2048)             8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,225,034\n",
      "Trainable params: 4,220,938\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(dropout_val=None):\n",
    "    input_layer = Input(shape=(2048))\n",
    "    x = layers.Dropout(dropout_val)(input_layer)\n",
    "    x = layers.Dense(2048, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout_val)(x)\n",
    "    output = layers.Dense(N_CLASS, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "model = create_model(0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_values = [0.1, 0.2, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3041 - categorical_accuracy: 0.9270 - categorical_crossentropy: 0.3041\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3013 - categorical_accuracy: 0.9251 - categorical_crossentropy: 0.3013\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3152 - categorical_accuracy: 0.9230 - categorical_crossentropy: 0.3152\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3003 - categorical_accuracy: 0.9290 - categorical_crossentropy: 0.3003\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3100 - categorical_accuracy: 0.9282 - categorical_crossentropy: 0.3100\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2726 - categorical_accuracy: 0.9254 - categorical_crossentropy: 0.2726\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2705 - categorical_accuracy: 0.9240 - categorical_crossentropy: 0.2705\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2998 - categorical_accuracy: 0.9299 - categorical_crossentropy: 0.2998\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3143 - categorical_accuracy: 0.9285 - categorical_crossentropy: 0.3143\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3122 - categorical_accuracy: 0.9261 - categorical_crossentropy: 0.3122\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3057 - categorical_accuracy: 0.9235 - categorical_crossentropy: 0.3057\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2650 - categorical_accuracy: 0.9288 - categorical_crossentropy: 0.2650\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2757 - categorical_accuracy: 0.9259 - categorical_crossentropy: 0.2757\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2778 - categorical_accuracy: 0.9272 - categorical_crossentropy: 0.2778\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2654 - categorical_accuracy: 0.9275 - categorical_crossentropy: 0.2654\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2559 - categorical_accuracy: 0.9249 - categorical_crossentropy: 0.2559\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2491 - categorical_accuracy: 0.9252 - categorical_crossentropy: 0.2491\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2637 - categorical_accuracy: 0.9257 - categorical_crossentropy: 0.2637\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2877 - categorical_accuracy: 0.9245 - categorical_crossentropy: 0.2877\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2546 - categorical_accuracy: 0.9224 - categorical_crossentropy: 0.2546\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2587 - categorical_accuracy: 0.9289 - categorical_crossentropy: 0.2587\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2485 - categorical_accuracy: 0.9274 - categorical_crossentropy: 0.2485\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2379 - categorical_accuracy: 0.9266 - categorical_crossentropy: 0.2379\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2395 - categorical_accuracy: 0.9280 - categorical_crossentropy: 0.2395\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2268 - categorical_accuracy: 0.9259 - categorical_crossentropy: 0.2268\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2672 - categorical_accuracy: 0.9256 - categorical_crossentropy: 0.2672\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2397 - categorical_accuracy: 0.9282 - categorical_crossentropy: 0.2397\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2512 - categorical_accuracy: 0.9279 - categorical_crossentropy: 0.2512\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2404 - categorical_accuracy: 0.9273 - categorical_crossentropy: 0.2404\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2619 - categorical_accuracy: 0.9272 - categorical_crossentropy: 0.2619\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2232 - categorical_accuracy: 0.9234 - categorical_crossentropy: 0.2232\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2152 - categorical_accuracy: 0.9283 - categorical_crossentropy: 0.2152\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2154 - categorical_accuracy: 0.9261 - categorical_crossentropy: 0.2154\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2215 - categorical_accuracy: 0.9260 - categorical_crossentropy: 0.2215\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2147 - categorical_accuracy: 0.9280 - categorical_crossentropy: 0.2147\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2178 - categorical_accuracy: 0.9264 - categorical_crossentropy: 0.2178\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2115 - categorical_accuracy: 0.9282 - categorical_crossentropy: 0.2115\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2228 - categorical_accuracy: 0.9236 - categorical_crossentropy: 0.2228\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2163 - categorical_accuracy: 0.9235 - categorical_crossentropy: 0.2163\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2258 - categorical_accuracy: 0.9232 - categorical_crossentropy: 0.2258\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(10))\n",
    "results = []\n",
    "\n",
    "for rate in dropout_values:\n",
    "    for seed in TRAINING_SEEDS:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(SEED)\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        model = create_model(rate)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "            loss=losses.CategoricalCrossentropy(),\n",
    "            metrics=[metrics.CategoricalAccuracy(), metrics.CategoricalCrossentropy()]\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            x=train_x, y=train_y,\n",
    "            epochs=200,\n",
    "            batch_size=512,\n",
    "            validation_data=(val_x, val_y),\n",
    "            shuffle=True,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        eval_results = model.evaluate(x=test_x, batch_size=512, y=test_y)\n",
    "\n",
    "        results += [{\n",
    "            'seed': seed,\n",
    "            'rate': rate,\n",
    "            'results': dict(zip(model.metrics_names, eval_results))\n",
    "        }]\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results = pd.concat([results.drop([\"results\"], axis=1), results[\"results\"].apply(pd.Series)], axis=1)\n",
    "results.to_csv('dropout_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>categorical_crossentropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.304116</td>\n",
       "      <td>0.9270</td>\n",
       "      <td>0.304116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.301261</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.301261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.315159</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.315159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.300282</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>0.300282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.310049</td>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.310049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.272612</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.272612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.270459</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.270459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.299823</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.299823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.314256</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.314256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.312211</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.312211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.305681</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.305681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.265040</td>\n",
       "      <td>0.9288</td>\n",
       "      <td>0.265040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.275683</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.275683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.277808</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.277808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.265351</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.265351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.255924</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.255924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.249104</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>0.249104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.263709</td>\n",
       "      <td>0.9257</td>\n",
       "      <td>0.263709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.287701</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.287701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.254598</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.254598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.258716</td>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.258716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.248473</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>0.248473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.237884</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.237884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.239535</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.239535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.226761</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.226761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.267172</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>0.267172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.239655</td>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.239655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.251154</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.251154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.240367</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.240367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.261914</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.261914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.223164</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>0.223164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.215152</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.215152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.215357</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.215357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.221467</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>0.221467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.214677</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.214677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.217782</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.217782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.211534</td>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.211534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.222804</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.222804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.216323</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.216323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.225750</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.225750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seed  rate      loss  categorical_accuracy  categorical_crossentropy\n",
       "0      0   0.1  0.304116                0.9270                  0.304116\n",
       "1      1   0.1  0.301261                0.9251                  0.301261\n",
       "2      2   0.1  0.315159                0.9230                  0.315159\n",
       "3      3   0.1  0.300282                0.9290                  0.300282\n",
       "4      4   0.1  0.310049                0.9282                  0.310049\n",
       "5      5   0.1  0.272612                0.9254                  0.272612\n",
       "6      6   0.1  0.270459                0.9240                  0.270459\n",
       "7      7   0.1  0.299823                0.9299                  0.299823\n",
       "8      8   0.1  0.314256                0.9285                  0.314256\n",
       "9      9   0.1  0.312211                0.9261                  0.312211\n",
       "10     0   0.2  0.305681                0.9235                  0.305681\n",
       "11     1   0.2  0.265040                0.9288                  0.265040\n",
       "12     2   0.2  0.275683                0.9259                  0.275683\n",
       "13     3   0.2  0.277808                0.9272                  0.277808\n",
       "14     4   0.2  0.265351                0.9275                  0.265351\n",
       "15     5   0.2  0.255924                0.9249                  0.255924\n",
       "16     6   0.2  0.249104                0.9252                  0.249104\n",
       "17     7   0.2  0.263709                0.9257                  0.263709\n",
       "18     8   0.2  0.287701                0.9245                  0.287701\n",
       "19     9   0.2  0.254598                0.9224                  0.254598\n",
       "20     0   0.3  0.258716                0.9289                  0.258716\n",
       "21     1   0.3  0.248473                0.9274                  0.248473\n",
       "22     2   0.3  0.237884                0.9266                  0.237884\n",
       "23     3   0.3  0.239535                0.9280                  0.239535\n",
       "24     4   0.3  0.226761                0.9259                  0.226761\n",
       "25     5   0.3  0.267172                0.9256                  0.267172\n",
       "26     6   0.3  0.239655                0.9282                  0.239655\n",
       "27     7   0.3  0.251154                0.9279                  0.251154\n",
       "28     8   0.3  0.240367                0.9273                  0.240367\n",
       "29     9   0.3  0.261914                0.9272                  0.261914\n",
       "30     0   0.5  0.223164                0.9234                  0.223164\n",
       "31     1   0.5  0.215152                0.9283                  0.215152\n",
       "32     2   0.5  0.215357                0.9261                  0.215357\n",
       "33     3   0.5  0.221467                0.9260                  0.221467\n",
       "34     4   0.5  0.214677                0.9280                  0.214677\n",
       "35     5   0.5  0.217782                0.9264                  0.217782\n",
       "36     6   0.5  0.211534                0.9282                  0.211534\n",
       "37     7   0.5  0.222804                0.9236                  0.222804\n",
       "38     8   0.5  0.216323                0.9235                  0.216323\n",
       "39     9   0.5  0.225750                0.9232                  0.225750"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
