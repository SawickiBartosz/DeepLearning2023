{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from os import path\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import layers, losses, optimizers, metrics, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 10\n",
    "IMG_SIZE = 32"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "            name  codes\n0          1.png      6\n1        100.png      1\n2      10001.png      1\n3      10002.png      6\n4      10003.png      6\n...          ...    ...\n34995   9994.png      1\n34996   9996.png      3\n34997   9997.png      9\n34998   9998.png      1\n34999   9999.png      1\n\n[35000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>codes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.png</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10001.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10002.png</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10003.png</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34995</th>\n      <td>9994.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34996</th>\n      <td>9996.png</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>34997</th>\n      <td>9997.png</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>34998</th>\n      <td>9998.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34999</th>\n      <td>9999.png</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>35000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df = pd.read_csv(path.join(os.getcwd(), 'train_val_test', 'train.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "train_labels_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = image_dataset_from_directory(\n",
    "    directory=path.join(os.getcwd(), 'train_val_test', 'train'),\n",
    "    labels=list(train_labels_df['codes']),\n",
    "    label_mode='int',\n",
    "    validation_split=0,\n",
    "    shuffle=True,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=512,\n",
    "    seed=SEED\n",
    ")\n",
    "dataset_train = dataset_train.map(lambda x, y : (x, tf.one_hot(y, N_CLASS)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "           name  codes\n0        10.png      3\n1      1000.png      5\n2     10000.png      5\n3     10014.png      6\n4     10029.png      7\n...         ...    ...\n4995   9961.png      8\n4996   9977.png      3\n4997    998.png      1\n4998   9986.png      0\n4999   9995.png      6\n\n[5000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>codes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.png</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000.png</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10000.png</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10014.png</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10029.png</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>9961.png</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>9977.png</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>998.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>9986.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>9995.png</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels_df = pd.read_csv(path.join(os.getcwd(), 'train_val_test', 'val.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "val_labels_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_val = image_dataset_from_directory(\n",
    "    directory=path.join(os.getcwd(), 'train_val_test', 'val'),\n",
    "    labels=list(val_labels_df['codes']),\n",
    "    label_mode='int',\n",
    "    validation_split=0,\n",
    "    shuffle=True,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=512,\n",
    "    seed=SEED\n",
    ")\n",
    "dataset_val = dataset_val.map(lambda x, y: (x, tf.one_hot(y, N_CLASS)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_labels_df = pd.read_csv(path.join(os.getcwd(), 'train_val_test', 'test.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "dataset_test = image_dataset_from_directory(\n",
    "    directory=path.join(os.getcwd(), 'train_val_test', 'test'),\n",
    "    labels=list(test_labels_df['codes']),\n",
    "    label_mode='int',\n",
    "    validation_split=0,\n",
    "    shuffle=True,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=512,\n",
    "    seed=SEED\n",
    ")\n",
    "dataset_test = dataset_test.map(lambda x, y: (x, tf.one_hot(y, N_CLASS)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([512, 32, 32, 3]), TensorShape([512, 10]))"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(dataset_train))\n",
    "X.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .cat accessor with a 'category' dtype",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(X[\u001B[38;5;241m3\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m))\n\u001B[1;32m----> 2\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[43mtrain_labels_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcodes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[38;5;241m.\u001B[39mcategories[np\u001B[38;5;241m.\u001B[39margwhere(y[\u001B[38;5;241m3\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy())\u001B[38;5;241m.\u001B[39mflatten()])\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5895\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5896\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[0;32m   5897\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[0;32m   5898\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[0;32m   5899\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   5900\u001B[0m ):\n\u001B[0;32m   5901\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[1;32m-> 5902\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001B[0m, in \u001B[0;36mCachedAccessor.__get__\u001B[1;34m(self, obj, cls)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001B[39;00m\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessor\n\u001B[1;32m--> 182\u001B[0m accessor_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_accessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001B[39;00m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001B[39;00m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;66;03m# NDFrame\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name, accessor_obj)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2849\u001B[0m, in \u001B[0;36mCategoricalAccessor.__init__\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   2848\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 2849\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2850\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m   2851\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mindex\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2858\u001B[0m, in \u001B[0;36mCategoricalAccessor._validate\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m   2855\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m   2856\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate\u001B[39m(data):\n\u001B[0;32m   2857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_categorical_dtype(data\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[1;32m-> 2858\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan only use .cat accessor with a \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m dtype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: Can only use .cat accessor with a 'category' dtype"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqI0lEQVR4nO3df3CV5Zn/8U8STk4SkpyQhPyChPJDQcCwu1RixpZSyQLpjIOV6WjbmcWuo6MbnFW22zY7rVZ3d+Lamda2k+IfdaGdKdLaKTo6W1xFE6a7QJesSKk2I2lawJCgkZz8PonJ8/3D4ew3Cnhf4RzuJLxfM2cGkosr93Pu55yLJznnk5QgCAIBAHCFpfpeAADg6sQAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4Mcv3Aj5sfHxcHR0dysnJUUpKiu/lAACMgiBQX1+fysrKlJp68eucKTeAOjo6VF5e7nsZAIDLdOrUKc2fP/+in0/aAGpsbNR3vvMddXZ2atWqVfrhD3+oNWvWfOy/y8nJkSTdcMMNmjXLbXkjIyPO67LUStLY2Jhz7fvvv2/qnax1WOsv9T+UC8nIyDDVu+6jZN8fy1VyWlqaqbflPozFYqbeoVDIVG9Zu3V/BgcHnWutx2nZn/HxcVNvC+s5bv3uSzK/W1NcXOxca30OikajzrWWc3ZsbExvvPFG/Pn8YpIygH7+859r+/btevLJJ1VVVaUnnnhCGzduVGtrq4qKii75b89v5KxZs5yfuCwnrvWJ3GIqxepZ1mJ9cFqfyC311t7JHEAWybxPrPXJ7G09V6z1yZLM82oy9RaW/8BZJfO8kj7+fknK2fHd735Xd999t77yla9o+fLlevLJJ5WVlaV///d/T8aXAwBMQwkfQCMjI2ppaVFNTc3/fZHUVNXU1OjgwYMfqY/FYurt7Z1wAwDMfAkfQO+++67GxsY+8n3L4uJidXZ2fqS+oaFBkUgkfuMFCABwdfD+Ddr6+npFo9H47dSpU76XBAC4AhL+063CwkKlpaWpq6trwse7urpUUlLykfpwOKxwOJzoZQAApriEXwGlp6dr9erV2r9/f/xj4+Pj2r9/v6qrqxP95QAA01RSXt+3fft2bd26VZ/85Ce1Zs0aPfHEExoYGNBXvvKVZHw5AMA0lJQBdPvtt+udd97RQw89pM7OTv3FX/yF9u3bZ3pDFQBgZksJptK7JyX19vYqEolozZo1zm/AsrzZbWBgwLQeyzvzre8St7zBzPouccsbbq1vMJs9e7ap3qK/v99Un5mZ6VxrTQgYHR11rrWu28qyR1lZWabelseE9Y3clnPc2juZb/609k7mm3kjkYhzbTKf3yzrHhsb05tvvqloNKrc3NyL93TuCABAAjGAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXiTvl41fpiAI5JoSZI0esbBEW1jjct5//33n2mRGg1ijeJKZ3mTtbbnPrREolpgSK+taVq5c6Vy7fPlyU+9oNOpc29PTY+r9+uuvO9dao6ws5631vAqFQqZ6y2PZ+jxh+S3R1jgjy3louQ9da7kCAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHgxZbPgQqGQZs1yW54lo8iaqWatt7DkR1mzqSySeYySbX+sWVaW/DBr5t11112XlFrJnl9YWVnpXFtQUGDqPTo66lxrzTH77W9/61z79ttvm3pbMtLefPNNU29LBqRkO8czMzNNvS0GBwdN9cnKUnR9TuEKCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxZSN4hkZGXGOiRgZGXHua4lukZIXVSHZInCsvS3rtsarWCKEJFvUizUWyNI7Ozvb1PsLX/iCc+3y5ctNvS3nrGTbo6GhIVNvy32YkZFh6l1dXe1ca42RsTyWc3JyTL1fffVVU71rbNhk1mLZH+t9aGGJG3Kt5QoIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MWUzYJLSUlxzgWzZJNZc7Is+UdWlvyo9PR0U2/LcVqz4JJZb72/Lb2Li4tNvefNm+dcGwqFTL27u7tN9ZY8MGtuoOVcsaxDsu2PtXdWVpZz7YoVK0y9jxw5Yqq3ZPtZHveS7X6xPk9YHm+WdbjuO1dAAAAvEj6Avv3tb8evXs7fli1blugvAwCY5pLyLbgVK1bo5Zdf/r8vYrzkBADMfEmZDLNmzVJJSUkyWgMAZoik/AzorbfeUllZmRYtWqQvf/nLOnny5EVrY7GYent7J9wAADNfwgdQVVWVdu3apX379mnHjh1qb2/Xpz/9afX19V2wvqGhQZFIJH4rLy9P9JIAAFNQwgdQbW2tvvCFL6iyslIbN27Uf/zHf6inp0e/+MUvLlhfX1+vaDQav506dSrRSwIATEFJf3VAXl6err32Wp04ceKCnw+HwwqHw8leBgBgikn6+4D6+/vV1tam0tLSZH8pAMA0kvAB9NWvflXNzc3605/+pP/+7//W5z//eaWlpemLX/xior8UAGAaS/i34E6fPq0vfvGL6u7u1ty5c/WpT31Khw4d0ty5c019ent7lZaWlujlmWNkXOOAJFskkCRlZmY61+bk5Jh6W6JBrMbGxkz1lriPZEbxzJ49O2m9L/Yim4v585//bKq3xM7k5eWZelvO22g0aupt2U/LMUq2CCFrRI01WsmylnPnzpl6W6KVrM+Zlngdy3Oha23CB9CePXsS3RIAMAORBQcA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8CLpv45hskZHR52zuCyZXdasMUv+UUZGhqm3Zd2WrCnpg1+L7sqaYWfNgrP0t+6PJd/tmmuuMfW25GS9/vrrpt5NTU2m+s997nPOtXPmzDH1tuSHnT592tTbknn3yU9+0tTbkqVoqZWkefPmmeo7OjpM9RaWx7L1OShZ63B93uQKCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxZSN4rHE1FjiclJTkzdzw+Gwqd4SrzM8PGzqbYnNsLLG5Vj20hILI0mf+cxnnGv/8i//0tTbsj+Wc1CyxwIVFBQkbS2hUMi5dmBgwNS7ra3NubaiosLUu6SkxLnW+rhftmyZqf7o0aPOtSMjI6beFpbHmmR7vFke90TxAACmNAYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLKZsFl5qa6pxTZMk/smZCWfKPRkdHTb2TmUs3NjbmXGvNX0vmulesWGGq37Bhg3NtRkaGqXdPT49zbXl5uan30qVLTfWWnEHreWjJDbRm2GVmZjrXFhYWmnpbMtWs2YhlZWWmekuO3R/+8AdTb0tWXzKfgyyPH9fnH66AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF5M2Sy4UCjknFFmyT96//33TetISUlxrh0aGjL1tmQ8WTLpJFs+npV1LTk5Oc61N954o6l3JBJxrh0eHjb1tpwrWVlZpt6WbDfrWiw5gJItC7CoqMjU23Kc1sdmR0eHc6113ZbHpiStXLnSufbEiROm3tb9tLDsjzVPzwVXQAAAL8wD6MCBA7rllltUVlamlJQUPfvssxM+HwSBHnroIZWWliozM1M1NTV66623ErVeAMAMYR5AAwMDWrVqlRobGy/4+ccff1w/+MEP9OSTT+rw4cOaPXu2Nm7caP72BwBgZjN/U6+2tla1tbUX/FwQBHriiSf0zW9+U5s3b5Yk/fSnP1VxcbGeffZZ3XHHHZe3WgDAjJHQnwG1t7ers7NTNTU18Y9FIhFVVVXp4MGDF/w3sVhMvb29E24AgJkvoQOos7NTklRcXDzh48XFxfHPfVhDQ4MikUj8Zv3NkgCA6cn7q+Dq6+sVjUbjt1OnTvleEgDgCkjoACopKZEkdXV1Tfh4V1dX/HMfFg6HlZubO+EGAJj5EjqAFi5cqJKSEu3fvz/+sd7eXh0+fFjV1dWJ/FIAgGnO/Cq4/v7+Ce/kbW9v19GjR5Wfn6+Kigo98MAD+pd/+Rddc801Wrhwob71rW+prKxMt956ayLXDQCY5swD6MiRI/rsZz8b//v27dslSVu3btWuXbv0ta99TQMDA7rnnnvU09OjT33qU9q3b58yMjJMXyccDjtHhKSmul/IWaJ1zq/D1eDgoKm3JbrHcozW+mTH/Fi+rZqenm7qbYkp6e/vN/W27E9BQYGp93vvvWeq7+7udq61xvxYYmossT2SbT+tUTyxWMy51hLXJcn8fPXhF15dSl5enqm35T2U1rgcS2/L48H1cWkeQOvWrbvkE1ZKSooeffRRPfroo9bWAICriPdXwQEArk4MIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBfmKJ4rZXx83Dm3zZJ7Zs0ay8nJca615mRZsq+sWXCWfDdLnlqy1xIKhUy9LfdhNBo19bbkh/X19Zl6NzU1merPnTvnXGvJJZOkqqoq51pLbpxke/wMDAyYeluy4KznuLU+MzPTuTYSiZh6W85D63OQ5bFsycdzfVxyBQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8GLKRvFYojAs8TqW+A5JmjXL/S6yRM5IthgMa+9kxvxYJTMyZWhoyLnWGpczPj7uXPv222+bere0tJjqe3p6nGsLCwtNvRctWuRca43iCYfDzrWWY5Rs+zk8PGzqbX1MZGVlOdda9+fs2bPOtcmM4kkGroAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXkzZLLjMzEznXCNLDtN7771nWsfo6KhzrSU3TrJljVmy3aws65gMy9pHRkZMvS37Y+2dzPy1UChkqrdkmVnz9Kw5gxaW/Wlvbzf1tqw7Go2aelsfb7m5uc612dnZpt6W+9C699bnrETjCggA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MWUjeIJgsA5asMSm5Gaapu5lmgLa6SNJUrEuu6UlJSkrMPa29r/5MmTpt4ZGRnOtdZ4lc7OTudaSxSLJOXl5ZnqOzo6kraWzMxM51rruTIwMOBce+rUKVPvkpIS51rruq2RNufOnXOu/eMf/2jqbYmQSmYcmKXW9f7jCggA4AUDCADghXkAHThwQLfccovKysqUkpKiZ599dsLn77zzTqWkpEy4bdq0KVHrBQDMEOYBNDAwoFWrVqmxsfGiNZs2bdKZM2fit6effvqyFgkAmHnML0Kora1VbW3tJWvC4bDpB4QAgKtPUn4G1NTUpKKiIi1dulT33Xefuru7L1obi8XU29s74QYAmPkSPoA2bdqkn/70p9q/f7/+7d/+Tc3Nzaqtrb3oy/IaGhoUiUTit/Ly8kQvCQAwBSX8fUB33HFH/M/XX3+9KisrtXjxYjU1NWn9+vUfqa+vr9f27dvjf+/t7WUIAcBVIOkvw160aJEKCwt14sSJC34+HA4rNzd3wg0AMPMlfQCdPn1a3d3dKi0tTfaXAgBMI+ZvwfX390+4mmlvb9fRo0eVn5+v/Px8PfLII9qyZYtKSkrU1tamr33ta1qyZIk2btyY0IUDAKY38wA6cuSIPvvZz8b/fv7nN1u3btWOHTt07Ngx/eQnP1FPT4/Kysq0YcMG/fM//7PC4bDp64TDYedco+HhYVNvi6GhIefatLQ0U29Lvps1Z87S25ozZ83Vsqz92LFjpt6WDC7rWwMsOWbWnLnZs2eb6iORiHOt9Ty0PH6sWWN9fX3OtdFo1NS7oKDAudaSdyfZ78OzZ886117qVcGXy7o/1lzHRDMPoHXr1l3yCejFF1+8rAUBAK4OZMEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxI+O8DSpR58+YpFAo51VrywCyZTZItx8yaH2XJxxsZGTH1dr3vJHsuWSwWM9Vb8vSseWCWtVgzA7OyspxrLblxk6m35PUNDg6aer/zzjtJWYck/elPf3KuteTGSbbH/eLFi029rdl+lvvQmr+Wnp7uXGt9DrLkOlqeU1zPE66AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeTNkonrS0NOdYCUv8hDV2xhrJYZGRkeFca41AGRsbS0qtZIsQkpJ7H1qikixRIpJUUVHhXDtrlu2hVFhYaKq3nCvWKJ7Tp08711qjrCyRQzk5Oabe/f39zrXWc9wSHyXZIoesvS1xOVaWx7Jlf1wf81wBAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALyYsllwg4ODztldlpyn9PR00zpSUlKcay2ZdJItm8ySBSbZcrIseWqTYVm75f6WbFlWc+fONfW2ZMFFIhFT7+LiYlP9yZMnnWuHh4dNvS33uSXbTZLKysqcaxcuXGjqHYvFnGut+YVtbW2m+rffftu51ppLZ3lesT6/WXpbzhPXWq6AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeTNkonqGhIY2OjjrVWqJk3n//fdM6Zs1yv4vy8/NNvS3xINFo1NQ7NdX9/xbJjuLJzMx0rs3KyjL1ttznllgYSZozZ45zrTXqxRoL1NfX51xrjcsZHBx0rrXGyOTl5TnXzps3z9Tbcp9Y96ezs9NUb7kPrbFalsguy+NekvNzrGSLPnJ9nuUKCADghWkANTQ06IYbblBOTo6Kiop06623qrW1dULN8PCw6urqVFBQoOzsbG3ZskVdXV0JXTQAYPozDaDm5mbV1dXp0KFDeumllzQ6OqoNGzZMuOR/8MEH9fzzz+uZZ55Rc3OzOjo6dNtttyV84QCA6c30M6B9+/ZN+PuuXbtUVFSklpYWrV27VtFoVE899ZR2796tm2++WZK0c+dOXXfddTp06JBuvPHGxK0cADCtXdbPgM7/YPz8D4JbWlo0OjqqmpqaeM2yZctUUVGhgwcPXrBHLBZTb2/vhBsAYOab9AAaHx/XAw88oJtuukkrV66U9MErR9LT0z/yypfi4uKLvqqkoaFBkUgkfisvL5/skgAA08ikB1BdXZ2OHz+uPXv2XNYC6uvrFY1G47dTp05dVj8AwPQwqfcBbdu2TS+88IIOHDig+fPnxz9eUlKikZER9fT0TLgK6urqUklJyQV7hcNh82v0AQDTn+kKKAgCbdu2TXv37tUrr7zykd/hvnr1aoVCIe3fvz/+sdbWVp08eVLV1dWJWTEAYEYwXQHV1dVp9+7deu6555STkxP/uU4kElFmZqYikYjuuusubd++Xfn5+crNzdX999+v6upqXgEHAJjANIB27NghSVq3bt2Ej+/cuVN33nmnJOl73/ueUlNTtWXLFsViMW3cuFE/+tGPErJYAMDMYRpAQRB8bE1GRoYaGxvV2Ng46UVJtsw2S57RyMiIaR2WrLGCggJTb0t+lDULzpLvlpaWZuptyXaTpOzsbOda688DLdlx1nVbzhVLLplku08kadGiRc611nO8ra3Nuda6Py7PGefl5uaaeqekpDjXWvMOh4aGTPXJzF607Kc1q8/y2Lf0dj1GsuAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF5M6tcxXAlpaWnOMRGWGAxrXI4lfsIag2GJb7HEjkgfRCK5skbxWOJvJGnWLPfTzBLBJNlimCzniWSLkRkeHjb1tkQ8SbboHsu6JencuXPOtZa9lGz3izWixvJYtkYfffiXavpkeexbnycs50oy4oa4AgIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4MWWz4EZHR51zisLhsHNfa+5ZKBRyrrXkkkm23DNLtpskpaenO9daM+ys9SMjI8611v2xZF9ZcwBnz57tXNvf32/qPTQ0ZKpPZiZhMo/Tku9mzRiMRCLOtZmZmabeK1asMNUfO3bMudaaeWfJsbM+fixZcMnIpOMKCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxZSN4klJSXGOc7DET/T19ZnWkZeX51xrib+RpFgs5lw7PDxs6m2J+bGyRHJItmgYSyyMZItjmTt3rqm3JULIuj/nzp0z1Vtiaqx7b4mGSU21/Z/V8ticM2eOqfesWe5PX9ZzdsGCBaZ6y9qte29ZuzWyyxLFk4znFK6AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF5M2Sy41NRUc+5UMnR3dzvXWtc7OjrqXGvJjZNsGU/W/ChLtptky+yyZJ5J0ic+8Ymk9U5mnp51Py179M4775h6v/fee8611nVb9seS6yfZzkPLOShJpaWlpvpFixY51x4/ftzU25Ixacn1k2w5c5bnN9da/8/wAICrkmkANTQ06IYbblBOTo6Kiop06623qrW1dULNunXr4knW52/33ntvQhcNAJj+TAOoublZdXV1OnTokF566SWNjo5qw4YNGhgYmFB3991368yZM/Hb448/ntBFAwCmP9M3Rvft2zfh77t27VJRUZFaWlq0du3a+MezsrJUUlKSmBUCAGaky/oZUDQalSTl5+dP+PjPfvYzFRYWauXKlaqvr9fg4OBFe8RiMfX29k64AQBmvkm/Cm58fFwPPPCAbrrpJq1cuTL+8S996UtasGCBysrKdOzYMX39619Xa2urfvWrX12wT0NDgx555JHJLgMAME1NegDV1dXp+PHj+s1vfjPh4/fcc0/8z9dff71KS0u1fv16tbW1afHixR/pU19fr+3bt8f/3tvbq/Ly8skuCwAwTUxqAG3btk0vvPCCDhw4oPnz51+ytqqqSpJ04sSJCw6gcDiscDg8mWUAAKYx0wAKgkD333+/9u7dq6amJi1cuPBj/83Ro0cl2d/YBQCY2UwDqK6uTrt379Zzzz2nnJwcdXZ2SvrgHcyZmZlqa2vT7t279bnPfU4FBQU6duyYHnzwQa1du1aVlZVJOQAAwPRkGkA7duyQ9MGbTf9/O3fu1J133qn09HS9/PLLeuKJJzQwMKDy8nJt2bJF3/zmNxO2YADAzGD+FtyllJeXq7m5+bIWdF44HFYoFHKqteSeWTOhLBlcH35D7sexZCtZ1225Tyx5UJI9885SP2fOHFPvBQsWJGUdki07rri42NTbmqdnyaWzZt6lpaU513Z0dJh6W3LMrOehpT4zM9PU27JuSSoqKnKudX1eO8+yPyMjI6beFpaf1bs+/5AFBwDwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwYtK/DyjZxsbGnKM2LDE1lmgdyRY/YY2RsUTDvPvuu6belkgOa0SN9ddnWPpbI1NycnKca63xKpaoF2tv63kYiUSStpZ33nnHubakpMTU2xILZI2yys7Odq61xvxYz/G5c+c611r3fmhoyLl2fHzc1NtynJa9dI2O4goIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MWUzYLLyspSKBRyqrVmX1lY8qksuWSSVFZW5lwbi8VMvbu7u51rXe/n86z3t2sulCTl5uaaeltyAK0s+XvW/bEeZ35+vnOtNcfMsvbCwkJT7+HhYefaP/7xj6beo6OjzrVBEJh6Wx8TpaWlzrWWXD/Jlu/W399v6m3JpUtLS3OudV0zV0AAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC+mbBRPWlqac/RDNBpN2jrGxsacay2xPZI0b94859olS5aYeqekpDjXWmNkLBEoVpa4D8m2lszMTFPvkZER51rruq1RL5bzMDXV9v/K7OzspNRKthgma8ST5Tit+2O9D7OyspxrreehJV7Hel5ZWCKBiOIBAExpDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBdTNguuq6tLs2a5Lc+SUZSRkWFahyVDqqenx9TbkpNVXl5u6n3ttdc613Z3d5t6Dw8Pm+oHBweda9vb2029r7nmGufaoaEhU29LFpw1gyscDpvqc3JynGut57jlOIMgMPW2ZNhZM9Is97l13clkXYvl+c2aeWdhyZd0reUKCADghWkA7dixQ5WVlcrNzVVubq6qq6v161//Ov754eFh1dXVqaCgQNnZ2dqyZYu6uroSvmgAwPRnGkDz58/XY489ppaWFh05ckQ333yzNm/erN///veSpAcffFDPP/+8nnnmGTU3N6ujo0O33XZbUhYOAJjeTD8DuuWWWyb8/V//9V+1Y8cOHTp0SPPnz9dTTz2l3bt36+abb5Yk7dy5U9ddd50OHTqkG2+8MXGrBgBMe5P+GdDY2Jj27NmjgYEBVVdXq6WlRaOjo6qpqYnXLFu2TBUVFTp48OBF+8RiMfX29k64AQBmPvMA+t3vfqfs7GyFw2Hde++92rt3r5YvX67Ozk6lp6crLy9vQn1xcbE6Ozsv2q+hoUGRSCR+s77aCwAwPZkH0NKlS3X06FEdPnxY9913n7Zu3ao33nhj0guor69XNBqN306dOjXpXgCA6cP8PqD09HQtWbJEkrR69Wr9z//8j77//e/r9ttv18jIiHp6eiZcBXV1damkpOSi/cLhsPk9EQCA6e+y3wc0Pj6uWCym1atXKxQKaf/+/fHPtba26uTJk6qurr7cLwMAmGFMV0D19fWqra1VRUWF+vr6tHv3bjU1NenFF19UJBLRXXfdpe3btys/P1+5ubm6//77VV1dzSvgAAAfYRpAZ8+e1d/8zd/ozJkzikQiqqys1Isvvqi//uu/liR973vfU2pqqrZs2aJYLKaNGzfqRz/60aQWNjw87BwrYYnwsMTfWOstsSOSFI1GnWut8Tf5+fnOtXPnzjX1LigoMNUnM+rl9OnTzrWWOBtJKiwsdK61xshYYk0kW8SK9T60rMV6jlv23nqfWOotcTaSbd3WeteIsfNSU92/UWXde8uPPyznoOv9bbonnnrqqUt+PiMjQ42NjWpsbLS0BQBchciCAwB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeGFOw06281ESlsgPS1yOJdbCyhpTYmGNEBodHXWutcaOWCUziscSUWSNQBkcHHSuTWb8jbU+mceZzN5DQ0NJ6z0wMGDqbX2esKzd8tiUkhsHZultWff5vh/3uJhyA6ivr0+S9Prrr3teCQDgcvT19SkSiVz08ymB9b9uSTY+Pq6Ojg7l5ORM+F9fb2+vysvLderUKeXm5npcYXJxnDPH1XCMEsc50yTiOIMgUF9fn8rKyi55NTnlroBSU1M1f/78i34+Nzd3Rm/+eRznzHE1HKPEcc40l3ucl7ryOY8XIQAAvGAAAQC8mDYDKBwO6+GHHzb9AqXpiOOcOa6GY5Q4zpnmSh7nlHsRAgDg6jBtroAAADMLAwgA4AUDCADgBQMIAODFtBlAjY2N+sQnPqGMjAxVVVXpt7/9re8lJdS3v/1tpaSkTLgtW7bM97Iuy4EDB3TLLbeorKxMKSkpevbZZyd8PggCPfTQQyotLVVmZqZqamr01ltv+VnsZfi447zzzjs/srebNm3ys9hJamho0A033KCcnBwVFRXp1ltvVWtr64Sa4eFh1dXVqaCgQNnZ2dqyZYu6uro8rXhyXI5z3bp1H9nPe++919OKJ2fHjh2qrKyMv9m0urpav/71r+Ofv1J7OS0G0M9//nNt375dDz/8sP73f/9Xq1at0saNG3X27FnfS0uoFStW6MyZM/Hbb37zG99LuiwDAwNatWqVGhsbL/j5xx9/XD/4wQ/05JNP6vDhw5o9e7Y2btxoChidCj7uOCVp06ZNE/b26aefvoIrvHzNzc2qq6vToUOH9NJLL2l0dFQbNmyYEPL54IMP6vnnn9czzzyj5uZmdXR06LbbbvO4ajuX45Sku+++e8J+Pv74455WPDnz58/XY489ppaWFh05ckQ333yzNm/erN///veSruBeBtPAmjVrgrq6uvjfx8bGgrKysqChocHjqhLr4YcfDlatWuV7GUkjKdi7d2/87+Pj40FJSUnwne98J/6xnp6eIBwOB08//bSHFSbGh48zCIJg69atwebNm72sJ1nOnj0bSAqam5uDIPhg70KhUPDMM8/Ea958881AUnDw4EFfy7xsHz7OIAiCz3zmM8Hf//3f+1tUksyZMyf48Y9/fEX3cspfAY2MjKilpUU1NTXxj6WmpqqmpkYHDx70uLLEe+utt1RWVqZFixbpy1/+sk6ePOl7SUnT3t6uzs7OCfsaiURUVVU14/ZVkpqamlRUVKSlS5fqvvvuU3d3t+8lXZZoNCpJys/PlyS1tLRodHR0wn4uW7ZMFRUV03o/P3yc5/3sZz9TYWGhVq5cqfr6etOvhphqxsbGtGfPHg0MDKi6uvqK7uWUCyP9sHfffVdjY2MqLi6e8PHi4mL94Q9/8LSqxKuqqtKuXbu0dOlSnTlzRo888og+/elP6/jx48rJyfG9vITr7OyUpAvu6/nPzRSbNm3SbbfdpoULF6qtrU3/9E//pNraWh08eFBpaWm+l2c2Pj6uBx54QDfddJNWrlwp6YP9TE9PV15e3oTa6byfFzpOSfrSl76kBQsWqKysTMeOHdPXv/51tba26le/+pXH1dr97ne/U3V1tYaHh5Wdna29e/dq+fLlOnr06BXbyyk/gK4WtbW18T9XVlaqqqpKCxYs0C9+8QvdddddHleGy3XHHXfE/3z99dersrJSixcvVlNTk9avX+9xZZNTV1en48ePT/ufUX6cix3nPffcE//z9ddfr9LSUq1fv15tbW1avHjxlV7mpC1dulRHjx5VNBrVL3/5S23dulXNzc1XdA1T/ltwhYWFSktL+8grMLq6ulRSUuJpVcmXl5ena6+9VidOnPC9lKQ4v3dX275K0qJFi1RYWDgt93bbtm164YUX9Oqrr074tSklJSUaGRlRT0/PhPrpup8XO84LqaqqkqRpt5/p6elasmSJVq9erYaGBq1atUrf//73r+heTvkBlJ6ertWrV2v//v3xj42Pj2v//v2qrq72uLLk6u/vV1tbm0pLS30vJSkWLlyokpKSCfva29urw4cPz+h9laTTp0+ru7t7Wu1tEATatm2b9u7dq1deeUULFy6c8PnVq1crFApN2M/W1ladPHlyWu3nxx3nhRw9elSSptV+Xsj4+LhisdiV3cuEvqQhSfbs2ROEw+Fg165dwRtvvBHcc889QV5eXtDZ2el7aQnzD//wD0FTU1PQ3t4e/Nd//VdQU1MTFBYWBmfPnvW9tEnr6+sLXnvtteC1114LJAXf/e53g9deey3485//HARBEDz22GNBXl5e8NxzzwXHjh0LNm/eHCxcuDAYGhryvHKbSx1nX19f8NWvfjU4ePBg0N7eHrz88svBX/3VXwXXXHNNMDw87Hvpzu67774gEokETU1NwZkzZ+K3wcHBeM29994bVFRUBK+88kpw5MiRoLq6Oqiurva4aruPO84TJ04Ejz76aHDkyJGgvb09eO6554JFixYFa9eu9bxym2984xtBc3Nz0N7eHhw7diz4xje+EaSkpAT/+Z//GQTBldvLaTGAgiAIfvjDHwYVFRVBenp6sGbNmuDQoUO+l5RQt99+e1BaWhqkp6cH8+bNC26//fbgxIkTvpd1WV599dVA0kduW7duDYLgg5dif+tb3wqKi4uDcDgcrF+/PmhtbfW76Em41HEODg4GGzZsCObOnRuEQqFgwYIFwd133z3t/vN0oeOTFOzcuTNeMzQ0FPzd3/1dMGfOnCArKyv4/Oc/H5w5c8bfoifh447z5MmTwdq1a4P8/PwgHA4HS5YsCf7xH/8xiEajfhdu9Ld/+7fBggULgvT09GDu3LnB+vXr48MnCK7cXvLrGAAAXkz5nwEBAGYmBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAi/8H2ubQe2SWiawAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[3].numpy().astype(int))\n",
    "plt.xlabel(train_labels_df.codes.cat.categories[np.argwhere(y[3].numpy()).flatten()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple keras sequential model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 512)               819712    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 890,410\n",
      "Trainable params: 890,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "    model.add(layers.Conv2D(32, 3, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(layers.Conv2D(32, 3, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Conv2D(64, 3, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(layers.Conv2D(64, 3, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "    # Fully connected classifier\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(layers.Dense(N_CLASS, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=[metrics.CategoricalAccuracy(), metrics.CategoricalCrossentropy()]\n",
    ")\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath=\"simple_cnn.h5\",\n",
    "    monitor=\"val_categorical_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=3, min_lr=0.00001, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 8/69 [==>...........................] - ETA: 57s - loss: 24.6690 - categorical_accuracy: 0.1104 - categorical_crossentropy: 24.6690"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[78], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m25\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_lr\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\keras\\engine\\training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1648\u001B[0m ):\n\u001B[0;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    132\u001B[0m   (concrete_function,\n\u001B[0;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m     args,\n\u001B[0;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1750\u001B[0m     executing_eagerly)\n\u001B[0;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=25,\n",
    "    workers=2,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=dataset_val,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments\n",
    "\n",
    "Training will be repeated 10 times with different weights initialization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "25/69 [=========>....................] - ETA: 40s - loss: 5.1160 - categorical_accuracy: 0.1161 - categorical_crossentropy: 5.1160"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[82], line 15\u001B[0m\n\u001B[0;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m create_model()\n\u001B[0;32m      9\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[0;32m     10\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m),\n\u001B[0;32m     11\u001B[0m     loss\u001B[38;5;241m=\u001B[39mlosses\u001B[38;5;241m.\u001B[39mCategoricalCrossentropy(),\n\u001B[0;32m     12\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[metrics\u001B[38;5;241m.\u001B[39mCategoricalAccuracy(), metrics\u001B[38;5;241m.\u001B[39mCategoricalCrossentropy()]\n\u001B[0;32m     13\u001B[0m )\n\u001B[1;32m---> 15\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m25\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_lr\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m eval_results \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(dataset_test)\n\u001B[0;32m     26\u001B[0m results \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [{\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m'\u001B[39m: seed,\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mzip\u001B[39m(model\u001B[38;5;241m.\u001B[39mmetrics_names, eval_results))\n\u001B[0;32m     29\u001B[0m }]\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\keras\\engine\\training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1648\u001B[0m ):\n\u001B[0;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    132\u001B[0m   (concrete_function,\n\u001B[0;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m     args,\n\u001B[0;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1750\u001B[0m     executing_eagerly)\n\u001B[0;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mE:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(10))\n",
    "results = []\n",
    "for seed in TRAINING_SEEDS:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "        loss=losses.CategoricalCrossentropy(),\n",
    "        metrics=[metrics.CategoricalAccuracy(), metrics.CategoricalCrossentropy()]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        dataset_train,\n",
    "        epochs=25,\n",
    "        workers=2,\n",
    "        use_multiprocessing=True,\n",
    "        validation_data=dataset_val,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    eval_results = model.evaluate(dataset_test)\n",
    "\n",
    "    results += [{\n",
    "        'seed': seed,\n",
    "        'results': dict(zip(model.metrics_names, eval_results))\n",
    "    }]\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results = pd.concat([results.drop([\"results\"], axis=1), results[\"results\"].apply(pd.Series)], axis=1)\n",
    "results.to_csv('simple_cnn_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
