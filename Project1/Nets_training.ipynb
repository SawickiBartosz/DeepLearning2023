{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from os import path\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import layers, losses, optimizers, metrics, callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.config.list_logical_devices()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 10\n",
    "IMG_SIZE = 32"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels_df = pd.read_csv(path.join(os.getcwd(), 'train_val_test', 'train.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "train_labels_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_train = image_dataset_from_directory(\n",
    "    directory=path.join(os.getcwd(), 'train_val_test', 'train'),\n",
    "    labels=list(train_labels_df['codes']),\n",
    "    label_mode='int',\n",
    "    validation_split=0,\n",
    "    shuffle=True,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=512,\n",
    "    seed=SEED\n",
    ")\n",
    "dataset_train = dataset_train.map(lambda x, y : (x, tf.one_hot(y, N_CLASS)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_labels_df = pd.read_csv(path.join(os.getcwd(), 'train_val_test', 'val.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "val_labels_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_val = image_dataset_from_directory(\n",
    "    directory=path.join(os.getcwd(), 'train_val_test', 'val'),\n",
    "    labels=list(val_labels_df['codes']),\n",
    "    label_mode='int',\n",
    "    validation_split=0,\n",
    "    shuffle=True,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=512,\n",
    "    seed=SEED\n",
    ")\n",
    "dataset_val = dataset_val.map(lambda x, y: (x, tf.one_hot(y, N_CLASS)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_labels_df = pd.read_csv(path.join(os.getcwd(), 'train_val_test', 'test.csv')).drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "dataset_test = image_dataset_from_directory(\n",
    "    directory=path.join(os.getcwd(), 'train_val_test', 'test'),\n",
    "    labels=list(test_labels_df['codes']),\n",
    "    label_mode='int',\n",
    "    validation_split=0,\n",
    "    shuffle=True,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=512,\n",
    "    seed=SEED\n",
    ")\n",
    "dataset_test = dataset_test.map(lambda x, y: (x, tf.one_hot(y, N_CLASS)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X, y = next(iter(dataset_train))\n",
    "X.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(X[3].numpy().astype(int))\n",
    "plt.xlabel(train_labels_df.codes.cat.categories[np.argwhere(y[3].numpy()).flatten()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y[3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple keras sequential model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "    model.add(layers.Conv2D(32, 3, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(layers.Conv2D(32, 3, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Conv2D(64, 3, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(layers.Conv2D(64, 3, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "    # Fully connected classifier\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(layers.Dense(N_CLASS, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=[metrics.CategoricalAccuracy(), metrics.CategoricalCrossentropy()]\n",
    ")\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath=\"simple_cnn.h5\",\n",
    "    monitor=\"val_categorical_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=3, min_lr=0.00001, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=25,\n",
    "    workers=2,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=dataset_val,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments\n",
    "\n",
    "Training will be repeated 10 times with different weights initialization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAINING_SEEDS = list(range(10))\n",
    "results = []\n",
    "for seed in TRAINING_SEEDS:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "        loss=losses.CategoricalCrossentropy(),\n",
    "        metrics=[metrics.CategoricalAccuracy(), metrics.CategoricalCrossentropy()]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        dataset_train,\n",
    "        epochs=25,\n",
    "        workers=2,\n",
    "        use_multiprocessing=True,\n",
    "        validation_data=dataset_val,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    eval_results = model.evaluate(dataset_test)\n",
    "\n",
    "    results += [{\n",
    "        'seed': seed,\n",
    "        'results': dict(zip(model.metrics_names, eval_results))\n",
    "    }]\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results = pd.concat([results.drop([\"results\"], axis=1), results[\"results\"].apply(pd.Series)], axis=1)\n",
    "results.to_csv('simple_cnn_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
