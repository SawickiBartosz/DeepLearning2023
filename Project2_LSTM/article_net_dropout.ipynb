{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import losses, optimizers, metrics, callbacks, Model, layers, backend as K\n",
    "\n",
    "import SpeechModels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:46.143977Z",
     "end_time": "2023-04-24T00:39:49.582862Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:49.584856Z",
     "end_time": "2023-04-24T00:39:50.210822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 12\n",
    "MAX_EPOCHS = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:50.212815Z",
     "end_time": "2023-04-24T00:39:50.256669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:50.227765Z",
     "end_time": "2023-04-24T00:39:50.261653Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45586 files belonging to 12 classes.\n",
      "Found 6513 files belonging to 12 classes.\n",
      "Found 13024 files belonging to 12 classes.\n",
      "label names: ['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/train\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/val\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/test\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print(\"label names:\", label_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:50.245706Z",
     "end_time": "2023-04-24T00:39:55.570985Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(squeeze, tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:55.573976Z",
     "end_time": "2023-04-24T00:39:55.633784Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model from article"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " normalized_spectrogram_model (  (None, 125, 80)     0           ['input[0][0]']                  \n",
      " Functional)                                                                                      \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 125, 80, 1)   0           ['normalized_spectrogram_model[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 125, 80, 10)  60          ['tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 125, 80, 10)  40         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 125, 80, 1)   51          ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 125, 80, 1)  4           ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, 125, 80)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 125, 128)     74240       ['squeeze_last_dim[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 125, 128)    98816       ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 128)          0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          16512       ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 125)          0           ['dense[0][0]',                  \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, 125)          0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 12)           396         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 200,455\n",
      "Trainable params: 200,433\n",
      "Non-trainable params: 22\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(rate):\n",
    "    m = SpeechModels.get_melspec_model(iLen=16000)\n",
    "    m.trainable = False\n",
    "    inputs, outputs = m.inputs, m.outputs\n",
    "    x = m(inputs)\n",
    "    x = tf.expand_dims(x, axis=-1, name='mel_stft')\n",
    "\n",
    "    x = layers.Conv2D(10, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # x = Reshape((125, 80)) (x)\n",
    "    # keras.backend.squeeze(x, axis)\n",
    "    x = layers.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True)\n",
    "                        )(x)  # [b_s, seq_len, vec_dim]\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True)\n",
    "                        )(x)  # [b_s, seq_len, vec_dim]\n",
    "\n",
    "    x_first = layers.Lambda(lambda q: q[:, -1])(x)  # [b_s, vec_dim]\n",
    "    query = layers.Dense(128)(x_first)\n",
    "\n",
    "    # dot product attention\n",
    "    att_scores = layers.Dot(axes=[1, 2])([query, x])\n",
    "    att_scores = layers.Softmax(name='attSoftmax')(att_scores)  # [b_s, seq_len]\n",
    "\n",
    "    # rescale sequence\n",
    "    att_vector = layers.Dot(axes=[1, 1])([att_scores, x])  # [b_s, vec_dim]\n",
    "    x = layers.Dropout(rate=rate)(att_vector)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(rate=rate)(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "    x = layers.Dropout(rate=rate)(x)\n",
    "    output = layers.Dense(N_CLASS, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model(0.1)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:55.639764Z",
     "end_time": "2023-04-24T00:39:56.760546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=3, min_lr=0.00001, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:56.728452Z",
     "end_time": "2023-04-24T00:39:56.761542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "90/90 [==============================] - 30s 191ms/step - loss: 1.5906 - sparse_categorical_accuracy: 0.6232 - sparse_categorical_crossentropy: 1.5906 - val_loss: 1.5437 - val_sparse_categorical_accuracy: 0.6301 - val_sparse_categorical_crossentropy: 1.5437 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 18s 182ms/step - loss: 1.1429 - sparse_categorical_accuracy: 0.6714 - sparse_categorical_crossentropy: 1.1429 - val_loss: 1.0064 - val_sparse_categorical_accuracy: 0.6989 - val_sparse_categorical_crossentropy: 1.0064 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=2,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:39:56.758553Z",
     "end_time": "2023-04-24T00:40:44.573555Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments\n",
    "\n",
    "Training will be repeated 5 times with different weights initialization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 24s 193ms/step - loss: 1.1920 - sparse_categorical_accuracy: 0.6640 - sparse_categorical_crossentropy: 1.1920 - val_loss: 1.6116 - val_sparse_categorical_accuracy: 0.6146 - val_sparse_categorical_crossentropy: 1.6116 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 18s 182ms/step - loss: 0.4803 - sparse_categorical_accuracy: 0.8526 - sparse_categorical_crossentropy: 0.4803 - val_loss: 1.5603 - val_sparse_categorical_accuracy: 0.6269 - val_sparse_categorical_crossentropy: 1.5603 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 180ms/step - loss: 0.2730 - sparse_categorical_accuracy: 0.9176 - sparse_categorical_crossentropy: 0.2730 - val_loss: 1.4255 - val_sparse_categorical_accuracy: 0.6289 - val_sparse_categorical_crossentropy: 1.4255 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2072 - sparse_categorical_accuracy: 0.9384 - sparse_categorical_crossentropy: 0.2072 - val_loss: 1.2250 - val_sparse_categorical_accuracy: 0.6894 - val_sparse_categorical_crossentropy: 1.2250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9529 - sparse_categorical_crossentropy: 0.1602 - val_loss: 0.7353 - val_sparse_categorical_accuracy: 0.7947 - val_sparse_categorical_crossentropy: 0.7353 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 180ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9570 - sparse_categorical_crossentropy: 0.1434 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.8211 - val_sparse_categorical_crossentropy: 0.6548 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9671 - sparse_categorical_crossentropy: 0.1132 - val_loss: 0.2053 - val_sparse_categorical_accuracy: 0.9424 - val_sparse_categorical_crossentropy: 0.2053 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1039 - sparse_categorical_accuracy: 0.9701 - sparse_categorical_crossentropy: 0.1039 - val_loss: 0.5997 - val_sparse_categorical_accuracy: 0.8371 - val_sparse_categorical_crossentropy: 0.5997 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1284 - sparse_categorical_accuracy: 0.9623 - sparse_categorical_crossentropy: 0.1284 - val_loss: 0.4665 - val_sparse_categorical_accuracy: 0.8675 - val_sparse_categorical_crossentropy: 0.4665 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9728 - sparse_categorical_crossentropy: 0.0937 - val_loss: 0.1803 - val_sparse_categorical_accuracy: 0.9466 - val_sparse_categorical_crossentropy: 0.1803 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9756 - sparse_categorical_crossentropy: 0.0852 - val_loss: 0.3248 - val_sparse_categorical_accuracy: 0.9157 - val_sparse_categorical_crossentropy: 0.3248 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0810 - sparse_categorical_accuracy: 0.9768 - sparse_categorical_crossentropy: 0.0810 - val_loss: 0.5579 - val_sparse_categorical_accuracy: 0.8521 - val_sparse_categorical_crossentropy: 0.5579 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9718 - sparse_categorical_crossentropy: 0.0952 - val_loss: 0.1432 - val_sparse_categorical_accuracy: 0.9613 - val_sparse_categorical_crossentropy: 0.1432 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9785 - sparse_categorical_crossentropy: 0.0741 - val_loss: 0.4694 - val_sparse_categorical_accuracy: 0.8769 - val_sparse_categorical_crossentropy: 0.4694 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0609 - sparse_categorical_accuracy: 0.9824 - sparse_categorical_crossentropy: 0.0609 - val_loss: 0.4204 - val_sparse_categorical_accuracy: 0.8873 - val_sparse_categorical_crossentropy: 0.4204 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1619 - sparse_categorical_accuracy: 0.9529 - sparse_categorical_crossentropy: 0.1619\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1621 - sparse_categorical_accuracy: 0.9529 - sparse_categorical_crossentropy: 0.1621 - val_loss: 0.3650 - val_sparse_categorical_accuracy: 0.9060 - val_sparse_categorical_crossentropy: 0.3650 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9725 - sparse_categorical_crossentropy: 0.0956 - val_loss: 0.1757 - val_sparse_categorical_accuracy: 0.9529 - val_sparse_categorical_crossentropy: 0.1757 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0520 - sparse_categorical_accuracy: 0.9852 - sparse_categorical_crossentropy: 0.0520 - val_loss: 0.1582 - val_sparse_categorical_accuracy: 0.9618 - val_sparse_categorical_crossentropy: 0.1582 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9880 - sparse_categorical_crossentropy: 0.0415 - val_loss: 0.1577 - val_sparse_categorical_accuracy: 0.9633 - val_sparse_categorical_crossentropy: 0.1577 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9891 - sparse_categorical_crossentropy: 0.0388 - val_loss: 0.1467 - val_sparse_categorical_accuracy: 0.9645 - val_sparse_categorical_crossentropy: 0.1467 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9879 - sparse_categorical_crossentropy: 0.0429 - val_loss: 0.1534 - val_sparse_categorical_accuracy: 0.9659 - val_sparse_categorical_crossentropy: 0.1534 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9907 - sparse_categorical_crossentropy: 0.0313 - val_loss: 0.1500 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1500 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9911 - sparse_categorical_crossentropy: 0.0296 - val_loss: 0.1849 - val_sparse_categorical_accuracy: 0.9644 - val_sparse_categorical_crossentropy: 0.1849 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9908 - sparse_categorical_crossentropy: 0.0321 - val_loss: 0.1806 - val_sparse_categorical_accuracy: 0.9613 - val_sparse_categorical_crossentropy: 0.1806 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0490 - sparse_categorical_accuracy: 0.9858 - sparse_categorical_crossentropy: 0.0490\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9859 - sparse_categorical_crossentropy: 0.0490 - val_loss: 0.1628 - val_sparse_categorical_accuracy: 0.9647 - val_sparse_categorical_crossentropy: 0.1628 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9916 - sparse_categorical_crossentropy: 0.0298 - val_loss: 0.1532 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1532 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9936 - sparse_categorical_crossentropy: 0.0221 - val_loss: 0.1614 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.1614 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9940 - sparse_categorical_crossentropy: 0.0212 - val_loss: 0.1749 - val_sparse_categorical_accuracy: 0.9664 - val_sparse_categorical_crossentropy: 0.1749 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0482 - sparse_categorical_accuracy: 0.9867 - sparse_categorical_crossentropy: 0.0482\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9867 - sparse_categorical_crossentropy: 0.0482 - val_loss: 0.1584 - val_sparse_categorical_accuracy: 0.9659 - val_sparse_categorical_crossentropy: 0.1584 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0228 - sparse_categorical_accuracy: 0.9936 - sparse_categorical_crossentropy: 0.0228 - val_loss: 0.1695 - val_sparse_categorical_accuracy: 0.9681 - val_sparse_categorical_crossentropy: 0.1695 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0204 - sparse_categorical_accuracy: 0.9943 - sparse_categorical_crossentropy: 0.0204 - val_loss: 0.1720 - val_sparse_categorical_accuracy: 0.9688 - val_sparse_categorical_crossentropy: 0.1720 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.9945 - sparse_categorical_crossentropy: 0.0190 - val_loss: 0.1881 - val_sparse_categorical_accuracy: 0.9674 - val_sparse_categorical_crossentropy: 0.1881 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0183 - sparse_categorical_accuracy: 0.9948 - sparse_categorical_crossentropy: 0.0183 - val_loss: 0.1867 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.1867 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0180 - sparse_categorical_accuracy: 0.9950 - sparse_categorical_crossentropy: 0.0180\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9950 - sparse_categorical_crossentropy: 0.0180 - val_loss: 0.1851 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.1851 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0170 - sparse_categorical_accuracy: 0.9952 - sparse_categorical_crossentropy: 0.0170 - val_loss: 0.1877 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1877 - lr: 6.2500e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0233 - sparse_categorical_accuracy: 0.9932 - sparse_categorical_crossentropy: 0.0233 - val_loss: 0.1836 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.1836 - lr: 6.2500e-04\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9950 - sparse_categorical_crossentropy: 0.0174 - val_loss: 0.1854 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1854 - lr: 6.2500e-04\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9951 - sparse_categorical_crossentropy: 0.0172 - val_loss: 0.1902 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1902 - lr: 6.2500e-04\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9953 - sparse_categorical_crossentropy: 0.0164 - val_loss: 0.1954 - val_sparse_categorical_accuracy: 0.9698 - val_sparse_categorical_crossentropy: 0.1954 - lr: 6.2500e-04\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9953 - sparse_categorical_crossentropy: 0.0160 - val_loss: 0.1982 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1982 - lr: 6.2500e-04\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0162 - sparse_categorical_accuracy: 0.9953 - sparse_categorical_crossentropy: 0.0162 - val_loss: 0.1986 - val_sparse_categorical_accuracy: 0.9688 - val_sparse_categorical_crossentropy: 0.1986 - lr: 6.2500e-04\n",
      "Epoch 42/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0167 - sparse_categorical_accuracy: 0.9951 - sparse_categorical_crossentropy: 0.0167\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9951 - sparse_categorical_crossentropy: 0.0167 - val_loss: 0.2120 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.2120 - lr: 6.2500e-04\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9955 - sparse_categorical_crossentropy: 0.0156 - val_loss: 0.2126 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.2126 - lr: 3.1250e-04\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9957 - sparse_categorical_crossentropy: 0.0154 - val_loss: 0.2101 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.2101 - lr: 3.1250e-04\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.1945 - sparse_categorical_accuracy: 0.9695 - sparse_categorical_crossentropy: 0.1945\n",
      "26/26 [==============================] - 4s 113ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 192ms/step - loss: 1.2833 - sparse_categorical_accuracy: 0.6543 - sparse_categorical_crossentropy: 1.2833 - val_loss: 0.9537 - val_sparse_categorical_accuracy: 0.7193 - val_sparse_categorical_crossentropy: 0.9537 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.5286 - sparse_categorical_accuracy: 0.8379 - sparse_categorical_crossentropy: 0.5286 - val_loss: 0.5165 - val_sparse_categorical_accuracy: 0.8405 - val_sparse_categorical_crossentropy: 0.5165 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.3453 - sparse_categorical_accuracy: 0.8951 - sparse_categorical_crossentropy: 0.3453 - val_loss: 0.2672 - val_sparse_categorical_accuracy: 0.9143 - val_sparse_categorical_crossentropy: 0.2672 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2316 - sparse_categorical_accuracy: 0.9305 - sparse_categorical_crossentropy: 0.2316 - val_loss: 0.2504 - val_sparse_categorical_accuracy: 0.9308 - val_sparse_categorical_crossentropy: 0.2504 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2094 - sparse_categorical_accuracy: 0.9382 - sparse_categorical_crossentropy: 0.2094 - val_loss: 0.3124 - val_sparse_categorical_accuracy: 0.9057 - val_sparse_categorical_crossentropy: 0.3124 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1909 - sparse_categorical_accuracy: 0.9442 - sparse_categorical_crossentropy: 0.1909 - val_loss: 0.1894 - val_sparse_categorical_accuracy: 0.9481 - val_sparse_categorical_crossentropy: 0.1894 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1755 - sparse_categorical_accuracy: 0.9490 - sparse_categorical_crossentropy: 0.1755 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9478 - val_sparse_categorical_crossentropy: 0.1796 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1337 - sparse_categorical_accuracy: 0.9608 - sparse_categorical_crossentropy: 0.1337 - val_loss: 0.1526 - val_sparse_categorical_accuracy: 0.9575 - val_sparse_categorical_crossentropy: 0.1526 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1047 - sparse_categorical_accuracy: 0.9697 - sparse_categorical_crossentropy: 0.1047 - val_loss: 0.1629 - val_sparse_categorical_accuracy: 0.9564 - val_sparse_categorical_crossentropy: 0.1629 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9732 - sparse_categorical_crossentropy: 0.0924 - val_loss: 0.1587 - val_sparse_categorical_accuracy: 0.9572 - val_sparse_categorical_crossentropy: 0.1587 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0981 - sparse_categorical_accuracy: 0.9711 - sparse_categorical_crossentropy: 0.0981\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0980 - sparse_categorical_accuracy: 0.9711 - sparse_categorical_crossentropy: 0.0980 - val_loss: 0.1571 - val_sparse_categorical_accuracy: 0.9562 - val_sparse_categorical_crossentropy: 0.1571 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0648 - sparse_categorical_accuracy: 0.9818 - sparse_categorical_crossentropy: 0.0648 - val_loss: 0.1427 - val_sparse_categorical_accuracy: 0.9651 - val_sparse_categorical_crossentropy: 0.1427 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9869 - sparse_categorical_crossentropy: 0.0480 - val_loss: 0.1462 - val_sparse_categorical_accuracy: 0.9665 - val_sparse_categorical_crossentropy: 0.1462 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9873 - sparse_categorical_crossentropy: 0.0450 - val_loss: 0.1465 - val_sparse_categorical_accuracy: 0.9658 - val_sparse_categorical_crossentropy: 0.1465 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9893 - sparse_categorical_crossentropy: 0.0377 - val_loss: 0.1662 - val_sparse_categorical_accuracy: 0.9661 - val_sparse_categorical_crossentropy: 0.1662 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0369 - sparse_categorical_accuracy: 0.9898 - sparse_categorical_crossentropy: 0.0369\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0369 - sparse_categorical_accuracy: 0.9898 - sparse_categorical_crossentropy: 0.0369 - val_loss: 0.2035 - val_sparse_categorical_accuracy: 0.9621 - val_sparse_categorical_crossentropy: 0.2035 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0327 - sparse_categorical_accuracy: 0.9904 - sparse_categorical_crossentropy: 0.0327 - val_loss: 0.1712 - val_sparse_categorical_accuracy: 0.9644 - val_sparse_categorical_crossentropy: 0.1712 - lr: 0.0025\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0271 - sparse_categorical_accuracy: 0.9924 - sparse_categorical_crossentropy: 0.0271 - val_loss: 0.1822 - val_sparse_categorical_accuracy: 0.9645 - val_sparse_categorical_crossentropy: 0.1822 - lr: 0.0025\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9641 - sparse_categorical_crossentropy: 0.1552\n",
      "26/26 [==============================] - 4s 124ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 190ms/step - loss: 0.9253 - sparse_categorical_accuracy: 0.7293 - sparse_categorical_crossentropy: 0.9253 - val_loss: 1.3992 - val_sparse_categorical_accuracy: 0.6175 - val_sparse_categorical_crossentropy: 1.3992 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.4120 - sparse_categorical_accuracy: 0.8747 - sparse_categorical_crossentropy: 0.4120 - val_loss: 0.4069 - val_sparse_categorical_accuracy: 0.8655 - val_sparse_categorical_crossentropy: 0.4069 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2718 - sparse_categorical_accuracy: 0.9189 - sparse_categorical_crossentropy: 0.2718 - val_loss: 0.2710 - val_sparse_categorical_accuracy: 0.9159 - val_sparse_categorical_crossentropy: 0.2710 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2183 - sparse_categorical_accuracy: 0.9353 - sparse_categorical_crossentropy: 0.2183 - val_loss: 0.2089 - val_sparse_categorical_accuracy: 0.9366 - val_sparse_categorical_crossentropy: 0.2089 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1662 - sparse_categorical_accuracy: 0.9501 - sparse_categorical_crossentropy: 0.1662 - val_loss: 0.2376 - val_sparse_categorical_accuracy: 0.9269 - val_sparse_categorical_crossentropy: 0.2376 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1422 - sparse_categorical_accuracy: 0.9587 - sparse_categorical_crossentropy: 0.1422 - val_loss: 0.2011 - val_sparse_categorical_accuracy: 0.9438 - val_sparse_categorical_crossentropy: 0.2011 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9571 - sparse_categorical_crossentropy: 0.1476 - val_loss: 0.2268 - val_sparse_categorical_accuracy: 0.9370 - val_sparse_categorical_crossentropy: 0.2268 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9549 - sparse_categorical_crossentropy: 0.1543 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9573 - val_sparse_categorical_crossentropy: 0.1408 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1138 - sparse_categorical_accuracy: 0.9665 - sparse_categorical_crossentropy: 0.1138 - val_loss: 0.1516 - val_sparse_categorical_accuracy: 0.9598 - val_sparse_categorical_crossentropy: 0.1516 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9719 - sparse_categorical_crossentropy: 0.0976 - val_loss: 0.1377 - val_sparse_categorical_accuracy: 0.9638 - val_sparse_categorical_crossentropy: 0.1377 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9762 - sparse_categorical_crossentropy: 0.0809 - val_loss: 0.1559 - val_sparse_categorical_accuracy: 0.9572 - val_sparse_categorical_crossentropy: 0.1559 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9742 - sparse_categorical_crossentropy: 0.0902 - val_loss: 0.1467 - val_sparse_categorical_accuracy: 0.9596 - val_sparse_categorical_crossentropy: 0.1467 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9769 - sparse_categorical_crossentropy: 0.0790 - val_loss: 0.1428 - val_sparse_categorical_accuracy: 0.9644 - val_sparse_categorical_crossentropy: 0.1428 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9781 - sparse_categorical_crossentropy: 0.0758 - val_loss: 0.1421 - val_sparse_categorical_accuracy: 0.9625 - val_sparse_categorical_crossentropy: 0.1421 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9819 - sparse_categorical_crossentropy: 0.0626 - val_loss: 0.1627 - val_sparse_categorical_accuracy: 0.9576 - val_sparse_categorical_crossentropy: 0.1627 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0633 - sparse_categorical_accuracy: 0.9812 - sparse_categorical_crossentropy: 0.0633\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9812 - sparse_categorical_crossentropy: 0.0632 - val_loss: 0.1559 - val_sparse_categorical_accuracy: 0.9627 - val_sparse_categorical_crossentropy: 0.1559 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9853 - sparse_categorical_crossentropy: 0.0510 - val_loss: 0.1338 - val_sparse_categorical_accuracy: 0.9705 - val_sparse_categorical_crossentropy: 0.1338 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0318 - sparse_categorical_accuracy: 0.9910 - sparse_categorical_crossentropy: 0.0318 - val_loss: 0.1456 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.1456 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9922 - sparse_categorical_crossentropy: 0.0273 - val_loss: 0.1432 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.1432 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0272 - sparse_categorical_accuracy: 0.9922 - sparse_categorical_crossentropy: 0.0272\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9922 - sparse_categorical_crossentropy: 0.0272 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9671 - val_sparse_categorical_crossentropy: 0.1684 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9935 - sparse_categorical_crossentropy: 0.0222 - val_loss: 0.1640 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1640 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9944 - sparse_categorical_crossentropy: 0.0191 - val_loss: 0.1725 - val_sparse_categorical_accuracy: 0.9682 - val_sparse_categorical_crossentropy: 0.1725 - lr: 0.0025\n",
      "26/26 [==============================] - 4s 131ms/step - loss: 0.1403 - sparse_categorical_accuracy: 0.9657 - sparse_categorical_crossentropy: 0.1403\n",
      "26/26 [==============================] - 5s 128ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 190ms/step - loss: 0.9786 - sparse_categorical_accuracy: 0.7150 - sparse_categorical_crossentropy: 0.9786 - val_loss: 1.0606 - val_sparse_categorical_accuracy: 0.6559 - val_sparse_categorical_crossentropy: 1.0606 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.4786 - sparse_categorical_accuracy: 0.8522 - sparse_categorical_crossentropy: 0.4786 - val_loss: 0.3707 - val_sparse_categorical_accuracy: 0.8845 - val_sparse_categorical_crossentropy: 0.3707 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.3183 - sparse_categorical_accuracy: 0.9040 - sparse_categorical_crossentropy: 0.3183 - val_loss: 0.2723 - val_sparse_categorical_accuracy: 0.9197 - val_sparse_categorical_crossentropy: 0.2723 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2460 - sparse_categorical_accuracy: 0.9253 - sparse_categorical_crossentropy: 0.2460 - val_loss: 0.2163 - val_sparse_categorical_accuracy: 0.9369 - val_sparse_categorical_crossentropy: 0.2163 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.2057 - sparse_categorical_accuracy: 0.9384 - sparse_categorical_crossentropy: 0.2057 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9292 - val_sparse_categorical_crossentropy: 0.2325 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.2023 - sparse_categorical_accuracy: 0.9388 - sparse_categorical_crossentropy: 0.2023 - val_loss: 0.1948 - val_sparse_categorical_accuracy: 0.9427 - val_sparse_categorical_crossentropy: 0.1948 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1883 - sparse_categorical_accuracy: 0.9436 - sparse_categorical_crossentropy: 0.1883 - val_loss: 0.1792 - val_sparse_categorical_accuracy: 0.9472 - val_sparse_categorical_crossentropy: 0.1792 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1608 - sparse_categorical_accuracy: 0.9533 - sparse_categorical_crossentropy: 0.1608 - val_loss: 0.1758 - val_sparse_categorical_accuracy: 0.9504 - val_sparse_categorical_crossentropy: 0.1758 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9630 - sparse_categorical_crossentropy: 0.1271 - val_loss: 0.1805 - val_sparse_categorical_accuracy: 0.9492 - val_sparse_categorical_crossentropy: 0.1805 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1141 - sparse_categorical_accuracy: 0.9666 - sparse_categorical_crossentropy: 0.1141 - val_loss: 0.1602 - val_sparse_categorical_accuracy: 0.9547 - val_sparse_categorical_crossentropy: 0.1602 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9709 - sparse_categorical_crossentropy: 0.0979 - val_loss: 0.1779 - val_sparse_categorical_accuracy: 0.9515 - val_sparse_categorical_crossentropy: 0.1779 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1218 - sparse_categorical_accuracy: 0.9634 - sparse_categorical_crossentropy: 0.1218 - val_loss: 0.1602 - val_sparse_categorical_accuracy: 0.9576 - val_sparse_categorical_crossentropy: 0.1602 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9733 - sparse_categorical_crossentropy: 0.0918 - val_loss: 0.1846 - val_sparse_categorical_accuracy: 0.9529 - val_sparse_categorical_crossentropy: 0.1846 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1451 - sparse_categorical_accuracy: 0.9581 - sparse_categorical_crossentropy: 0.1451 - val_loss: 0.1784 - val_sparse_categorical_accuracy: 0.9484 - val_sparse_categorical_crossentropy: 0.1784 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9643 - sparse_categorical_crossentropy: 0.1209 - val_loss: 0.1637 - val_sparse_categorical_accuracy: 0.9578 - val_sparse_categorical_crossentropy: 0.1637 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0903 - sparse_categorical_accuracy: 0.9744 - sparse_categorical_crossentropy: 0.0903 - val_loss: 0.1524 - val_sparse_categorical_accuracy: 0.9598 - val_sparse_categorical_crossentropy: 0.1524 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9756 - sparse_categorical_crossentropy: 0.0838 - val_loss: 0.2158 - val_sparse_categorical_accuracy: 0.9487 - val_sparse_categorical_crossentropy: 0.2158 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1162 - sparse_categorical_accuracy: 0.9665 - sparse_categorical_crossentropy: 0.1162 - val_loss: 0.1576 - val_sparse_categorical_accuracy: 0.9575 - val_sparse_categorical_crossentropy: 0.1576 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9790 - sparse_categorical_crossentropy: 0.0732 - val_loss: 0.1507 - val_sparse_categorical_accuracy: 0.9619 - val_sparse_categorical_crossentropy: 0.1507 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9815 - sparse_categorical_crossentropy: 0.0660 - val_loss: 0.1788 - val_sparse_categorical_accuracy: 0.9578 - val_sparse_categorical_crossentropy: 0.1788 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0722 - sparse_categorical_accuracy: 0.9788 - sparse_categorical_crossentropy: 0.0722 - val_loss: 0.1682 - val_sparse_categorical_accuracy: 0.9590 - val_sparse_categorical_crossentropy: 0.1682 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9804 - sparse_categorical_crossentropy: 0.0678 - val_loss: 0.1457 - val_sparse_categorical_accuracy: 0.9638 - val_sparse_categorical_crossentropy: 0.1457 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9806 - sparse_categorical_crossentropy: 0.0679 - val_loss: 0.1736 - val_sparse_categorical_accuracy: 0.9604 - val_sparse_categorical_crossentropy: 0.1736 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9825 - sparse_categorical_crossentropy: 0.0600 - val_loss: 0.1934 - val_sparse_categorical_accuracy: 0.9546 - val_sparse_categorical_crossentropy: 0.1934 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1228 - sparse_categorical_accuracy: 0.9646 - sparse_categorical_crossentropy: 0.1228\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1227 - sparse_categorical_accuracy: 0.9646 - sparse_categorical_crossentropy: 0.1227 - val_loss: 0.1662 - val_sparse_categorical_accuracy: 0.9533 - val_sparse_categorical_crossentropy: 0.1662 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9822 - sparse_categorical_crossentropy: 0.0630 - val_loss: 0.1385 - val_sparse_categorical_accuracy: 0.9648 - val_sparse_categorical_crossentropy: 0.1385 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9879 - sparse_categorical_crossentropy: 0.0440 - val_loss: 0.1387 - val_sparse_categorical_accuracy: 0.9658 - val_sparse_categorical_crossentropy: 0.1387 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0358 - sparse_categorical_accuracy: 0.9898 - sparse_categorical_crossentropy: 0.0358 - val_loss: 0.1665 - val_sparse_categorical_accuracy: 0.9655 - val_sparse_categorical_crossentropy: 0.1665 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9899 - sparse_categorical_crossentropy: 0.0344 - val_loss: 0.1639 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1639 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9907 - sparse_categorical_crossentropy: 0.0321 - val_loss: 0.1782 - val_sparse_categorical_accuracy: 0.9628 - val_sparse_categorical_crossentropy: 0.1782 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0328 - sparse_categorical_accuracy: 0.9904 - sparse_categorical_crossentropy: 0.0328 - val_loss: 0.1613 - val_sparse_categorical_accuracy: 0.9659 - val_sparse_categorical_crossentropy: 0.1613 - lr: 0.0050\n",
      "Epoch 32/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0338 - sparse_categorical_accuracy: 0.9903 - sparse_categorical_crossentropy: 0.0338\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0338 - sparse_categorical_accuracy: 0.9903 - sparse_categorical_crossentropy: 0.0338 - val_loss: 0.1706 - val_sparse_categorical_accuracy: 0.9645 - val_sparse_categorical_crossentropy: 0.1706 - lr: 0.0050\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0266 - sparse_categorical_accuracy: 0.9923 - sparse_categorical_crossentropy: 0.0266 - val_loss: 0.1661 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.1661 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9940 - sparse_categorical_crossentropy: 0.0213 - val_loss: 0.1851 - val_sparse_categorical_accuracy: 0.9674 - val_sparse_categorical_crossentropy: 0.1851 - lr: 0.0025\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9944 - sparse_categorical_crossentropy: 0.0195 - val_loss: 0.1964 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.1964 - lr: 0.0025\n",
      "Epoch 36/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0187 - sparse_categorical_accuracy: 0.9944 - sparse_categorical_crossentropy: 0.0187\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9944 - sparse_categorical_crossentropy: 0.0187 - val_loss: 0.2041 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.2041 - lr: 0.0025\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9949 - sparse_categorical_crossentropy: 0.0173 - val_loss: 0.2185 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.2185 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9949 - sparse_categorical_crossentropy: 0.0174 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9674 - val_sparse_categorical_crossentropy: 0.2271 - lr: 0.0012\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9952 - sparse_categorical_crossentropy: 0.0164 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.2272 - lr: 0.0012\n",
      "Epoch 40/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0166 - sparse_categorical_accuracy: 0.9949 - sparse_categorical_crossentropy: 0.0166\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9949 - sparse_categorical_crossentropy: 0.0167 - val_loss: 0.2330 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.2330 - lr: 0.0012\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9955 - sparse_categorical_crossentropy: 0.0154 - val_loss: 0.2402 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.2402 - lr: 6.2500e-04\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0152 - sparse_categorical_accuracy: 0.9953 - sparse_categorical_crossentropy: 0.0152 - val_loss: 0.2412 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.2412 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.2412 - sparse_categorical_accuracy: 0.9659 - sparse_categorical_crossentropy: 0.2412\n",
      "26/26 [==============================] - 4s 125ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 191ms/step - loss: 1.5788 - sparse_categorical_accuracy: 0.6239 - sparse_categorical_crossentropy: 1.5788 - val_loss: 1.5363 - val_sparse_categorical_accuracy: 0.6301 - val_sparse_categorical_crossentropy: 1.5363 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 1.2009 - sparse_categorical_accuracy: 0.6499 - sparse_categorical_crossentropy: 1.2009 - val_loss: 2.1378 - val_sparse_categorical_accuracy: 0.2954 - val_sparse_categorical_crossentropy: 2.1378 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.5963 - sparse_categorical_accuracy: 0.8088 - sparse_categorical_crossentropy: 0.5963 - val_loss: 1.8163 - val_sparse_categorical_accuracy: 0.5877 - val_sparse_categorical_crossentropy: 1.8163 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.3259 - sparse_categorical_accuracy: 0.9013 - sparse_categorical_crossentropy: 0.3259 - val_loss: 1.4032 - val_sparse_categorical_accuracy: 0.6433 - val_sparse_categorical_crossentropy: 1.4032 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2216 - sparse_categorical_accuracy: 0.9342 - sparse_categorical_crossentropy: 0.2216 - val_loss: 0.6215 - val_sparse_categorical_accuracy: 0.8150 - val_sparse_categorical_crossentropy: 0.6215 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1887 - sparse_categorical_accuracy: 0.9458 - sparse_categorical_crossentropy: 0.1887 - val_loss: 0.5111 - val_sparse_categorical_accuracy: 0.8485 - val_sparse_categorical_crossentropy: 0.5111 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1651 - sparse_categorical_accuracy: 0.9521 - sparse_categorical_crossentropy: 0.1651 - val_loss: 0.7801 - val_sparse_categorical_accuracy: 0.7709 - val_sparse_categorical_crossentropy: 0.7801 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1599 - sparse_categorical_accuracy: 0.9536 - sparse_categorical_crossentropy: 0.1599 - val_loss: 0.3887 - val_sparse_categorical_accuracy: 0.8881 - val_sparse_categorical_crossentropy: 0.3887 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9637 - sparse_categorical_crossentropy: 0.1255 - val_loss: 0.2692 - val_sparse_categorical_accuracy: 0.9272 - val_sparse_categorical_crossentropy: 0.2692 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1435 - sparse_categorical_accuracy: 0.9588 - sparse_categorical_crossentropy: 0.1435 - val_loss: 0.2638 - val_sparse_categorical_accuracy: 0.9261 - val_sparse_categorical_crossentropy: 0.2638 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9672 - sparse_categorical_crossentropy: 0.1157 - val_loss: 0.1851 - val_sparse_categorical_accuracy: 0.9496 - val_sparse_categorical_crossentropy: 0.1851 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.9681 - sparse_categorical_crossentropy: 0.1113 - val_loss: 0.1719 - val_sparse_categorical_accuracy: 0.9513 - val_sparse_categorical_crossentropy: 0.1719 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9726 - sparse_categorical_crossentropy: 0.0964 - val_loss: 0.1563 - val_sparse_categorical_accuracy: 0.9585 - val_sparse_categorical_crossentropy: 0.1563 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9767 - sparse_categorical_crossentropy: 0.0820 - val_loss: 0.1595 - val_sparse_categorical_accuracy: 0.9555 - val_sparse_categorical_crossentropy: 0.1595 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0811 - sparse_categorical_accuracy: 0.9764 - sparse_categorical_crossentropy: 0.0811 - val_loss: 0.1399 - val_sparse_categorical_accuracy: 0.9625 - val_sparse_categorical_crossentropy: 0.1399 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0729 - sparse_categorical_accuracy: 0.9793 - sparse_categorical_crossentropy: 0.0729 - val_loss: 0.2031 - val_sparse_categorical_accuracy: 0.9493 - val_sparse_categorical_crossentropy: 0.2031 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0731 - sparse_categorical_accuracy: 0.9792 - sparse_categorical_crossentropy: 0.0731 - val_loss: 0.1560 - val_sparse_categorical_accuracy: 0.9601 - val_sparse_categorical_crossentropy: 0.1560 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0689 - sparse_categorical_accuracy: 0.9806 - sparse_categorical_crossentropy: 0.0689\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9805 - sparse_categorical_crossentropy: 0.0689 - val_loss: 0.1535 - val_sparse_categorical_accuracy: 0.9596 - val_sparse_categorical_crossentropy: 0.1535 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0516 - sparse_categorical_accuracy: 0.9848 - sparse_categorical_crossentropy: 0.0516 - val_loss: 0.1469 - val_sparse_categorical_accuracy: 0.9642 - val_sparse_categorical_crossentropy: 0.1469 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0384 - sparse_categorical_accuracy: 0.9893 - sparse_categorical_crossentropy: 0.0384 - val_loss: 0.1364 - val_sparse_categorical_accuracy: 0.9668 - val_sparse_categorical_crossentropy: 0.1364 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0331 - sparse_categorical_accuracy: 0.9910 - sparse_categorical_crossentropy: 0.0331 - val_loss: 0.1493 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.1493 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9917 - sparse_categorical_crossentropy: 0.0302 - val_loss: 0.1655 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1655 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0343 - sparse_categorical_accuracy: 0.9902 - sparse_categorical_crossentropy: 0.0343 - val_loss: 0.1936 - val_sparse_categorical_accuracy: 0.9599 - val_sparse_categorical_crossentropy: 0.1936 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0346 - sparse_categorical_accuracy: 0.9903 - sparse_categorical_crossentropy: 0.0346\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9903 - sparse_categorical_crossentropy: 0.0346 - val_loss: 0.1589 - val_sparse_categorical_accuracy: 0.9673 - val_sparse_categorical_crossentropy: 0.1589 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0261 - sparse_categorical_accuracy: 0.9928 - sparse_categorical_crossentropy: 0.0261 - val_loss: 0.1590 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1590 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0237 - sparse_categorical_accuracy: 0.9933 - sparse_categorical_crossentropy: 0.0237 - val_loss: 0.1781 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1781 - lr: 0.0025\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.1673 - sparse_categorical_accuracy: 0.9668 - sparse_categorical_crossentropy: 0.1673\n",
      "26/26 [==============================] - 5s 129ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 192ms/step - loss: 1.3732 - sparse_categorical_accuracy: 0.6302 - sparse_categorical_crossentropy: 1.3732 - val_loss: 1.6867 - val_sparse_categorical_accuracy: 0.6240 - val_sparse_categorical_crossentropy: 1.6867 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.6957 - sparse_categorical_accuracy: 0.7673 - sparse_categorical_crossentropy: 0.6957 - val_loss: 1.7218 - val_sparse_categorical_accuracy: 0.6272 - val_sparse_categorical_crossentropy: 1.7218 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.3994 - sparse_categorical_accuracy: 0.8809 - sparse_categorical_crossentropy: 0.3994 - val_loss: 1.7480 - val_sparse_categorical_accuracy: 0.5911 - val_sparse_categorical_crossentropy: 1.7480 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2792 - sparse_categorical_accuracy: 0.9219 - sparse_categorical_crossentropy: 0.2792 - val_loss: 0.6123 - val_sparse_categorical_accuracy: 0.8397 - val_sparse_categorical_crossentropy: 0.6123 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.3757 - sparse_categorical_accuracy: 0.8947 - sparse_categorical_crossentropy: 0.3757 - val_loss: 0.5283 - val_sparse_categorical_accuracy: 0.8537 - val_sparse_categorical_crossentropy: 0.5283 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1969 - sparse_categorical_accuracy: 0.9468 - sparse_categorical_crossentropy: 0.1969 - val_loss: 0.3381 - val_sparse_categorical_accuracy: 0.9065 - val_sparse_categorical_crossentropy: 0.3381 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1678 - sparse_categorical_accuracy: 0.9542 - sparse_categorical_crossentropy: 0.1678 - val_loss: 0.6184 - val_sparse_categorical_accuracy: 0.8263 - val_sparse_categorical_crossentropy: 0.6184 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1985 - sparse_categorical_accuracy: 0.9446 - sparse_categorical_crossentropy: 0.1985 - val_loss: 0.2251 - val_sparse_categorical_accuracy: 0.9409 - val_sparse_categorical_crossentropy: 0.2251 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1569 - sparse_categorical_accuracy: 0.9561 - sparse_categorical_crossentropy: 0.1569 - val_loss: 0.1632 - val_sparse_categorical_accuracy: 0.9576 - val_sparse_categorical_crossentropy: 0.1632 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1250 - sparse_categorical_accuracy: 0.9647 - sparse_categorical_crossentropy: 0.1250 - val_loss: 0.1906 - val_sparse_categorical_accuracy: 0.9512 - val_sparse_categorical_crossentropy: 0.1906 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9671 - sparse_categorical_crossentropy: 0.1210 - val_loss: 0.1731 - val_sparse_categorical_accuracy: 0.9585 - val_sparse_categorical_crossentropy: 0.1731 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1274 - sparse_categorical_accuracy: 0.9644 - sparse_categorical_crossentropy: 0.1274 - val_loss: 0.2022 - val_sparse_categorical_accuracy: 0.9450 - val_sparse_categorical_crossentropy: 0.2022 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1101 - sparse_categorical_accuracy: 0.9700 - sparse_categorical_crossentropy: 0.1101 - val_loss: 0.1808 - val_sparse_categorical_accuracy: 0.9518 - val_sparse_categorical_crossentropy: 0.1808 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1170 - sparse_categorical_accuracy: 0.9673 - sparse_categorical_crossentropy: 0.1170\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1170 - sparse_categorical_accuracy: 0.9673 - sparse_categorical_crossentropy: 0.1170 - val_loss: 0.2082 - val_sparse_categorical_accuracy: 0.9490 - val_sparse_categorical_crossentropy: 0.2082 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9788 - sparse_categorical_crossentropy: 0.0788 - val_loss: 0.1476 - val_sparse_categorical_accuracy: 0.9639 - val_sparse_categorical_crossentropy: 0.1476 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9834 - sparse_categorical_crossentropy: 0.0603 - val_loss: 0.1315 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1315 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9857 - sparse_categorical_crossentropy: 0.0532 - val_loss: 0.1468 - val_sparse_categorical_accuracy: 0.9673 - val_sparse_categorical_crossentropy: 0.1468 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9877 - sparse_categorical_crossentropy: 0.0462 - val_loss: 0.1527 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1527 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0527 - sparse_categorical_accuracy: 0.9861 - sparse_categorical_crossentropy: 0.0527\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9861 - sparse_categorical_crossentropy: 0.0527 - val_loss: 0.1425 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1425 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9885 - sparse_categorical_crossentropy: 0.0429 - val_loss: 0.1364 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1364 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9910 - sparse_categorical_crossentropy: 0.0344 - val_loss: 0.1493 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1493 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0305 - sparse_categorical_accuracy: 0.9919 - sparse_categorical_crossentropy: 0.0305 - val_loss: 0.1674 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.1674 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0309 - sparse_categorical_accuracy: 0.9916 - sparse_categorical_crossentropy: 0.0309 - val_loss: 0.1759 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.1759 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0297 - sparse_categorical_accuracy: 0.9922 - sparse_categorical_crossentropy: 0.0297 - val_loss: 0.1815 - val_sparse_categorical_accuracy: 0.9691 - val_sparse_categorical_crossentropy: 0.1815 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0285 - sparse_categorical_accuracy: 0.9924 - sparse_categorical_crossentropy: 0.0285\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0285 - sparse_categorical_accuracy: 0.9924 - sparse_categorical_crossentropy: 0.0285 - val_loss: 0.1834 - val_sparse_categorical_accuracy: 0.9701 - val_sparse_categorical_crossentropy: 0.1834 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0260 - sparse_categorical_accuracy: 0.9929 - sparse_categorical_crossentropy: 0.0260 - val_loss: 0.1879 - val_sparse_categorical_accuracy: 0.9707 - val_sparse_categorical_crossentropy: 0.1879 - lr: 0.0012\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0241 - sparse_categorical_accuracy: 0.9934 - sparse_categorical_crossentropy: 0.0241 - val_loss: 0.2035 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.2035 - lr: 0.0012\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.9935 - sparse_categorical_crossentropy: 0.0235 - val_loss: 0.2017 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.2017 - lr: 0.0012\n",
      "Epoch 29/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0225 - sparse_categorical_accuracy: 0.9938 - sparse_categorical_crossentropy: 0.0225\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9938 - sparse_categorical_crossentropy: 0.0225 - val_loss: 0.2115 - val_sparse_categorical_accuracy: 0.9701 - val_sparse_categorical_crossentropy: 0.2115 - lr: 0.0012\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9939 - sparse_categorical_crossentropy: 0.0222 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9694 - val_sparse_categorical_crossentropy: 0.2121 - lr: 6.2500e-04\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0233 - sparse_categorical_accuracy: 0.9934 - sparse_categorical_crossentropy: 0.0233 - val_loss: 0.2049 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.2049 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 4s 137ms/step - loss: 0.2350 - sparse_categorical_accuracy: 0.9671 - sparse_categorical_crossentropy: 0.2350\n",
      "26/26 [==============================] - 5s 134ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 188ms/step - loss: 1.3500 - sparse_categorical_accuracy: 0.6331 - sparse_categorical_crossentropy: 1.3500 - val_loss: 0.8912 - val_sparse_categorical_accuracy: 0.7118 - val_sparse_categorical_crossentropy: 0.8912 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.6704 - sparse_categorical_accuracy: 0.7918 - sparse_categorical_crossentropy: 0.6704 - val_loss: 0.6071 - val_sparse_categorical_accuracy: 0.8171 - val_sparse_categorical_crossentropy: 0.6071 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.4809 - sparse_categorical_accuracy: 0.8593 - sparse_categorical_crossentropy: 0.4809 - val_loss: 0.3629 - val_sparse_categorical_accuracy: 0.8941 - val_sparse_categorical_crossentropy: 0.3629 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.3370 - sparse_categorical_accuracy: 0.9052 - sparse_categorical_crossentropy: 0.3370 - val_loss: 0.3092 - val_sparse_categorical_accuracy: 0.9125 - val_sparse_categorical_crossentropy: 0.3092 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.2753 - sparse_categorical_accuracy: 0.9225 - sparse_categorical_crossentropy: 0.2753 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9354 - val_sparse_categorical_crossentropy: 0.2271 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.2335 - sparse_categorical_accuracy: 0.9358 - sparse_categorical_crossentropy: 0.2335 - val_loss: 0.2605 - val_sparse_categorical_accuracy: 0.9265 - val_sparse_categorical_crossentropy: 0.2605 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.2134 - sparse_categorical_accuracy: 0.9412 - sparse_categorical_crossentropy: 0.2134 - val_loss: 0.2136 - val_sparse_categorical_accuracy: 0.9378 - val_sparse_categorical_crossentropy: 0.2136 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 173ms/step - loss: 0.1788 - sparse_categorical_accuracy: 0.9511 - sparse_categorical_crossentropy: 0.1788 - val_loss: 0.2057 - val_sparse_categorical_accuracy: 0.9421 - val_sparse_categorical_crossentropy: 0.2057 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.1555 - sparse_categorical_accuracy: 0.9580 - sparse_categorical_crossentropy: 0.1555 - val_loss: 0.1804 - val_sparse_categorical_accuracy: 0.9565 - val_sparse_categorical_crossentropy: 0.1804 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1872 - sparse_categorical_accuracy: 0.9498 - sparse_categorical_crossentropy: 0.1872 - val_loss: 0.1937 - val_sparse_categorical_accuracy: 0.9509 - val_sparse_categorical_crossentropy: 0.1937 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9587 - sparse_categorical_crossentropy: 0.1537 - val_loss: 0.1833 - val_sparse_categorical_accuracy: 0.9532 - val_sparse_categorical_crossentropy: 0.1833 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1219 - sparse_categorical_accuracy: 0.9673 - sparse_categorical_crossentropy: 0.1219\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9673 - sparse_categorical_crossentropy: 0.1221 - val_loss: 0.2998 - val_sparse_categorical_accuracy: 0.9249 - val_sparse_categorical_crossentropy: 0.2998 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.9722 - sparse_categorical_crossentropy: 0.1049 - val_loss: 0.1525 - val_sparse_categorical_accuracy: 0.9619 - val_sparse_categorical_crossentropy: 0.1525 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0729 - sparse_categorical_accuracy: 0.9801 - sparse_categorical_crossentropy: 0.0729 - val_loss: 0.1859 - val_sparse_categorical_accuracy: 0.9621 - val_sparse_categorical_crossentropy: 0.1859 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9811 - sparse_categorical_crossentropy: 0.0705 - val_loss: 0.1682 - val_sparse_categorical_accuracy: 0.9599 - val_sparse_categorical_crossentropy: 0.1682 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0702 - sparse_categorical_accuracy: 0.9819 - sparse_categorical_crossentropy: 0.0702 - val_loss: 0.1541 - val_sparse_categorical_accuracy: 0.9651 - val_sparse_categorical_crossentropy: 0.1541 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9846 - sparse_categorical_crossentropy: 0.0574 - val_loss: 0.1747 - val_sparse_categorical_accuracy: 0.9638 - val_sparse_categorical_crossentropy: 0.1747 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 173ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9855 - sparse_categorical_crossentropy: 0.0531 - val_loss: 0.1740 - val_sparse_categorical_accuracy: 0.9632 - val_sparse_categorical_crossentropy: 0.1740 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0527 - sparse_categorical_accuracy: 0.9858 - sparse_categorical_crossentropy: 0.0527\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9858 - sparse_categorical_crossentropy: 0.0527 - val_loss: 0.1772 - val_sparse_categorical_accuracy: 0.9628 - val_sparse_categorical_crossentropy: 0.1772 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 173ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9883 - sparse_categorical_crossentropy: 0.0453 - val_loss: 0.1909 - val_sparse_categorical_accuracy: 0.9645 - val_sparse_categorical_crossentropy: 0.1909 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0405 - sparse_categorical_accuracy: 0.9889 - sparse_categorical_crossentropy: 0.0405 - val_loss: 0.1904 - val_sparse_categorical_accuracy: 0.9650 - val_sparse_categorical_crossentropy: 0.1904 - lr: 0.0025\n",
      "26/26 [==============================] - 4s 137ms/step - loss: 0.1715 - sparse_categorical_accuracy: 0.9638 - sparse_categorical_crossentropy: 0.1715\n",
      "26/26 [==============================] - 5s 136ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 192ms/step - loss: 1.2584 - sparse_categorical_accuracy: 0.6543 - sparse_categorical_crossentropy: 1.2584 - val_loss: 0.8140 - val_sparse_categorical_accuracy: 0.7402 - val_sparse_categorical_crossentropy: 0.8140 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.5788 - sparse_categorical_accuracy: 0.8253 - sparse_categorical_crossentropy: 0.5788 - val_loss: 0.4815 - val_sparse_categorical_accuracy: 0.8548 - val_sparse_categorical_crossentropy: 0.4815 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.3845 - sparse_categorical_accuracy: 0.8903 - sparse_categorical_crossentropy: 0.3845 - val_loss: 0.3671 - val_sparse_categorical_accuracy: 0.8882 - val_sparse_categorical_crossentropy: 0.3671 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.3219 - sparse_categorical_accuracy: 0.9099 - sparse_categorical_crossentropy: 0.3219 - val_loss: 0.2888 - val_sparse_categorical_accuracy: 0.9175 - val_sparse_categorical_crossentropy: 0.2888 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 18s 179ms/step - loss: 0.2608 - sparse_categorical_accuracy: 0.9274 - sparse_categorical_crossentropy: 0.2608 - val_loss: 0.3224 - val_sparse_categorical_accuracy: 0.9079 - val_sparse_categorical_crossentropy: 0.3224 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.2382 - sparse_categorical_accuracy: 0.9348 - sparse_categorical_crossentropy: 0.2382 - val_loss: 0.2818 - val_sparse_categorical_accuracy: 0.9162 - val_sparse_categorical_crossentropy: 0.2818 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2573 - sparse_categorical_accuracy: 0.9288 - sparse_categorical_crossentropy: 0.2573 - val_loss: 0.2060 - val_sparse_categorical_accuracy: 0.9427 - val_sparse_categorical_crossentropy: 0.2060 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1827 - sparse_categorical_accuracy: 0.9506 - sparse_categorical_crossentropy: 0.1827 - val_loss: 0.1872 - val_sparse_categorical_accuracy: 0.9452 - val_sparse_categorical_crossentropy: 0.1872 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1619 - sparse_categorical_accuracy: 0.9554 - sparse_categorical_crossentropy: 0.1619 - val_loss: 0.1941 - val_sparse_categorical_accuracy: 0.9489 - val_sparse_categorical_crossentropy: 0.1941 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9607 - sparse_categorical_crossentropy: 0.1449 - val_loss: 0.2095 - val_sparse_categorical_accuracy: 0.9447 - val_sparse_categorical_crossentropy: 0.2095 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1254 - sparse_categorical_accuracy: 0.9654 - sparse_categorical_crossentropy: 0.1254 - val_loss: 0.1549 - val_sparse_categorical_accuracy: 0.9576 - val_sparse_categorical_crossentropy: 0.1549 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1304 - sparse_categorical_accuracy: 0.9652 - sparse_categorical_crossentropy: 0.1304 - val_loss: 0.1852 - val_sparse_categorical_accuracy: 0.9503 - val_sparse_categorical_crossentropy: 0.1852 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1322 - sparse_categorical_accuracy: 0.9640 - sparse_categorical_crossentropy: 0.1322 - val_loss: 0.2409 - val_sparse_categorical_accuracy: 0.9452 - val_sparse_categorical_crossentropy: 0.2409 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1261 - sparse_categorical_accuracy: 0.9664 - sparse_categorical_crossentropy: 0.1261\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9664 - sparse_categorical_crossentropy: 0.1262 - val_loss: 0.1710 - val_sparse_categorical_accuracy: 0.9565 - val_sparse_categorical_crossentropy: 0.1710 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9777 - sparse_categorical_crossentropy: 0.0852 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9655 - val_sparse_categorical_crossentropy: 0.1407 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9814 - sparse_categorical_crossentropy: 0.0704 - val_loss: 0.1648 - val_sparse_categorical_accuracy: 0.9625 - val_sparse_categorical_crossentropy: 0.1648 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0613 - sparse_categorical_accuracy: 0.9841 - sparse_categorical_crossentropy: 0.0613 - val_loss: 0.1681 - val_sparse_categorical_accuracy: 0.9621 - val_sparse_categorical_crossentropy: 0.1681 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0568 - sparse_categorical_accuracy: 0.9851 - sparse_categorical_crossentropy: 0.0568\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0568 - sparse_categorical_accuracy: 0.9850 - sparse_categorical_crossentropy: 0.0568 - val_loss: 0.1649 - val_sparse_categorical_accuracy: 0.9647 - val_sparse_categorical_crossentropy: 0.1649 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0477 - sparse_categorical_accuracy: 0.9870 - sparse_categorical_crossentropy: 0.0477 - val_loss: 0.1923 - val_sparse_categorical_accuracy: 0.9653 - val_sparse_categorical_crossentropy: 0.1923 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0392 - sparse_categorical_accuracy: 0.9899 - sparse_categorical_crossentropy: 0.0392 - val_loss: 0.1974 - val_sparse_categorical_accuracy: 0.9667 - val_sparse_categorical_crossentropy: 0.1974 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9886 - sparse_categorical_crossentropy: 0.0439 - val_loss: 0.2072 - val_sparse_categorical_accuracy: 0.9616 - val_sparse_categorical_crossentropy: 0.2072 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0407 - sparse_categorical_accuracy: 0.9897 - sparse_categorical_crossentropy: 0.0407 - val_loss: 0.2046 - val_sparse_categorical_accuracy: 0.9659 - val_sparse_categorical_crossentropy: 0.2046 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0342 - sparse_categorical_accuracy: 0.9909 - sparse_categorical_crossentropy: 0.0342\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9909 - sparse_categorical_crossentropy: 0.0342 - val_loss: 0.2155 - val_sparse_categorical_accuracy: 0.9653 - val_sparse_categorical_crossentropy: 0.2155 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9918 - sparse_categorical_crossentropy: 0.0314 - val_loss: 0.2336 - val_sparse_categorical_accuracy: 0.9635 - val_sparse_categorical_crossentropy: 0.2336 - lr: 0.0012\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0277 - sparse_categorical_accuracy: 0.9924 - sparse_categorical_crossentropy: 0.0277 - val_loss: 0.2344 - val_sparse_categorical_accuracy: 0.9661 - val_sparse_categorical_crossentropy: 0.2344 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 132ms/step - loss: 0.1898 - sparse_categorical_accuracy: 0.9676 - sparse_categorical_crossentropy: 0.1898\n",
      "26/26 [==============================] - 5s 130ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 192ms/step - loss: 1.1139 - sparse_categorical_accuracy: 0.6857 - sparse_categorical_crossentropy: 1.1139 - val_loss: 0.8902 - val_sparse_categorical_accuracy: 0.7064 - val_sparse_categorical_crossentropy: 0.8902 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.5791 - sparse_categorical_accuracy: 0.8245 - sparse_categorical_crossentropy: 0.5791 - val_loss: 0.3753 - val_sparse_categorical_accuracy: 0.8861 - val_sparse_categorical_crossentropy: 0.3753 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.4005 - sparse_categorical_accuracy: 0.8827 - sparse_categorical_crossentropy: 0.4005 - val_loss: 0.3161 - val_sparse_categorical_accuracy: 0.9056 - val_sparse_categorical_crossentropy: 0.3161 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.3198 - sparse_categorical_accuracy: 0.9095 - sparse_categorical_crossentropy: 0.3198 - val_loss: 0.2594 - val_sparse_categorical_accuracy: 0.9203 - val_sparse_categorical_crossentropy: 0.2594 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2605 - sparse_categorical_accuracy: 0.9266 - sparse_categorical_crossentropy: 0.2605 - val_loss: 0.2390 - val_sparse_categorical_accuracy: 0.9321 - val_sparse_categorical_crossentropy: 0.2390 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.2195 - sparse_categorical_accuracy: 0.9398 - sparse_categorical_crossentropy: 0.2195 - val_loss: 0.1941 - val_sparse_categorical_accuracy: 0.9421 - val_sparse_categorical_crossentropy: 0.1941 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9394 - sparse_categorical_crossentropy: 0.2163 - val_loss: 0.2014 - val_sparse_categorical_accuracy: 0.9437 - val_sparse_categorical_crossentropy: 0.2014 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.1797 - sparse_categorical_accuracy: 0.9515 - sparse_categorical_crossentropy: 0.1797 - val_loss: 0.1863 - val_sparse_categorical_accuracy: 0.9498 - val_sparse_categorical_crossentropy: 0.1863 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1710 - sparse_categorical_accuracy: 0.9523 - sparse_categorical_crossentropy: 0.1710 - val_loss: 0.1804 - val_sparse_categorical_accuracy: 0.9513 - val_sparse_categorical_crossentropy: 0.1804 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9588 - sparse_categorical_crossentropy: 0.1508 - val_loss: 0.1601 - val_sparse_categorical_accuracy: 0.9575 - val_sparse_categorical_crossentropy: 0.1601 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9629 - sparse_categorical_crossentropy: 0.1350 - val_loss: 0.1840 - val_sparse_categorical_accuracy: 0.9526 - val_sparse_categorical_crossentropy: 0.1840 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.1214 - sparse_categorical_accuracy: 0.9663 - sparse_categorical_crossentropy: 0.1214 - val_loss: 0.1701 - val_sparse_categorical_accuracy: 0.9555 - val_sparse_categorical_crossentropy: 0.1701 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1079 - sparse_categorical_accuracy: 0.9705 - sparse_categorical_crossentropy: 0.1079\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9705 - sparse_categorical_crossentropy: 0.1079 - val_loss: 0.2102 - val_sparse_categorical_accuracy: 0.9401 - val_sparse_categorical_crossentropy: 0.2102 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9734 - sparse_categorical_crossentropy: 0.0982 - val_loss: 0.1352 - val_sparse_categorical_accuracy: 0.9656 - val_sparse_categorical_crossentropy: 0.1352 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9821 - sparse_categorical_crossentropy: 0.0684 - val_loss: 0.1389 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.1389 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9848 - sparse_categorical_crossentropy: 0.0556 - val_loss: 0.1455 - val_sparse_categorical_accuracy: 0.9688 - val_sparse_categorical_crossentropy: 0.1455 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9755 - sparse_categorical_crossentropy: 0.0894 - val_loss: 0.1389 - val_sparse_categorical_accuracy: 0.9659 - val_sparse_categorical_crossentropy: 0.1389 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9834 - sparse_categorical_crossentropy: 0.0625 - val_loss: 0.1513 - val_sparse_categorical_accuracy: 0.9665 - val_sparse_categorical_crossentropy: 0.1513 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0546 - sparse_categorical_accuracy: 0.9854 - sparse_categorical_crossentropy: 0.0546\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9854 - sparse_categorical_crossentropy: 0.0546 - val_loss: 0.1393 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.1393 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9883 - sparse_categorical_crossentropy: 0.0446 - val_loss: 0.1338 - val_sparse_categorical_accuracy: 0.9722 - val_sparse_categorical_crossentropy: 0.1338 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9896 - sparse_categorical_crossentropy: 0.0388 - val_loss: 0.1386 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1386 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9905 - sparse_categorical_crossentropy: 0.0362 - val_loss: 0.1554 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1554 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0333 - sparse_categorical_accuracy: 0.9908 - sparse_categorical_crossentropy: 0.0333\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0333 - sparse_categorical_accuracy: 0.9908 - sparse_categorical_crossentropy: 0.0333 - val_loss: 0.1605 - val_sparse_categorical_accuracy: 0.9708 - val_sparse_categorical_crossentropy: 0.1605 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.0297 - sparse_categorical_accuracy: 0.9919 - sparse_categorical_crossentropy: 0.0297 - val_loss: 0.1662 - val_sparse_categorical_accuracy: 0.9705 - val_sparse_categorical_crossentropy: 0.1662 - lr: 0.0012\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9928 - sparse_categorical_crossentropy: 0.0273 - val_loss: 0.1726 - val_sparse_categorical_accuracy: 0.9714 - val_sparse_categorical_crossentropy: 0.1726 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 134ms/step - loss: 0.1835 - sparse_categorical_accuracy: 0.9648 - sparse_categorical_crossentropy: 0.1835\n",
      "26/26 [==============================] - 5s 134ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 192ms/step - loss: 1.2280 - sparse_categorical_accuracy: 0.6616 - sparse_categorical_crossentropy: 1.2280 - val_loss: 0.8070 - val_sparse_categorical_accuracy: 0.7402 - val_sparse_categorical_crossentropy: 0.8070 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.6802 - sparse_categorical_accuracy: 0.7921 - sparse_categorical_crossentropy: 0.6802 - val_loss: 0.4837 - val_sparse_categorical_accuracy: 0.8494 - val_sparse_categorical_crossentropy: 0.4837 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.4533 - sparse_categorical_accuracy: 0.8682 - sparse_categorical_crossentropy: 0.4533 - val_loss: 0.3372 - val_sparse_categorical_accuracy: 0.8944 - val_sparse_categorical_crossentropy: 0.3372 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.3486 - sparse_categorical_accuracy: 0.9005 - sparse_categorical_crossentropy: 0.3486 - val_loss: 0.2629 - val_sparse_categorical_accuracy: 0.9255 - val_sparse_categorical_crossentropy: 0.2629 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2912 - sparse_categorical_accuracy: 0.9185 - sparse_categorical_crossentropy: 0.2912 - val_loss: 0.2166 - val_sparse_categorical_accuracy: 0.9334 - val_sparse_categorical_crossentropy: 0.2166 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2440 - sparse_categorical_accuracy: 0.9329 - sparse_categorical_crossentropy: 0.2440 - val_loss: 0.2312 - val_sparse_categorical_accuracy: 0.9300 - val_sparse_categorical_crossentropy: 0.2312 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2433 - sparse_categorical_accuracy: 0.9326 - sparse_categorical_crossentropy: 0.2433 - val_loss: 0.1800 - val_sparse_categorical_accuracy: 0.9512 - val_sparse_categorical_crossentropy: 0.1800 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1935 - sparse_categorical_accuracy: 0.9488 - sparse_categorical_crossentropy: 0.1935 - val_loss: 0.3196 - val_sparse_categorical_accuracy: 0.9140 - val_sparse_categorical_crossentropy: 0.3196 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2352 - sparse_categorical_accuracy: 0.9351 - sparse_categorical_crossentropy: 0.2352 - val_loss: 0.2183 - val_sparse_categorical_accuracy: 0.9420 - val_sparse_categorical_crossentropy: 0.2183 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1930 - sparse_categorical_accuracy: 0.9482 - sparse_categorical_crossentropy: 0.1930 - val_loss: 0.1748 - val_sparse_categorical_accuracy: 0.9527 - val_sparse_categorical_crossentropy: 0.1748 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1540 - sparse_categorical_accuracy: 0.9593 - sparse_categorical_crossentropy: 0.1540 - val_loss: 0.1743 - val_sparse_categorical_accuracy: 0.9541 - val_sparse_categorical_crossentropy: 0.1743 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1612 - sparse_categorical_accuracy: 0.9560 - sparse_categorical_crossentropy: 0.1612 - val_loss: 0.1571 - val_sparse_categorical_accuracy: 0.9559 - val_sparse_categorical_crossentropy: 0.1571 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1284 - sparse_categorical_accuracy: 0.9646 - sparse_categorical_crossentropy: 0.1284 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9584 - val_sparse_categorical_crossentropy: 0.1684 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1199 - sparse_categorical_accuracy: 0.9680 - sparse_categorical_crossentropy: 0.1199 - val_loss: 0.1642 - val_sparse_categorical_accuracy: 0.9584 - val_sparse_categorical_crossentropy: 0.1642 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2380 - sparse_categorical_accuracy: 0.9362 - sparse_categorical_crossentropy: 0.2380 - val_loss: 0.1966 - val_sparse_categorical_accuracy: 0.9478 - val_sparse_categorical_crossentropy: 0.1966 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1596 - sparse_categorical_accuracy: 0.9562 - sparse_categorical_crossentropy: 0.1596 - val_loss: 0.1625 - val_sparse_categorical_accuracy: 0.9590 - val_sparse_categorical_crossentropy: 0.1625 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1208 - sparse_categorical_accuracy: 0.9678 - sparse_categorical_crossentropy: 0.1208 - val_loss: 0.1631 - val_sparse_categorical_accuracy: 0.9573 - val_sparse_categorical_crossentropy: 0.1631 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.1407 - sparse_categorical_accuracy: 0.9624 - sparse_categorical_crossentropy: 0.1407 - val_loss: 0.1554 - val_sparse_categorical_accuracy: 0.9599 - val_sparse_categorical_crossentropy: 0.1554 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9728 - sparse_categorical_crossentropy: 0.1032 - val_loss: 0.1442 - val_sparse_categorical_accuracy: 0.9659 - val_sparse_categorical_crossentropy: 0.1442 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9760 - sparse_categorical_crossentropy: 0.0919 - val_loss: 0.1511 - val_sparse_categorical_accuracy: 0.9641 - val_sparse_categorical_crossentropy: 0.1511 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9740 - sparse_categorical_crossentropy: 0.0970 - val_loss: 0.1568 - val_sparse_categorical_accuracy: 0.9625 - val_sparse_categorical_crossentropy: 0.1568 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0831 - sparse_categorical_accuracy: 0.9781 - sparse_categorical_crossentropy: 0.0831\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9781 - sparse_categorical_crossentropy: 0.0831 - val_loss: 0.1885 - val_sparse_categorical_accuracy: 0.9601 - val_sparse_categorical_crossentropy: 0.1885 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9835 - sparse_categorical_crossentropy: 0.0625 - val_loss: 0.1426 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1426 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9866 - sparse_categorical_crossentropy: 0.0497 - val_loss: 0.1440 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1440 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0430 - sparse_categorical_accuracy: 0.9888 - sparse_categorical_crossentropy: 0.0430 - val_loss: 0.1569 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.1569 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0386 - sparse_categorical_accuracy: 0.9899 - sparse_categorical_crossentropy: 0.0386 - val_loss: 0.1701 - val_sparse_categorical_accuracy: 0.9690 - val_sparse_categorical_crossentropy: 0.1701 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0408 - sparse_categorical_accuracy: 0.9894 - sparse_categorical_crossentropy: 0.0408 - val_loss: 0.1886 - val_sparse_categorical_accuracy: 0.9627 - val_sparse_categorical_crossentropy: 0.1886 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0428 - sparse_categorical_accuracy: 0.9885 - sparse_categorical_crossentropy: 0.0428\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9884 - sparse_categorical_crossentropy: 0.0429 - val_loss: 0.1589 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1589 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0341 - sparse_categorical_accuracy: 0.9912 - sparse_categorical_crossentropy: 0.0341 - val_loss: 0.1749 - val_sparse_categorical_accuracy: 0.9705 - val_sparse_categorical_crossentropy: 0.1749 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0281 - sparse_categorical_accuracy: 0.9924 - sparse_categorical_crossentropy: 0.0281 - val_loss: 0.1841 - val_sparse_categorical_accuracy: 0.9699 - val_sparse_categorical_crossentropy: 0.1841 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9925 - sparse_categorical_crossentropy: 0.0275 - val_loss: 0.2003 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.2003 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0271 - sparse_categorical_accuracy: 0.9926 - sparse_categorical_crossentropy: 0.0271\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0271 - sparse_categorical_accuracy: 0.9926 - sparse_categorical_crossentropy: 0.0271 - val_loss: 0.2097 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.2097 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0260 - sparse_categorical_accuracy: 0.9928 - sparse_categorical_crossentropy: 0.0260 - val_loss: 0.2093 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.2093 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0228 - sparse_categorical_accuracy: 0.9935 - sparse_categorical_crossentropy: 0.0228 - val_loss: 0.2142 - val_sparse_categorical_accuracy: 0.9707 - val_sparse_categorical_crossentropy: 0.2142 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0226 - sparse_categorical_accuracy: 0.9939 - sparse_categorical_crossentropy: 0.0226 - val_loss: 0.2383 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.2383 - lr: 0.0012\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0234 - sparse_categorical_accuracy: 0.9935 - sparse_categorical_crossentropy: 0.0234 - val_loss: 0.2287 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.2287 - lr: 0.0012\n",
      "Epoch 37/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0219 - sparse_categorical_accuracy: 0.9937 - sparse_categorical_crossentropy: 0.0219\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9937 - sparse_categorical_crossentropy: 0.0219 - val_loss: 0.2403 - val_sparse_categorical_accuracy: 0.9688 - val_sparse_categorical_crossentropy: 0.2403 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9941 - sparse_categorical_crossentropy: 0.0209 - val_loss: 0.2421 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.2421 - lr: 6.2500e-04\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9943 - sparse_categorical_crossentropy: 0.0203 - val_loss: 0.2482 - val_sparse_categorical_accuracy: 0.9698 - val_sparse_categorical_crossentropy: 0.2482 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.2685 - sparse_categorical_accuracy: 0.9662 - sparse_categorical_crossentropy: 0.2685\n",
      "26/26 [==============================] - 5s 139ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 191ms/step - loss: 1.4932 - sparse_categorical_accuracy: 0.6189 - sparse_categorical_crossentropy: 1.4932 - val_loss: 1.7237 - val_sparse_categorical_accuracy: 0.6301 - val_sparse_categorical_crossentropy: 1.7237 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 18s 178ms/step - loss: 0.9456 - sparse_categorical_accuracy: 0.6877 - sparse_categorical_crossentropy: 0.9456 - val_loss: 1.9541 - val_sparse_categorical_accuracy: 0.5087 - val_sparse_categorical_crossentropy: 1.9541 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 18s 180ms/step - loss: 0.6427 - sparse_categorical_accuracy: 0.7766 - sparse_categorical_crossentropy: 0.6427 - val_loss: 2.0172 - val_sparse_categorical_accuracy: 0.4927 - val_sparse_categorical_crossentropy: 2.0172 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 18s 179ms/step - loss: 0.5158 - sparse_categorical_accuracy: 0.8352 - sparse_categorical_crossentropy: 0.5158 - val_loss: 1.2042 - val_sparse_categorical_accuracy: 0.6869 - val_sparse_categorical_crossentropy: 1.2042 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.4058 - sparse_categorical_accuracy: 0.8816 - sparse_categorical_crossentropy: 0.4058 - val_loss: 0.5835 - val_sparse_categorical_accuracy: 0.8365 - val_sparse_categorical_crossentropy: 0.5835 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.3218 - sparse_categorical_accuracy: 0.9096 - sparse_categorical_crossentropy: 0.3218 - val_loss: 0.3038 - val_sparse_categorical_accuracy: 0.9175 - val_sparse_categorical_crossentropy: 0.3038 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.3068 - sparse_categorical_accuracy: 0.9148 - sparse_categorical_crossentropy: 0.3068 - val_loss: 0.3744 - val_sparse_categorical_accuracy: 0.8996 - val_sparse_categorical_crossentropy: 0.3744 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2565 - sparse_categorical_accuracy: 0.9309 - sparse_categorical_crossentropy: 0.2565 - val_loss: 0.4567 - val_sparse_categorical_accuracy: 0.8752 - val_sparse_categorical_crossentropy: 0.4567 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2219 - sparse_categorical_accuracy: 0.9407 - sparse_categorical_crossentropy: 0.2219\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2219 - sparse_categorical_accuracy: 0.9407 - sparse_categorical_crossentropy: 0.2219 - val_loss: 0.3527 - val_sparse_categorical_accuracy: 0.9105 - val_sparse_categorical_crossentropy: 0.3527 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 18s 179ms/step - loss: 0.1753 - sparse_categorical_accuracy: 0.9533 - sparse_categorical_crossentropy: 0.1753 - val_loss: 0.2089 - val_sparse_categorical_accuracy: 0.9483 - val_sparse_categorical_crossentropy: 0.2089 - lr: 0.0050\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1446 - sparse_categorical_accuracy: 0.9618 - sparse_categorical_crossentropy: 0.1446 - val_loss: 0.2616 - val_sparse_categorical_accuracy: 0.9441 - val_sparse_categorical_crossentropy: 0.2616 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 18s 179ms/step - loss: 0.1283 - sparse_categorical_accuracy: 0.9671 - sparse_categorical_crossentropy: 0.1283 - val_loss: 0.2060 - val_sparse_categorical_accuracy: 0.9567 - val_sparse_categorical_crossentropy: 0.2060 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 18s 179ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9662 - sparse_categorical_crossentropy: 0.1301 - val_loss: 0.1686 - val_sparse_categorical_accuracy: 0.9633 - val_sparse_categorical_crossentropy: 0.1686 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.1171 - sparse_categorical_accuracy: 0.9697 - sparse_categorical_crossentropy: 0.1171 - val_loss: 0.1652 - val_sparse_categorical_accuracy: 0.9630 - val_sparse_categorical_crossentropy: 0.1652 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9730 - sparse_categorical_crossentropy: 0.1056 - val_loss: 0.2978 - val_sparse_categorical_accuracy: 0.9372 - val_sparse_categorical_crossentropy: 0.2978 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1063 - sparse_categorical_accuracy: 0.9730 - sparse_categorical_crossentropy: 0.1063\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1062 - sparse_categorical_accuracy: 0.9730 - sparse_categorical_crossentropy: 0.1062 - val_loss: 0.1642 - val_sparse_categorical_accuracy: 0.9621 - val_sparse_categorical_crossentropy: 0.1642 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.0854 - sparse_categorical_accuracy: 0.9782 - sparse_categorical_crossentropy: 0.0854 - val_loss: 0.1840 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1840 - lr: 0.0025\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9810 - sparse_categorical_crossentropy: 0.0727 - val_loss: 0.2024 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.2024 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9823 - sparse_categorical_crossentropy: 0.0708 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9632 - val_sparse_categorical_crossentropy: 0.2099 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0697 - sparse_categorical_accuracy: 0.9823 - sparse_categorical_crossentropy: 0.0697\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9823 - sparse_categorical_crossentropy: 0.0697 - val_loss: 0.2438 - val_sparse_categorical_accuracy: 0.9615 - val_sparse_categorical_crossentropy: 0.2438 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.0597 - sparse_categorical_accuracy: 0.9846 - sparse_categorical_crossentropy: 0.0597 - val_loss: 0.2074 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.2074 - lr: 0.0012\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.0547 - sparse_categorical_accuracy: 0.9851 - sparse_categorical_crossentropy: 0.0547 - val_loss: 0.2339 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.2339 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 0.1981 - sparse_categorical_accuracy: 0.9660 - sparse_categorical_crossentropy: 0.1981\n",
      "26/26 [==============================] - 5s 140ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 189ms/step - loss: 1.5187 - sparse_categorical_accuracy: 0.6170 - sparse_categorical_crossentropy: 1.5187 - val_loss: 1.7042 - val_sparse_categorical_accuracy: 0.6301 - val_sparse_categorical_crossentropy: 1.7042 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 1.1163 - sparse_categorical_accuracy: 0.6564 - sparse_categorical_crossentropy: 1.1163 - val_loss: 1.0260 - val_sparse_categorical_accuracy: 0.6700 - val_sparse_categorical_crossentropy: 1.0260 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.7672 - sparse_categorical_accuracy: 0.7331 - sparse_categorical_crossentropy: 0.7672 - val_loss: 0.5913 - val_sparse_categorical_accuracy: 0.7812 - val_sparse_categorical_crossentropy: 0.5913 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.6127 - sparse_categorical_accuracy: 0.7950 - sparse_categorical_crossentropy: 0.6127 - val_loss: 0.3931 - val_sparse_categorical_accuracy: 0.8681 - val_sparse_categorical_crossentropy: 0.3931 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.4575 - sparse_categorical_accuracy: 0.8547 - sparse_categorical_crossentropy: 0.4575 - val_loss: 0.4847 - val_sparse_categorical_accuracy: 0.8586 - val_sparse_categorical_crossentropy: 0.4847 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.3884 - sparse_categorical_accuracy: 0.8887 - sparse_categorical_crossentropy: 0.3884 - val_loss: 0.3023 - val_sparse_categorical_accuracy: 0.9159 - val_sparse_categorical_crossentropy: 0.3023 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.3423 - sparse_categorical_accuracy: 0.9054 - sparse_categorical_crossentropy: 0.3423 - val_loss: 0.3222 - val_sparse_categorical_accuracy: 0.9060 - val_sparse_categorical_crossentropy: 0.3222 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.3444 - sparse_categorical_accuracy: 0.9028 - sparse_categorical_crossentropy: 0.3444 - val_loss: 0.2547 - val_sparse_categorical_accuracy: 0.9341 - val_sparse_categorical_crossentropy: 0.2547 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.3117 - sparse_categorical_accuracy: 0.9167 - sparse_categorical_crossentropy: 0.3117 - val_loss: 0.3863 - val_sparse_categorical_accuracy: 0.8945 - val_sparse_categorical_crossentropy: 0.3863 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2637 - sparse_categorical_accuracy: 0.9293 - sparse_categorical_crossentropy: 0.2637 - val_loss: 0.2321 - val_sparse_categorical_accuracy: 0.9364 - val_sparse_categorical_crossentropy: 0.2321 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2349 - sparse_categorical_accuracy: 0.9370 - sparse_categorical_crossentropy: 0.2349 - val_loss: 0.4292 - val_sparse_categorical_accuracy: 0.8941 - val_sparse_categorical_crossentropy: 0.4292 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2352 - sparse_categorical_accuracy: 0.9382 - sparse_categorical_crossentropy: 0.2352 - val_loss: 0.2010 - val_sparse_categorical_accuracy: 0.9521 - val_sparse_categorical_crossentropy: 0.2010 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2123 - sparse_categorical_accuracy: 0.9443 - sparse_categorical_crossentropy: 0.2123 - val_loss: 0.2352 - val_sparse_categorical_accuracy: 0.9412 - val_sparse_categorical_crossentropy: 0.2352 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1983 - sparse_categorical_accuracy: 0.9479 - sparse_categorical_crossentropy: 0.1983 - val_loss: 0.1984 - val_sparse_categorical_accuracy: 0.9499 - val_sparse_categorical_crossentropy: 0.1984 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2078 - sparse_categorical_accuracy: 0.9455 - sparse_categorical_crossentropy: 0.2078\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2079 - sparse_categorical_accuracy: 0.9455 - sparse_categorical_crossentropy: 0.2079 - val_loss: 0.2379 - val_sparse_categorical_accuracy: 0.9450 - val_sparse_categorical_crossentropy: 0.2379 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1699 - sparse_categorical_accuracy: 0.9557 - sparse_categorical_crossentropy: 0.1699 - val_loss: 0.1775 - val_sparse_categorical_accuracy: 0.9622 - val_sparse_categorical_crossentropy: 0.1775 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1284 - sparse_categorical_accuracy: 0.9664 - sparse_categorical_crossentropy: 0.1284 - val_loss: 0.1793 - val_sparse_categorical_accuracy: 0.9607 - val_sparse_categorical_crossentropy: 0.1793 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9690 - sparse_categorical_crossentropy: 0.1192 - val_loss: 0.1751 - val_sparse_categorical_accuracy: 0.9630 - val_sparse_categorical_crossentropy: 0.1751 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9718 - sparse_categorical_crossentropy: 0.1073 - val_loss: 0.1735 - val_sparse_categorical_accuracy: 0.9656 - val_sparse_categorical_crossentropy: 0.1735 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9662 - sparse_categorical_crossentropy: 0.1338 - val_loss: 0.1915 - val_sparse_categorical_accuracy: 0.9595 - val_sparse_categorical_crossentropy: 0.1915 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9717 - sparse_categorical_crossentropy: 0.1089 - val_loss: 0.1985 - val_sparse_categorical_accuracy: 0.9605 - val_sparse_categorical_crossentropy: 0.1985 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1656 - sparse_categorical_accuracy: 0.9569 - sparse_categorical_crossentropy: 0.1656\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.1655 - sparse_categorical_accuracy: 0.9569 - sparse_categorical_crossentropy: 0.1655 - val_loss: 0.1845 - val_sparse_categorical_accuracy: 0.9593 - val_sparse_categorical_crossentropy: 0.1845 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9752 - sparse_categorical_crossentropy: 0.0939 - val_loss: 0.1777 - val_sparse_categorical_accuracy: 0.9650 - val_sparse_categorical_crossentropy: 0.1777 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9775 - sparse_categorical_crossentropy: 0.0846 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9661 - val_sparse_categorical_crossentropy: 0.1932 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9812 - sparse_categorical_crossentropy: 0.0724 - val_loss: 0.2073 - val_sparse_categorical_accuracy: 0.9661 - val_sparse_categorical_crossentropy: 0.2073 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9822 - sparse_categorical_crossentropy: 0.0694 - val_loss: 0.2356 - val_sparse_categorical_accuracy: 0.9625 - val_sparse_categorical_crossentropy: 0.2356 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9809 - sparse_categorical_crossentropy: 0.0732 - val_loss: 0.2221 - val_sparse_categorical_accuracy: 0.9673 - val_sparse_categorical_crossentropy: 0.2221 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9829 - sparse_categorical_crossentropy: 0.0678 - val_loss: 0.2077 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.2077 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0609 - sparse_categorical_accuracy: 0.9848 - sparse_categorical_crossentropy: 0.0609 - val_loss: 0.2275 - val_sparse_categorical_accuracy: 0.9682 - val_sparse_categorical_crossentropy: 0.2275 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9846 - sparse_categorical_crossentropy: 0.0604 - val_loss: 0.2343 - val_sparse_categorical_accuracy: 0.9655 - val_sparse_categorical_crossentropy: 0.2343 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0637 - sparse_categorical_accuracy: 0.9837 - sparse_categorical_crossentropy: 0.0637\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9837 - sparse_categorical_crossentropy: 0.0637 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.2121 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9863 - sparse_categorical_crossentropy: 0.0535 - val_loss: 0.2298 - val_sparse_categorical_accuracy: 0.9690 - val_sparse_categorical_crossentropy: 0.2298 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9877 - sparse_categorical_crossentropy: 0.0480 - val_loss: 0.2454 - val_sparse_categorical_accuracy: 0.9699 - val_sparse_categorical_crossentropy: 0.2454 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9881 - sparse_categorical_crossentropy: 0.0457 - val_loss: 0.2675 - val_sparse_categorical_accuracy: 0.9701 - val_sparse_categorical_crossentropy: 0.2675 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0459 - sparse_categorical_accuracy: 0.9882 - sparse_categorical_crossentropy: 0.0459 - val_loss: 0.2691 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.2691 - lr: 0.0012\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0445 - sparse_categorical_accuracy: 0.9878 - sparse_categorical_crossentropy: 0.0445 - val_loss: 0.2829 - val_sparse_categorical_accuracy: 0.9691 - val_sparse_categorical_crossentropy: 0.2829 - lr: 0.0012\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9889 - sparse_categorical_crossentropy: 0.0425 - val_loss: 0.2839 - val_sparse_categorical_accuracy: 0.9701 - val_sparse_categorical_crossentropy: 0.2839 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9888 - sparse_categorical_crossentropy: 0.0452 - val_loss: 0.2910 - val_sparse_categorical_accuracy: 0.9719 - val_sparse_categorical_crossentropy: 0.2910 - lr: 0.0012\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9887 - sparse_categorical_crossentropy: 0.0437 - val_loss: 0.2936 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.2936 - lr: 0.0012\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0402 - sparse_categorical_accuracy: 0.9895 - sparse_categorical_crossentropy: 0.0402 - val_loss: 0.3529 - val_sparse_categorical_accuracy: 0.9656 - val_sparse_categorical_crossentropy: 0.3529 - lr: 0.0012\n",
      "Epoch 41/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0545 - sparse_categorical_accuracy: 0.9862 - sparse_categorical_crossentropy: 0.0545\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.9862 - sparse_categorical_crossentropy: 0.0545 - val_loss: 0.3058 - val_sparse_categorical_accuracy: 0.9674 - val_sparse_categorical_crossentropy: 0.3058 - lr: 0.0012\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9882 - sparse_categorical_crossentropy: 0.0452 - val_loss: 0.2671 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.2671 - lr: 6.2500e-04\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9889 - sparse_categorical_crossentropy: 0.0420 - val_loss: 0.2831 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.2831 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.3698 - sparse_categorical_accuracy: 0.9638 - sparse_categorical_crossentropy: 0.3698\n",
      "26/26 [==============================] - 5s 136ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 189ms/step - loss: 1.3934 - sparse_categorical_accuracy: 0.6221 - sparse_categorical_crossentropy: 1.3934 - val_loss: 1.3364 - val_sparse_categorical_accuracy: 0.6192 - val_sparse_categorical_crossentropy: 1.3364 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.8892 - sparse_categorical_accuracy: 0.7195 - sparse_categorical_crossentropy: 0.8892 - val_loss: 1.2279 - val_sparse_categorical_accuracy: 0.6393 - val_sparse_categorical_crossentropy: 1.2279 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.7116 - sparse_categorical_accuracy: 0.7740 - sparse_categorical_crossentropy: 0.7116 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.7887 - val_sparse_categorical_crossentropy: 0.6805 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.5463 - sparse_categorical_accuracy: 0.8301 - sparse_categorical_crossentropy: 0.5463 - val_loss: 0.4205 - val_sparse_categorical_accuracy: 0.8709 - val_sparse_categorical_crossentropy: 0.4205 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.5250 - sparse_categorical_accuracy: 0.8408 - sparse_categorical_crossentropy: 0.5250 - val_loss: 0.3773 - val_sparse_categorical_accuracy: 0.8727 - val_sparse_categorical_crossentropy: 0.3773 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.4155 - sparse_categorical_accuracy: 0.8746 - sparse_categorical_crossentropy: 0.4155 - val_loss: 0.3228 - val_sparse_categorical_accuracy: 0.8936 - val_sparse_categorical_crossentropy: 0.3228 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.3557 - sparse_categorical_accuracy: 0.8883 - sparse_categorical_crossentropy: 0.3557 - val_loss: 0.3101 - val_sparse_categorical_accuracy: 0.9019 - val_sparse_categorical_crossentropy: 0.3101 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.3245 - sparse_categorical_accuracy: 0.8980 - sparse_categorical_crossentropy: 0.3245 - val_loss: 0.3562 - val_sparse_categorical_accuracy: 0.8968 - val_sparse_categorical_crossentropy: 0.3562 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.2967 - sparse_categorical_accuracy: 0.9094 - sparse_categorical_crossentropy: 0.2967 - val_loss: 0.2642 - val_sparse_categorical_accuracy: 0.9288 - val_sparse_categorical_crossentropy: 0.2642 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2811 - sparse_categorical_accuracy: 0.9181 - sparse_categorical_crossentropy: 0.2811 - val_loss: 0.2721 - val_sparse_categorical_accuracy: 0.9192 - val_sparse_categorical_crossentropy: 0.2721 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2923 - sparse_categorical_accuracy: 0.9181 - sparse_categorical_crossentropy: 0.2923 - val_loss: 0.2558 - val_sparse_categorical_accuracy: 0.9294 - val_sparse_categorical_crossentropy: 0.2558 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2561 - sparse_categorical_accuracy: 0.9300 - sparse_categorical_crossentropy: 0.2561 - val_loss: 0.3078 - val_sparse_categorical_accuracy: 0.9133 - val_sparse_categorical_crossentropy: 0.3078 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2622 - sparse_categorical_accuracy: 0.9302 - sparse_categorical_crossentropy: 0.2622 - val_loss: 0.1904 - val_sparse_categorical_accuracy: 0.9519 - val_sparse_categorical_crossentropy: 0.1904 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2069 - sparse_categorical_accuracy: 0.9457 - sparse_categorical_crossentropy: 0.2069 - val_loss: 0.2227 - val_sparse_categorical_accuracy: 0.9499 - val_sparse_categorical_crossentropy: 0.2227 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.2088 - sparse_categorical_accuracy: 0.9452 - sparse_categorical_crossentropy: 0.2088 - val_loss: 0.2057 - val_sparse_categorical_accuracy: 0.9546 - val_sparse_categorical_crossentropy: 0.2057 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1913 - sparse_categorical_accuracy: 0.9501 - sparse_categorical_crossentropy: 0.1913 - val_loss: 0.2330 - val_sparse_categorical_accuracy: 0.9455 - val_sparse_categorical_crossentropy: 0.2330 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2154 - sparse_categorical_accuracy: 0.9432 - sparse_categorical_crossentropy: 0.2154 - val_loss: 0.1771 - val_sparse_categorical_accuracy: 0.9538 - val_sparse_categorical_crossentropy: 0.1771 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2046 - sparse_categorical_accuracy: 0.9472 - sparse_categorical_crossentropy: 0.2046\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2047 - sparse_categorical_accuracy: 0.9471 - sparse_categorical_crossentropy: 0.2047 - val_loss: 0.2203 - val_sparse_categorical_accuracy: 0.9470 - val_sparse_categorical_crossentropy: 0.2203 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9601 - sparse_categorical_crossentropy: 0.1523 - val_loss: 0.1888 - val_sparse_categorical_accuracy: 0.9581 - val_sparse_categorical_crossentropy: 0.1888 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.1272 - sparse_categorical_accuracy: 0.9672 - sparse_categorical_crossentropy: 0.1272 - val_loss: 0.1819 - val_sparse_categorical_accuracy: 0.9621 - val_sparse_categorical_crossentropy: 0.1819 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9709 - sparse_categorical_crossentropy: 0.1106 - val_loss: 0.1920 - val_sparse_categorical_accuracy: 0.9590 - val_sparse_categorical_crossentropy: 0.1920 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9714 - sparse_categorical_crossentropy: 0.1071 - val_loss: 0.1933 - val_sparse_categorical_accuracy: 0.9622 - val_sparse_categorical_crossentropy: 0.1933 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0947 - sparse_categorical_accuracy: 0.9749 - sparse_categorical_crossentropy: 0.0947 - val_loss: 0.1933 - val_sparse_categorical_accuracy: 0.9642 - val_sparse_categorical_crossentropy: 0.1933 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0929 - sparse_categorical_accuracy: 0.9760 - sparse_categorical_crossentropy: 0.0929 - val_loss: 0.1913 - val_sparse_categorical_accuracy: 0.9641 - val_sparse_categorical_crossentropy: 0.1913 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9754 - sparse_categorical_crossentropy: 0.0935 - val_loss: 0.2165 - val_sparse_categorical_accuracy: 0.9630 - val_sparse_categorical_crossentropy: 0.2165 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0991 - sparse_categorical_accuracy: 0.9745 - sparse_categorical_crossentropy: 0.0991\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9746 - sparse_categorical_crossentropy: 0.0991 - val_loss: 0.2059 - val_sparse_categorical_accuracy: 0.9610 - val_sparse_categorical_crossentropy: 0.2059 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9790 - sparse_categorical_crossentropy: 0.0817 - val_loss: 0.1925 - val_sparse_categorical_accuracy: 0.9674 - val_sparse_categorical_crossentropy: 0.1925 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9831 - sparse_categorical_crossentropy: 0.0670 - val_loss: 0.1828 - val_sparse_categorical_accuracy: 0.9656 - val_sparse_categorical_crossentropy: 0.1828 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9837 - sparse_categorical_crossentropy: 0.0618 - val_loss: 0.2214 - val_sparse_categorical_accuracy: 0.9668 - val_sparse_categorical_crossentropy: 0.2214 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0575 - sparse_categorical_accuracy: 0.9848 - sparse_categorical_crossentropy: 0.0575\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9848 - sparse_categorical_crossentropy: 0.0575 - val_loss: 0.2423 - val_sparse_categorical_accuracy: 0.9628 - val_sparse_categorical_crossentropy: 0.2423 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0557 - sparse_categorical_accuracy: 0.9857 - sparse_categorical_crossentropy: 0.0557 - val_loss: 0.2323 - val_sparse_categorical_accuracy: 0.9662 - val_sparse_categorical_crossentropy: 0.2323 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9858 - sparse_categorical_crossentropy: 0.0532 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 0.9639 - val_sparse_categorical_crossentropy: 0.2324 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 136ms/step - loss: 0.2289 - sparse_categorical_accuracy: 0.9618 - sparse_categorical_crossentropy: 0.2289\n",
      "26/26 [==============================] - 5s 134ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 191ms/step - loss: 1.2896 - sparse_categorical_accuracy: 0.6371 - sparse_categorical_crossentropy: 1.2896 - val_loss: 1.3135 - val_sparse_categorical_accuracy: 0.6630 - val_sparse_categorical_crossentropy: 1.3135 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.7624 - sparse_categorical_accuracy: 0.7536 - sparse_categorical_crossentropy: 0.7624 - val_loss: 0.4977 - val_sparse_categorical_accuracy: 0.8402 - val_sparse_categorical_crossentropy: 0.4977 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.5269 - sparse_categorical_accuracy: 0.8382 - sparse_categorical_crossentropy: 0.5269 - val_loss: 0.4050 - val_sparse_categorical_accuracy: 0.8789 - val_sparse_categorical_crossentropy: 0.4050 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.4288 - sparse_categorical_accuracy: 0.8730 - sparse_categorical_crossentropy: 0.4288 - val_loss: 0.3783 - val_sparse_categorical_accuracy: 0.8911 - val_sparse_categorical_crossentropy: 0.3783 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.3502 - sparse_categorical_accuracy: 0.9001 - sparse_categorical_crossentropy: 0.3502 - val_loss: 0.2713 - val_sparse_categorical_accuracy: 0.9234 - val_sparse_categorical_crossentropy: 0.2713 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2933 - sparse_categorical_accuracy: 0.9202 - sparse_categorical_crossentropy: 0.2933 - val_loss: 0.2231 - val_sparse_categorical_accuracy: 0.9400 - val_sparse_categorical_crossentropy: 0.2231 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2492 - sparse_categorical_accuracy: 0.9347 - sparse_categorical_crossentropy: 0.2492 - val_loss: 0.2256 - val_sparse_categorical_accuracy: 0.9420 - val_sparse_categorical_crossentropy: 0.2256 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2404 - sparse_categorical_accuracy: 0.9377 - sparse_categorical_crossentropy: 0.2404 - val_loss: 0.2191 - val_sparse_categorical_accuracy: 0.9450 - val_sparse_categorical_crossentropy: 0.2191 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9459 - sparse_categorical_crossentropy: 0.2082 - val_loss: 0.2464 - val_sparse_categorical_accuracy: 0.9429 - val_sparse_categorical_crossentropy: 0.2464 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2466 - sparse_categorical_accuracy: 0.9349 - sparse_categorical_crossentropy: 0.2466 - val_loss: 0.1984 - val_sparse_categorical_accuracy: 0.9475 - val_sparse_categorical_crossentropy: 0.1984 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2046 - sparse_categorical_accuracy: 0.9466 - sparse_categorical_crossentropy: 0.2046 - val_loss: 0.1528 - val_sparse_categorical_accuracy: 0.9608 - val_sparse_categorical_crossentropy: 0.1528 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1700 - sparse_categorical_accuracy: 0.9557 - sparse_categorical_crossentropy: 0.1700 - val_loss: 0.3111 - val_sparse_categorical_accuracy: 0.9406 - val_sparse_categorical_crossentropy: 0.3111 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.1988 - sparse_categorical_accuracy: 0.9487 - sparse_categorical_crossentropy: 0.1988 - val_loss: 0.2253 - val_sparse_categorical_accuracy: 0.9541 - val_sparse_categorical_crossentropy: 0.2253 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1821 - sparse_categorical_accuracy: 0.9533 - sparse_categorical_crossentropy: 0.1821\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1820 - sparse_categorical_accuracy: 0.9533 - sparse_categorical_crossentropy: 0.1820 - val_loss: 0.2055 - val_sparse_categorical_accuracy: 0.9504 - val_sparse_categorical_crossentropy: 0.2055 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1383 - sparse_categorical_accuracy: 0.9643 - sparse_categorical_crossentropy: 0.1383 - val_loss: 0.1905 - val_sparse_categorical_accuracy: 0.9569 - val_sparse_categorical_crossentropy: 0.1905 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1714 - sparse_categorical_accuracy: 0.9556 - sparse_categorical_crossentropy: 0.1714 - val_loss: 0.1724 - val_sparse_categorical_accuracy: 0.9613 - val_sparse_categorical_crossentropy: 0.1724 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1198 - sparse_categorical_accuracy: 0.9685 - sparse_categorical_crossentropy: 0.1198 - val_loss: 0.1849 - val_sparse_categorical_accuracy: 0.9639 - val_sparse_categorical_crossentropy: 0.1849 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9639 - sparse_categorical_crossentropy: 0.1381 - val_loss: 0.1630 - val_sparse_categorical_accuracy: 0.9655 - val_sparse_categorical_crossentropy: 0.1630 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9744 - sparse_categorical_crossentropy: 0.0992 - val_loss: 0.1780 - val_sparse_categorical_accuracy: 0.9632 - val_sparse_categorical_crossentropy: 0.1780 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9765 - sparse_categorical_crossentropy: 0.0885 - val_loss: 0.1844 - val_sparse_categorical_accuracy: 0.9682 - val_sparse_categorical_crossentropy: 0.1844 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9789 - sparse_categorical_crossentropy: 0.0835 - val_loss: 0.1931 - val_sparse_categorical_accuracy: 0.9645 - val_sparse_categorical_crossentropy: 0.1931 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9785 - sparse_categorical_crossentropy: 0.0825 - val_loss: 0.1739 - val_sparse_categorical_accuracy: 0.9662 - val_sparse_categorical_crossentropy: 0.1739 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0802 - sparse_categorical_accuracy: 0.9793 - sparse_categorical_crossentropy: 0.0802\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9793 - sparse_categorical_crossentropy: 0.0802 - val_loss: 0.2114 - val_sparse_categorical_accuracy: 0.9650 - val_sparse_categorical_crossentropy: 0.2114 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9826 - sparse_categorical_crossentropy: 0.0657 - val_loss: 0.1957 - val_sparse_categorical_accuracy: 0.9659 - val_sparse_categorical_crossentropy: 0.1957 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9844 - sparse_categorical_crossentropy: 0.0599 - val_loss: 0.2158 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.2158 - lr: 0.0025\n",
      "26/26 [==============================] - 4s 135ms/step - loss: 0.1859 - sparse_categorical_accuracy: 0.9642 - sparse_categorical_crossentropy: 0.1859\n",
      "26/26 [==============================] - 5s 134ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 191ms/step - loss: 1.4270 - sparse_categorical_accuracy: 0.6207 - sparse_categorical_crossentropy: 1.4270 - val_loss: 1.1491 - val_sparse_categorical_accuracy: 0.6469 - val_sparse_categorical_crossentropy: 1.1491 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.9303 - sparse_categorical_accuracy: 0.7105 - sparse_categorical_crossentropy: 0.9303 - val_loss: 1.0262 - val_sparse_categorical_accuracy: 0.6948 - val_sparse_categorical_crossentropy: 1.0262 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.7099 - sparse_categorical_accuracy: 0.7762 - sparse_categorical_crossentropy: 0.7099 - val_loss: 0.5670 - val_sparse_categorical_accuracy: 0.8311 - val_sparse_categorical_crossentropy: 0.5670 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.8237 - sparse_categorical_crossentropy: 0.5699 - val_loss: 0.5170 - val_sparse_categorical_accuracy: 0.8638 - val_sparse_categorical_crossentropy: 0.5170 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.4766 - sparse_categorical_accuracy: 0.8602 - sparse_categorical_crossentropy: 0.4766 - val_loss: 0.3326 - val_sparse_categorical_accuracy: 0.9071 - val_sparse_categorical_crossentropy: 0.3326 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.3806 - sparse_categorical_accuracy: 0.8913 - sparse_categorical_crossentropy: 0.3806 - val_loss: 0.7177 - val_sparse_categorical_accuracy: 0.7976 - val_sparse_categorical_crossentropy: 0.7177 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.5056 - sparse_categorical_accuracy: 0.8552 - sparse_categorical_crossentropy: 0.5056 - val_loss: 0.7726 - val_sparse_categorical_accuracy: 0.7635 - val_sparse_categorical_crossentropy: 0.7726 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.3726 - sparse_categorical_accuracy: 0.8970 - sparse_categorical_crossentropy: 0.3726 - val_loss: 0.3087 - val_sparse_categorical_accuracy: 0.9142 - val_sparse_categorical_crossentropy: 0.3087 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.3156 - sparse_categorical_accuracy: 0.9167 - sparse_categorical_crossentropy: 0.3156 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9374 - val_sparse_categorical_crossentropy: 0.2193 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2618 - sparse_categorical_accuracy: 0.9289 - sparse_categorical_crossentropy: 0.2618 - val_loss: 0.2584 - val_sparse_categorical_accuracy: 0.9286 - val_sparse_categorical_crossentropy: 0.2584 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2519 - sparse_categorical_accuracy: 0.9335 - sparse_categorical_crossentropy: 0.2519 - val_loss: 0.2696 - val_sparse_categorical_accuracy: 0.9383 - val_sparse_categorical_crossentropy: 0.2696 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2583 - sparse_categorical_accuracy: 0.9328 - sparse_categorical_crossentropy: 0.2583 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9444 - val_sparse_categorical_crossentropy: 0.2271 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2288 - sparse_categorical_accuracy: 0.9398 - sparse_categorical_crossentropy: 0.2288 - val_loss: 0.2178 - val_sparse_categorical_accuracy: 0.9413 - val_sparse_categorical_crossentropy: 0.2178 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2138 - sparse_categorical_accuracy: 0.9435 - sparse_categorical_crossentropy: 0.2138 - val_loss: 0.3240 - val_sparse_categorical_accuracy: 0.9271 - val_sparse_categorical_crossentropy: 0.3240 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.4212 - sparse_categorical_accuracy: 0.8859 - sparse_categorical_crossentropy: 0.4212\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.4212 - sparse_categorical_accuracy: 0.8859 - sparse_categorical_crossentropy: 0.4212 - val_loss: 0.2342 - val_sparse_categorical_accuracy: 0.9318 - val_sparse_categorical_crossentropy: 0.2342 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2599 - sparse_categorical_accuracy: 0.9299 - sparse_categorical_crossentropy: 0.2599 - val_loss: 0.2119 - val_sparse_categorical_accuracy: 0.9446 - val_sparse_categorical_crossentropy: 0.2119 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1948 - sparse_categorical_accuracy: 0.9483 - sparse_categorical_crossentropy: 0.1948 - val_loss: 0.1978 - val_sparse_categorical_accuracy: 0.9487 - val_sparse_categorical_crossentropy: 0.1978 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1684 - sparse_categorical_accuracy: 0.9551 - sparse_categorical_crossentropy: 0.1684 - val_loss: 0.2004 - val_sparse_categorical_accuracy: 0.9538 - val_sparse_categorical_crossentropy: 0.2004 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9603 - sparse_categorical_crossentropy: 0.1514 - val_loss: 0.2060 - val_sparse_categorical_accuracy: 0.9539 - val_sparse_categorical_crossentropy: 0.2060 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9624 - sparse_categorical_crossentropy: 0.1434 - val_loss: 0.1985 - val_sparse_categorical_accuracy: 0.9550 - val_sparse_categorical_crossentropy: 0.1985 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9632 - sparse_categorical_crossentropy: 0.1463 - val_loss: 0.1981 - val_sparse_categorical_accuracy: 0.9549 - val_sparse_categorical_crossentropy: 0.1981 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1506 - sparse_categorical_accuracy: 0.9598 - sparse_categorical_crossentropy: 0.1506 - val_loss: 0.2016 - val_sparse_categorical_accuracy: 0.9590 - val_sparse_categorical_crossentropy: 0.2016 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9623 - sparse_categorical_crossentropy: 0.1465 - val_loss: 0.1898 - val_sparse_categorical_accuracy: 0.9578 - val_sparse_categorical_crossentropy: 0.1898 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1231 - sparse_categorical_accuracy: 0.9686 - sparse_categorical_crossentropy: 0.1231 - val_loss: 0.1998 - val_sparse_categorical_accuracy: 0.9567 - val_sparse_categorical_crossentropy: 0.1998 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1315 - sparse_categorical_accuracy: 0.9662 - sparse_categorical_crossentropy: 0.1315\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.1315 - sparse_categorical_accuracy: 0.9663 - sparse_categorical_crossentropy: 0.1315 - val_loss: 0.2085 - val_sparse_categorical_accuracy: 0.9538 - val_sparse_categorical_crossentropy: 0.2085 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9750 - sparse_categorical_crossentropy: 0.0996 - val_loss: 0.2185 - val_sparse_categorical_accuracy: 0.9598 - val_sparse_categorical_crossentropy: 0.2185 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9763 - sparse_categorical_crossentropy: 0.0905 - val_loss: 0.2274 - val_sparse_categorical_accuracy: 0.9608 - val_sparse_categorical_crossentropy: 0.2274 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9793 - sparse_categorical_crossentropy: 0.0793 - val_loss: 0.2432 - val_sparse_categorical_accuracy: 0.9608 - val_sparse_categorical_crossentropy: 0.2432 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9810 - sparse_categorical_crossentropy: 0.0750 - val_loss: 0.2555 - val_sparse_categorical_accuracy: 0.9602 - val_sparse_categorical_crossentropy: 0.2555 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0697 - sparse_categorical_accuracy: 0.9826 - sparse_categorical_crossentropy: 0.0697\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9826 - sparse_categorical_crossentropy: 0.0697 - val_loss: 0.2753 - val_sparse_categorical_accuracy: 0.9584 - val_sparse_categorical_crossentropy: 0.2753 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0644 - sparse_categorical_accuracy: 0.9832 - sparse_categorical_crossentropy: 0.0644 - val_loss: 0.2710 - val_sparse_categorical_accuracy: 0.9633 - val_sparse_categorical_crossentropy: 0.2710 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9850 - sparse_categorical_crossentropy: 0.0590 - val_loss: 0.2837 - val_sparse_categorical_accuracy: 0.9627 - val_sparse_categorical_crossentropy: 0.2837 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9846 - sparse_categorical_crossentropy: 0.0602 - val_loss: 0.2973 - val_sparse_categorical_accuracy: 0.9624 - val_sparse_categorical_crossentropy: 0.2973 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0583 - sparse_categorical_accuracy: 0.9849 - sparse_categorical_crossentropy: 0.0583\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9850 - sparse_categorical_crossentropy: 0.0583 - val_loss: 0.3089 - val_sparse_categorical_accuracy: 0.9607 - val_sparse_categorical_crossentropy: 0.3089 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9866 - sparse_categorical_crossentropy: 0.0534 - val_loss: 0.3160 - val_sparse_categorical_accuracy: 0.9599 - val_sparse_categorical_crossentropy: 0.3160 - lr: 6.2500e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.0512 - sparse_categorical_accuracy: 0.9871 - sparse_categorical_crossentropy: 0.0512 - val_loss: 0.3148 - val_sparse_categorical_accuracy: 0.9615 - val_sparse_categorical_crossentropy: 0.3148 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 4s 132ms/step - loss: 0.2977 - sparse_categorical_accuracy: 0.9593 - sparse_categorical_crossentropy: 0.2977\n",
      "26/26 [==============================] - 5s 129ms/step\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(5))\n",
    "DROPOUTS = [0.1, 0.3, 0.5]\n",
    "for dropout in DROPOUTS:\n",
    "    results = []\n",
    "    EXPERIMENT_NAME = f\"article_net_{dropout}\"\n",
    "    if os.path.exists(EXPERIMENT_NAME):\n",
    "        shutil.rmtree(EXPERIMENT_NAME)\n",
    "        os.mkdir(EXPERIMENT_NAME)\n",
    "    else:\n",
    "        os.mkdir(EXPERIMENT_NAME)\n",
    "\n",
    "    for seed in TRAINING_SEEDS:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        model = create_model(dropout)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "            loss=losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=MAX_EPOCHS,\n",
    "            validation_data=val_ds,\n",
    "            shuffle=True,\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "\n",
    "        with open(os.path.join(EXPERIMENT_NAME, f\"history_{seed}.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(history.history, file)\n",
    "\n",
    "        eval_results = model.evaluate(test_ds)\n",
    "\n",
    "        predictions = model.predict(test_ds)\n",
    "        with open(os.path.join(EXPERIMENT_NAME, f\"predictions_{seed}.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(predictions, file)\n",
    "\n",
    "        results += [{\n",
    "            'seed': seed,\n",
    "            'results': dict(zip(model.metrics_names, eval_results))\n",
    "        }]\n",
    "        gc.collect()\n",
    "\n",
    "    results_temp = pd.DataFrame(results)\n",
    "    results_df = pd.concat([results_temp.drop([\"results\"], axis=1), results_temp[\"results\"].apply(pd.Series)], axis=1)\n",
    "    results_df.to_csv(os.path.join(EXPERIMENT_NAME, 'results.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T00:40:44.574552Z",
     "end_time": "2023-04-24T02:54:07.681133Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   seed      loss  sparse_categorical_accuracy  \\\n0     0  0.198098                     0.965986   \n1     1  0.369765                     0.963759   \n2     2  0.228863                     0.961763   \n3     3  0.185863                     0.964220   \n4     4  0.297651                     0.959306   \n\n   sparse_categorical_crossentropy  \n0                         0.198098  \n1                         0.369765  \n2                         0.228863  \n3                         0.185863  \n4                         0.297651  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed</th>\n      <th>loss</th>\n      <th>sparse_categorical_accuracy</th>\n      <th>sparse_categorical_crossentropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.198098</td>\n      <td>0.965986</td>\n      <td>0.198098</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.369765</td>\n      <td>0.963759</td>\n      <td>0.369765</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.228863</td>\n      <td>0.961763</td>\n      <td>0.228863</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.185863</td>\n      <td>0.964220</td>\n      <td>0.185863</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.297651</td>\n      <td>0.959306</td>\n      <td>0.297651</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T02:54:07.684088Z",
     "end_time": "2023-04-24T02:54:07.697044Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
