{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import losses, optimizers, metrics, callbacks, Model, layers, backend as K\n",
    "from augment_layers import FreqMaskLayer, TimeMaskLayer\n",
    "import SpeechModels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:06.123165Z",
     "end_time": "2023-04-24T06:46:09.261710Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:09.248749Z",
     "end_time": "2023-04-24T06:46:09.809477Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 12\n",
    "MAX_EPOCHS = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:09.809477Z",
     "end_time": "2023-04-24T06:46:09.854352Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:09.826447Z",
     "end_time": "2023-04-24T06:46:09.860333Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45586 files belonging to 12 classes.\n",
      "Found 6513 files belonging to 12 classes.\n",
      "Found 13024 files belonging to 12 classes.\n",
      "label names: ['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/train\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/val\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/test\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print(\"label names:\", label_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:09.843389Z",
     "end_time": "2023-04-24T06:46:15.155778Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(squeeze, tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:15.156774Z",
     "end_time": "2023-04-24T06:46:15.217571Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model from article"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " normalized_spectrogram_model (  (None, 125, 80)     0           ['input[0][0]']                  \n",
      " Functional)                                                                                      \n",
      "                                                                                                  \n",
      " time_mask_layer (TimeMaskLayer  (None, 125, 80)     0           ['normalized_spectrogram_model[0]\n",
      " )                                                               [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 125, 80, 1)   0           ['time_mask_layer[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 125, 80, 10)  60          ['tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 125, 80, 10)  40         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 125, 80, 1)   51          ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 125, 80, 1)  4           ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, 125, 80)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 125, 128)     74240       ['squeeze_last_dim[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 125, 128)    98816       ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 128)          0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          16512       ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 125)          0           ['dense[0][0]',                  \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, 125)          0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 12)           396         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 200,455\n",
      "Trainable params: 200,433\n",
      "Non-trainable params: 22\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(freq=False, time=False):\n",
    "    m = SpeechModels.get_melspec_model(iLen=16000)\n",
    "    m.trainable = False\n",
    "    inputs, outputs = m.inputs, m.outputs\n",
    "\n",
    "    x = m(inputs)\n",
    "    if freq:\n",
    "        x = FreqMaskLayer(10)(x)\n",
    "    if time:\n",
    "        x = TimeMaskLayer(10)(x)\n",
    "    x = tf.expand_dims(x, axis=-1, name='mel_stft')\n",
    "\n",
    "    x = layers.Conv2D(10, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # x = Reshape((125, 80)) (x)\n",
    "    # keras.backend.squeeze(x, axis)\n",
    "    x = layers.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True)\n",
    "                        )(x)  # [b_s, seq_len, vec_dim]\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True)\n",
    "                        )(x)  # [b_s, seq_len, vec_dim]\n",
    "\n",
    "    x_first = layers.Lambda(lambda q: q[:, -1])(x)  # [b_s, vec_dim]\n",
    "    query = layers.Dense(128)(x_first)\n",
    "\n",
    "    # dot product attention\n",
    "    att_scores = layers.Dot(axes=[1, 2])([query, x])\n",
    "    att_scores = layers.Softmax(name='attSoftmax')(att_scores)  # [b_s, seq_len]\n",
    "\n",
    "    # rescale sequence\n",
    "    att_vector = layers.Dot(axes=[1, 1])([att_scores, x])  # [b_s, vec_dim]\n",
    "    x = layers.Dropout(rate=0.3)(att_vector)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(rate=0.3)(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "    x = layers.Dropout(rate=0.3)(x)\n",
    "    output = layers.Dense(N_CLASS, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model(time=True)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:15.210594Z",
     "end_time": "2023-04-24T06:46:16.376894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=3, min_lr=0.00001, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:16.341959Z",
     "end_time": "2023-04-24T06:46:16.400814Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "90/90 [==============================] - 52s 432ms/step - loss: 1.6582 - sparse_categorical_accuracy: 0.6191 - sparse_categorical_crossentropy: 1.6582 - val_loss: 1.6379 - val_sparse_categorical_accuracy: 0.6301 - val_sparse_categorical_crossentropy: 1.6379 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 40s 427ms/step - loss: 1.3996 - sparse_categorical_accuracy: 0.6339 - sparse_categorical_crossentropy: 1.3996 - val_loss: 1.1504 - val_sparse_categorical_accuracy: 0.6544 - val_sparse_categorical_crossentropy: 1.1504 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=2,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:46:16.372908Z",
     "end_time": "2023-04-24T06:47:48.228966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " normalized_spectrogram_model (  (None, 125, 80)     0           ['input[0][0]']                  \n",
      " Functional)                                                                                      \n",
      "                                                                                                  \n",
      " freq_mask_layer (FreqMaskLayer  (None, 125, 80)     0           ['normalized_spectrogram_model[0]\n",
      " )                                                               [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 125, 80, 1)   0           ['freq_mask_layer[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 125, 80, 10)  60          ['tf.expand_dims_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 125, 80, 10)  40         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 125, 80, 1)   51          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 125, 80, 1)  4           ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, 125, 80)      0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 125, 128)    74240       ['squeeze_last_dim[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 125, 128)    98816       ['bidirectional_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 128)          0           ['bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          16512       ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                    (None, 125)          0           ['dense_3[0][0]',                \n",
      "                                                                  'bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, 125)          0           ['dot_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                    (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dot_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           8256        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           2080        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 32)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 12)           396         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 200,455\n",
      "Trainable params: 200,433\n",
      "Non-trainable params: 22\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(freq=True)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:47:48.230959Z",
     "end_time": "2023-04-24T06:47:49.320864Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments\n",
    "\n",
    "Training will be repeated 5 times with different weights initialization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 45s 429ms/step - loss: 1.4198 - sparse_categorical_accuracy: 0.6244 - sparse_categorical_crossentropy: 1.4198 - val_loss: 1.1306 - val_sparse_categorical_accuracy: 0.6484 - val_sparse_categorical_crossentropy: 1.1306 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 38s 414ms/step - loss: 0.7851 - sparse_categorical_accuracy: 0.7476 - sparse_categorical_crossentropy: 0.7851 - val_loss: 0.6156 - val_sparse_categorical_accuracy: 0.8147 - val_sparse_categorical_crossentropy: 0.6156 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.5026 - sparse_categorical_accuracy: 0.8513 - sparse_categorical_crossentropy: 0.5026 - val_loss: 0.4711 - val_sparse_categorical_accuracy: 0.8557 - val_sparse_categorical_crossentropy: 0.4711 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 38s 407ms/step - loss: 0.3915 - sparse_categorical_accuracy: 0.8875 - sparse_categorical_crossentropy: 0.3915 - val_loss: 0.3584 - val_sparse_categorical_accuracy: 0.8908 - val_sparse_categorical_crossentropy: 0.3584 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 38s 411ms/step - loss: 0.3840 - sparse_categorical_accuracy: 0.8912 - sparse_categorical_crossentropy: 0.3840 - val_loss: 0.2556 - val_sparse_categorical_accuracy: 0.9283 - val_sparse_categorical_crossentropy: 0.2556 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.3159 - sparse_categorical_accuracy: 0.9122 - sparse_categorical_crossentropy: 0.3159 - val_loss: 0.2307 - val_sparse_categorical_accuracy: 0.9324 - val_sparse_categorical_crossentropy: 0.2307 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 39s 422ms/step - loss: 0.2550 - sparse_categorical_accuracy: 0.9286 - sparse_categorical_crossentropy: 0.2550 - val_loss: 0.1942 - val_sparse_categorical_accuracy: 0.9441 - val_sparse_categorical_crossentropy: 0.1942 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.2138 - sparse_categorical_accuracy: 0.9406 - sparse_categorical_crossentropy: 0.2138 - val_loss: 0.1811 - val_sparse_categorical_accuracy: 0.9487 - val_sparse_categorical_crossentropy: 0.1811 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.1977 - sparse_categorical_accuracy: 0.9457 - sparse_categorical_crossentropy: 0.1977 - val_loss: 0.1970 - val_sparse_categorical_accuracy: 0.9487 - val_sparse_categorical_crossentropy: 0.1970 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 39s 417ms/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9474 - sparse_categorical_crossentropy: 0.1929 - val_loss: 0.1879 - val_sparse_categorical_accuracy: 0.9478 - val_sparse_categorical_crossentropy: 0.1879 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.1752 - sparse_categorical_accuracy: 0.9517 - sparse_categorical_crossentropy: 0.1752 - val_loss: 0.1709 - val_sparse_categorical_accuracy: 0.9538 - val_sparse_categorical_crossentropy: 0.1709 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 39s 425ms/step - loss: 0.1636 - sparse_categorical_accuracy: 0.9554 - sparse_categorical_crossentropy: 0.1636 - val_loss: 0.2022 - val_sparse_categorical_accuracy: 0.9487 - val_sparse_categorical_crossentropy: 0.2022 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.1601 - sparse_categorical_accuracy: 0.9560 - sparse_categorical_crossentropy: 0.1601 - val_loss: 0.1653 - val_sparse_categorical_accuracy: 0.9565 - val_sparse_categorical_crossentropy: 0.1653 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 39s 417ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9587 - sparse_categorical_crossentropy: 0.1486 - val_loss: 0.1808 - val_sparse_categorical_accuracy: 0.9539 - val_sparse_categorical_crossentropy: 0.1808 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.1376 - sparse_categorical_accuracy: 0.9620 - sparse_categorical_crossentropy: 0.1376 - val_loss: 0.1892 - val_sparse_categorical_accuracy: 0.9530 - val_sparse_categorical_crossentropy: 0.1892 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1801 - sparse_categorical_accuracy: 0.9508 - sparse_categorical_crossentropy: 0.1801\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.1800 - sparse_categorical_accuracy: 0.9508 - sparse_categorical_crossentropy: 0.1800 - val_loss: 0.1858 - val_sparse_categorical_accuracy: 0.9521 - val_sparse_categorical_crossentropy: 0.1858 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 39s 422ms/step - loss: 0.1233 - sparse_categorical_accuracy: 0.9663 - sparse_categorical_crossentropy: 0.1233 - val_loss: 0.1560 - val_sparse_categorical_accuracy: 0.9633 - val_sparse_categorical_crossentropy: 0.1560 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.1171 - sparse_categorical_accuracy: 0.9678 - sparse_categorical_crossentropy: 0.1171 - val_loss: 0.1441 - val_sparse_categorical_accuracy: 0.9665 - val_sparse_categorical_crossentropy: 0.1441 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 38s 407ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9748 - sparse_categorical_crossentropy: 0.0917 - val_loss: 0.1418 - val_sparse_categorical_accuracy: 0.9658 - val_sparse_categorical_crossentropy: 0.1418 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9760 - sparse_categorical_crossentropy: 0.0889 - val_loss: 0.1529 - val_sparse_categorical_accuracy: 0.9656 - val_sparse_categorical_crossentropy: 0.1529 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0893 - sparse_categorical_accuracy: 0.9755 - sparse_categorical_crossentropy: 0.0893\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 39s 424ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9755 - sparse_categorical_crossentropy: 0.0892 - val_loss: 0.1511 - val_sparse_categorical_accuracy: 0.9658 - val_sparse_categorical_crossentropy: 0.1511 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9802 - sparse_categorical_crossentropy: 0.0730 - val_loss: 0.1548 - val_sparse_categorical_accuracy: 0.9674 - val_sparse_categorical_crossentropy: 0.1548 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.0622 - sparse_categorical_accuracy: 0.9832 - sparse_categorical_crossentropy: 0.0622 - val_loss: 0.1529 - val_sparse_categorical_accuracy: 0.9673 - val_sparse_categorical_crossentropy: 0.1529 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.0659 - sparse_categorical_accuracy: 0.9825 - sparse_categorical_crossentropy: 0.0659 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9681 - val_sparse_categorical_crossentropy: 0.1463 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9845 - sparse_categorical_crossentropy: 0.0569 - val_loss: 0.1578 - val_sparse_categorical_accuracy: 0.9673 - val_sparse_categorical_crossentropy: 0.1578 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 39s 422ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9843 - sparse_categorical_crossentropy: 0.0584 - val_loss: 0.1503 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.1503 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0550 - sparse_categorical_accuracy: 0.9851 - sparse_categorical_crossentropy: 0.0550\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 39s 424ms/step - loss: 0.0550 - sparse_categorical_accuracy: 0.9851 - sparse_categorical_crossentropy: 0.0550 - val_loss: 0.1643 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1643 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 38s 413ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9864 - sparse_categorical_crossentropy: 0.0532 - val_loss: 0.1635 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.1635 - lr: 0.0012\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.0478 - sparse_categorical_accuracy: 0.9872 - sparse_categorical_crossentropy: 0.0478 - val_loss: 0.1652 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.1652 - lr: 0.0012\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 39s 423ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9881 - sparse_categorical_crossentropy: 0.0452 - val_loss: 0.1625 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.1625 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0448 - sparse_categorical_accuracy: 0.9880 - sparse_categorical_crossentropy: 0.0448 - val_loss: 0.1624 - val_sparse_categorical_accuracy: 0.9688 - val_sparse_categorical_crossentropy: 0.1624 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.0484 - sparse_categorical_accuracy: 0.9875 - sparse_categorical_crossentropy: 0.0484 - val_loss: 0.1732 - val_sparse_categorical_accuracy: 0.9667 - val_sparse_categorical_crossentropy: 0.1732 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 39s 417ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9882 - sparse_categorical_crossentropy: 0.0446 - val_loss: 0.1792 - val_sparse_categorical_accuracy: 0.9671 - val_sparse_categorical_crossentropy: 0.1792 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0443 - sparse_categorical_accuracy: 0.9884 - sparse_categorical_crossentropy: 0.0443\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 39s 424ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9884 - sparse_categorical_crossentropy: 0.0443 - val_loss: 0.1764 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.1764 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 38s 406ms/step - loss: 0.0434 - sparse_categorical_accuracy: 0.9885 - sparse_categorical_crossentropy: 0.0434 - val_loss: 0.1731 - val_sparse_categorical_accuracy: 0.9674 - val_sparse_categorical_crossentropy: 0.1731 - lr: 6.2500e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 39s 424ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9887 - sparse_categorical_crossentropy: 0.0417 - val_loss: 0.1745 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1745 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 109ms/step - loss: 0.1496 - sparse_categorical_accuracy: 0.9699 - sparse_categorical_crossentropy: 0.1496\n",
      "26/26 [==============================] - 4s 97ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 45s 435ms/step - loss: 1.5277 - sparse_categorical_accuracy: 0.6213 - sparse_categorical_crossentropy: 1.5277 - val_loss: 1.5013 - val_sparse_categorical_accuracy: 0.6297 - val_sparse_categorical_crossentropy: 1.5013 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 1.0272 - sparse_categorical_accuracy: 0.6872 - sparse_categorical_crossentropy: 1.0272 - val_loss: 1.5515 - val_sparse_categorical_accuracy: 0.6303 - val_sparse_categorical_crossentropy: 1.5515 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.6521 - sparse_categorical_accuracy: 0.8020 - sparse_categorical_crossentropy: 0.6521 - val_loss: 1.2230 - val_sparse_categorical_accuracy: 0.6700 - val_sparse_categorical_crossentropy: 1.2230 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.4325 - sparse_categorical_accuracy: 0.8730 - sparse_categorical_crossentropy: 0.4325 - val_loss: 0.8685 - val_sparse_categorical_accuracy: 0.7586 - val_sparse_categorical_crossentropy: 0.8685 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.4195 - sparse_categorical_accuracy: 0.8807 - sparse_categorical_crossentropy: 0.4195 - val_loss: 0.7348 - val_sparse_categorical_accuracy: 0.7780 - val_sparse_categorical_crossentropy: 0.7348 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 38s 411ms/step - loss: 0.4082 - sparse_categorical_accuracy: 0.8829 - sparse_categorical_crossentropy: 0.4082 - val_loss: 0.3259 - val_sparse_categorical_accuracy: 0.9047 - val_sparse_categorical_crossentropy: 0.3259 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.3111 - sparse_categorical_accuracy: 0.9117 - sparse_categorical_crossentropy: 0.3111 - val_loss: 0.2807 - val_sparse_categorical_accuracy: 0.9205 - val_sparse_categorical_crossentropy: 0.2807 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.2472 - sparse_categorical_accuracy: 0.9306 - sparse_categorical_crossentropy: 0.2472 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9418 - val_sparse_categorical_crossentropy: 0.2121 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.2411 - sparse_categorical_accuracy: 0.9333 - sparse_categorical_crossentropy: 0.2411 - val_loss: 0.1797 - val_sparse_categorical_accuracy: 0.9535 - val_sparse_categorical_crossentropy: 0.1797 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 39s 424ms/step - loss: 0.2032 - sparse_categorical_accuracy: 0.9444 - sparse_categorical_crossentropy: 0.2032 - val_loss: 0.1910 - val_sparse_categorical_accuracy: 0.9464 - val_sparse_categorical_crossentropy: 0.1910 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 38s 407ms/step - loss: 0.1745 - sparse_categorical_accuracy: 0.9524 - sparse_categorical_crossentropy: 0.1745 - val_loss: 0.1698 - val_sparse_categorical_accuracy: 0.9521 - val_sparse_categorical_crossentropy: 0.1698 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1531 - sparse_categorical_accuracy: 0.9577 - sparse_categorical_crossentropy: 0.1531\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 40s 427ms/step - loss: 0.1531 - sparse_categorical_accuracy: 0.9577 - sparse_categorical_crossentropy: 0.1531 - val_loss: 0.1897 - val_sparse_categorical_accuracy: 0.9496 - val_sparse_categorical_crossentropy: 0.1897 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 39s 425ms/step - loss: 0.1284 - sparse_categorical_accuracy: 0.9651 - sparse_categorical_crossentropy: 0.1284 - val_loss: 0.1437 - val_sparse_categorical_accuracy: 0.9639 - val_sparse_categorical_crossentropy: 0.1437 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 38s 411ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9715 - sparse_categorical_crossentropy: 0.1061 - val_loss: 0.1537 - val_sparse_categorical_accuracy: 0.9616 - val_sparse_categorical_crossentropy: 0.1537 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.1216 - sparse_categorical_accuracy: 0.9666 - sparse_categorical_crossentropy: 0.1216 - val_loss: 0.1525 - val_sparse_categorical_accuracy: 0.9622 - val_sparse_categorical_crossentropy: 0.1525 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1064 - sparse_categorical_accuracy: 0.9708 - sparse_categorical_crossentropy: 0.1064\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9708 - sparse_categorical_crossentropy: 0.1064 - val_loss: 0.1570 - val_sparse_categorical_accuracy: 0.9627 - val_sparse_categorical_crossentropy: 0.1570 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.0886 - sparse_categorical_accuracy: 0.9752 - sparse_categorical_crossentropy: 0.0886 - val_loss: 0.1438 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.1438 - lr: 0.0025\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9783 - sparse_categorical_crossentropy: 0.0775 - val_loss: 0.1375 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.1375 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9795 - sparse_categorical_crossentropy: 0.0759 - val_loss: 0.1389 - val_sparse_categorical_accuracy: 0.9701 - val_sparse_categorical_crossentropy: 0.1389 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9810 - sparse_categorical_crossentropy: 0.0696 - val_loss: 0.1442 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.1442 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0777 - sparse_categorical_accuracy: 0.9786 - sparse_categorical_crossentropy: 0.0777\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 38s 411ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9787 - sparse_categorical_crossentropy: 0.0777 - val_loss: 0.1453 - val_sparse_categorical_accuracy: 0.9665 - val_sparse_categorical_crossentropy: 0.1453 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9828 - sparse_categorical_crossentropy: 0.0628 - val_loss: 0.1372 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.1372 - lr: 0.0012\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9839 - sparse_categorical_crossentropy: 0.0603 - val_loss: 0.1533 - val_sparse_categorical_accuracy: 0.9681 - val_sparse_categorical_crossentropy: 0.1533 - lr: 0.0012\n",
      "26/26 [==============================] - 3s 110ms/step - loss: 0.1443 - sparse_categorical_accuracy: 0.9668 - sparse_categorical_crossentropy: 0.1443\n",
      "26/26 [==============================] - 4s 109ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 44s 418ms/step - loss: 1.3162 - sparse_categorical_accuracy: 0.6418 - sparse_categorical_crossentropy: 1.3162 - val_loss: 0.9132 - val_sparse_categorical_accuracy: 0.7066 - val_sparse_categorical_crossentropy: 0.9132 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 38s 405ms/step - loss: 0.6799 - sparse_categorical_accuracy: 0.7904 - sparse_categorical_crossentropy: 0.6799 - val_loss: 0.8994 - val_sparse_categorical_accuracy: 0.7361 - val_sparse_categorical_crossentropy: 0.8994 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 38s 407ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8699 - sparse_categorical_crossentropy: 0.4308 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.7897 - val_sparse_categorical_crossentropy: 0.6951 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 38s 404ms/step - loss: 0.3559 - sparse_categorical_accuracy: 0.8976 - sparse_categorical_crossentropy: 0.3559 - val_loss: 0.3210 - val_sparse_categorical_accuracy: 0.9017 - val_sparse_categorical_crossentropy: 0.3210 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 38s 406ms/step - loss: 0.3279 - sparse_categorical_accuracy: 0.9083 - sparse_categorical_crossentropy: 0.3279 - val_loss: 0.2838 - val_sparse_categorical_accuracy: 0.9194 - val_sparse_categorical_crossentropy: 0.2838 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.2817 - sparse_categorical_accuracy: 0.9222 - sparse_categorical_crossentropy: 0.2817 - val_loss: 0.2277 - val_sparse_categorical_accuracy: 0.9320 - val_sparse_categorical_crossentropy: 0.2277 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 38s 406ms/step - loss: 0.2182 - sparse_categorical_accuracy: 0.9390 - sparse_categorical_crossentropy: 0.2182 - val_loss: 0.1639 - val_sparse_categorical_accuracy: 0.9507 - val_sparse_categorical_crossentropy: 0.1639 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9485 - sparse_categorical_crossentropy: 0.1869 - val_loss: 0.1800 - val_sparse_categorical_accuracy: 0.9476 - val_sparse_categorical_crossentropy: 0.1800 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.2015 - sparse_categorical_accuracy: 0.9433 - sparse_categorical_crossentropy: 0.2015 - val_loss: 0.1905 - val_sparse_categorical_accuracy: 0.9496 - val_sparse_categorical_crossentropy: 0.1905 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2049 - sparse_categorical_accuracy: 0.9431 - sparse_categorical_crossentropy: 0.2049\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 38s 411ms/step - loss: 0.2049 - sparse_categorical_accuracy: 0.9431 - sparse_categorical_crossentropy: 0.2049 - val_loss: 0.1868 - val_sparse_categorical_accuracy: 0.9460 - val_sparse_categorical_crossentropy: 0.1868 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.1678 - sparse_categorical_accuracy: 0.9527 - sparse_categorical_crossentropy: 0.1678 - val_loss: 0.1292 - val_sparse_categorical_accuracy: 0.9653 - val_sparse_categorical_crossentropy: 0.1292 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 38s 404ms/step - loss: 0.1179 - sparse_categorical_accuracy: 0.9680 - sparse_categorical_crossentropy: 0.1179 - val_loss: 0.1150 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.1150 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9675 - sparse_categorical_crossentropy: 0.1159 - val_loss: 0.1277 - val_sparse_categorical_accuracy: 0.9661 - val_sparse_categorical_crossentropy: 0.1277 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 38s 413ms/step - loss: 0.1047 - sparse_categorical_accuracy: 0.9715 - sparse_categorical_crossentropy: 0.1047 - val_loss: 0.1237 - val_sparse_categorical_accuracy: 0.9668 - val_sparse_categorical_crossentropy: 0.1237 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0925 - sparse_categorical_accuracy: 0.9745 - sparse_categorical_crossentropy: 0.0925\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 38s 405ms/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9746 - sparse_categorical_crossentropy: 0.0924 - val_loss: 0.1486 - val_sparse_categorical_accuracy: 0.9668 - val_sparse_categorical_crossentropy: 0.1486 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0794 - sparse_categorical_accuracy: 0.9784 - sparse_categorical_crossentropy: 0.0794 - val_loss: 0.1325 - val_sparse_categorical_accuracy: 0.9698 - val_sparse_categorical_crossentropy: 0.1325 - lr: 0.0025\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 38s 403ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9816 - sparse_categorical_crossentropy: 0.0684 - val_loss: 0.1278 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.1278 - lr: 0.0025\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9822 - sparse_categorical_crossentropy: 0.0653 - val_loss: 0.1577 - val_sparse_categorical_accuracy: 0.9645 - val_sparse_categorical_crossentropy: 0.1577 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 38s 407ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9828 - sparse_categorical_crossentropy: 0.0628 - val_loss: 0.1438 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.1438 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0618 - sparse_categorical_accuracy: 0.9831 - sparse_categorical_crossentropy: 0.0618\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9831 - sparse_categorical_crossentropy: 0.0618 - val_loss: 0.1295 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1295 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 38s 406ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9842 - sparse_categorical_crossentropy: 0.0576 - val_loss: 0.1381 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1381 - lr: 0.0012\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 38s 407ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9860 - sparse_categorical_crossentropy: 0.0534 - val_loss: 0.1437 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1437 - lr: 0.0012\n",
      "26/26 [==============================] - 3s 111ms/step - loss: 0.1403 - sparse_categorical_accuracy: 0.9684 - sparse_categorical_crossentropy: 0.1403\n",
      "26/26 [==============================] - 4s 111ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 45s 426ms/step - loss: 1.1557 - sparse_categorical_accuracy: 0.6716 - sparse_categorical_crossentropy: 1.1557 - val_loss: 1.6031 - val_sparse_categorical_accuracy: 0.6289 - val_sparse_categorical_crossentropy: 1.6031 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.6071 - sparse_categorical_accuracy: 0.8149 - sparse_categorical_crossentropy: 0.6071 - val_loss: 0.5504 - val_sparse_categorical_accuracy: 0.8293 - val_sparse_categorical_crossentropy: 0.5504 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.4210 - sparse_categorical_accuracy: 0.8769 - sparse_categorical_crossentropy: 0.4210 - val_loss: 0.3239 - val_sparse_categorical_accuracy: 0.8985 - val_sparse_categorical_crossentropy: 0.3239 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 38s 413ms/step - loss: 0.3265 - sparse_categorical_accuracy: 0.9067 - sparse_categorical_crossentropy: 0.3265 - val_loss: 0.2714 - val_sparse_categorical_accuracy: 0.9183 - val_sparse_categorical_crossentropy: 0.2714 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 38s 414ms/step - loss: 0.3115 - sparse_categorical_accuracy: 0.9123 - sparse_categorical_crossentropy: 0.3115 - val_loss: 0.2412 - val_sparse_categorical_accuracy: 0.9291 - val_sparse_categorical_crossentropy: 0.2412 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.3259 - sparse_categorical_accuracy: 0.9080 - sparse_categorical_crossentropy: 0.3259 - val_loss: 0.2011 - val_sparse_categorical_accuracy: 0.9397 - val_sparse_categorical_crossentropy: 0.2011 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.2255 - sparse_categorical_accuracy: 0.9381 - sparse_categorical_crossentropy: 0.2255 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.8182 - val_sparse_categorical_crossentropy: 0.6661 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.3123 - sparse_categorical_accuracy: 0.9120 - sparse_categorical_crossentropy: 0.3123 - val_loss: 0.2221 - val_sparse_categorical_accuracy: 0.9358 - val_sparse_categorical_crossentropy: 0.2221 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.1995 - sparse_categorical_accuracy: 0.9449 - sparse_categorical_crossentropy: 0.1995 - val_loss: 0.1663 - val_sparse_categorical_accuracy: 0.9547 - val_sparse_categorical_crossentropy: 0.1663 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 38s 413ms/step - loss: 0.1706 - sparse_categorical_accuracy: 0.9537 - sparse_categorical_crossentropy: 0.1706 - val_loss: 0.1757 - val_sparse_categorical_accuracy: 0.9535 - val_sparse_categorical_crossentropy: 0.1757 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 38s 411ms/step - loss: 0.1601 - sparse_categorical_accuracy: 0.9562 - sparse_categorical_crossentropy: 0.1601 - val_loss: 0.1525 - val_sparse_categorical_accuracy: 0.9561 - val_sparse_categorical_crossentropy: 0.1525 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 38s 413ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9604 - sparse_categorical_crossentropy: 0.1416 - val_loss: 0.1539 - val_sparse_categorical_accuracy: 0.9558 - val_sparse_categorical_crossentropy: 0.1539 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.1269 - sparse_categorical_accuracy: 0.9645 - sparse_categorical_crossentropy: 0.1269 - val_loss: 0.1442 - val_sparse_categorical_accuracy: 0.9625 - val_sparse_categorical_crossentropy: 0.1442 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 38s 411ms/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9673 - sparse_categorical_crossentropy: 0.1222 - val_loss: 0.1457 - val_sparse_categorical_accuracy: 0.9619 - val_sparse_categorical_crossentropy: 0.1457 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 38s 413ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9615 - sparse_categorical_crossentropy: 0.1434 - val_loss: 0.1448 - val_sparse_categorical_accuracy: 0.9624 - val_sparse_categorical_crossentropy: 0.1448 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1268 - sparse_categorical_accuracy: 0.9658 - sparse_categorical_crossentropy: 0.1268\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 38s 407ms/step - loss: 0.1268 - sparse_categorical_accuracy: 0.9658 - sparse_categorical_crossentropy: 0.1268 - val_loss: 0.1781 - val_sparse_categorical_accuracy: 0.9526 - val_sparse_categorical_crossentropy: 0.1781 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 38s 410ms/step - loss: 0.1126 - sparse_categorical_accuracy: 0.9692 - sparse_categorical_crossentropy: 0.1126 - val_loss: 0.1277 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1277 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9789 - sparse_categorical_crossentropy: 0.0802 - val_loss: 0.1285 - val_sparse_categorical_accuracy: 0.9679 - val_sparse_categorical_crossentropy: 0.1285 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9798 - sparse_categorical_crossentropy: 0.0755 - val_loss: 0.1285 - val_sparse_categorical_accuracy: 0.9705 - val_sparse_categorical_crossentropy: 0.1285 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 38s 413ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9819 - sparse_categorical_crossentropy: 0.0682 - val_loss: 0.1417 - val_sparse_categorical_accuracy: 0.9688 - val_sparse_categorical_crossentropy: 0.1417 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.0692 - sparse_categorical_accuracy: 0.9814 - sparse_categorical_crossentropy: 0.0692 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9668 - val_sparse_categorical_crossentropy: 0.1407 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0669 - sparse_categorical_accuracy: 0.9814 - sparse_categorical_crossentropy: 0.0669\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9814 - sparse_categorical_crossentropy: 0.0669 - val_loss: 0.1430 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1430 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9856 - sparse_categorical_crossentropy: 0.0555 - val_loss: 0.1280 - val_sparse_categorical_accuracy: 0.9721 - val_sparse_categorical_crossentropy: 0.1280 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.0521 - sparse_categorical_accuracy: 0.9859 - sparse_categorical_crossentropy: 0.0521 - val_loss: 0.1344 - val_sparse_categorical_accuracy: 0.9719 - val_sparse_categorical_crossentropy: 0.1344 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0487 - sparse_categorical_accuracy: 0.9868 - sparse_categorical_crossentropy: 0.0487 - val_loss: 0.1431 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1431 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0616 - sparse_categorical_accuracy: 0.9833 - sparse_categorical_crossentropy: 0.0616\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 38s 414ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9833 - sparse_categorical_crossentropy: 0.0615 - val_loss: 0.1411 - val_sparse_categorical_accuracy: 0.9705 - val_sparse_categorical_crossentropy: 0.1411 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9880 - sparse_categorical_crossentropy: 0.0453 - val_loss: 0.1409 - val_sparse_categorical_accuracy: 0.9719 - val_sparse_categorical_crossentropy: 0.1409 - lr: 0.0012\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0427 - sparse_categorical_accuracy: 0.9886 - sparse_categorical_crossentropy: 0.0427 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9727 - val_sparse_categorical_crossentropy: 0.1463 - lr: 0.0012\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.0424 - sparse_categorical_accuracy: 0.9890 - sparse_categorical_crossentropy: 0.0424 - val_loss: 0.1380 - val_sparse_categorical_accuracy: 0.9728 - val_sparse_categorical_crossentropy: 0.1380 - lr: 0.0012\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.0390 - sparse_categorical_accuracy: 0.9895 - sparse_categorical_crossentropy: 0.0390 - val_loss: 0.1460 - val_sparse_categorical_accuracy: 0.9731 - val_sparse_categorical_crossentropy: 0.1460 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.0386 - sparse_categorical_accuracy: 0.9898 - sparse_categorical_crossentropy: 0.0386 - val_loss: 0.1414 - val_sparse_categorical_accuracy: 0.9722 - val_sparse_categorical_crossentropy: 0.1414 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 38s 409ms/step - loss: 0.0379 - sparse_categorical_accuracy: 0.9897 - sparse_categorical_crossentropy: 0.0379 - val_loss: 0.1440 - val_sparse_categorical_accuracy: 0.9731 - val_sparse_categorical_crossentropy: 0.1440 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0402 - sparse_categorical_accuracy: 0.9894 - sparse_categorical_crossentropy: 0.0402\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.0402 - sparse_categorical_accuracy: 0.9894 - sparse_categorical_crossentropy: 0.0402 - val_loss: 0.1413 - val_sparse_categorical_accuracy: 0.9724 - val_sparse_categorical_crossentropy: 0.1413 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 38s 408ms/step - loss: 0.0367 - sparse_categorical_accuracy: 0.9905 - sparse_categorical_crossentropy: 0.0367 - val_loss: 0.1460 - val_sparse_categorical_accuracy: 0.9707 - val_sparse_categorical_crossentropy: 0.1460 - lr: 6.2500e-04\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 39s 415ms/step - loss: 0.0348 - sparse_categorical_accuracy: 0.9908 - sparse_categorical_crossentropy: 0.0348 - val_loss: 0.1515 - val_sparse_categorical_accuracy: 0.9705 - val_sparse_categorical_crossentropy: 0.1515 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 0.1498 - sparse_categorical_accuracy: 0.9709 - sparse_categorical_crossentropy: 0.1498\n",
      "26/26 [==============================] - 4s 112ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 45s 431ms/step - loss: 1.2219 - sparse_categorical_accuracy: 0.6623 - sparse_categorical_crossentropy: 1.2219 - val_loss: 1.2825 - val_sparse_categorical_accuracy: 0.6304 - val_sparse_categorical_crossentropy: 1.2825 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.6023 - sparse_categorical_accuracy: 0.8143 - sparse_categorical_crossentropy: 0.6023 - val_loss: 0.6287 - val_sparse_categorical_accuracy: 0.8082 - val_sparse_categorical_crossentropy: 0.6287 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 39s 415ms/step - loss: 0.4345 - sparse_categorical_accuracy: 0.8739 - sparse_categorical_crossentropy: 0.4345 - val_loss: 0.3843 - val_sparse_categorical_accuracy: 0.8852 - val_sparse_categorical_crossentropy: 0.3843 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.9032 - sparse_categorical_crossentropy: 0.3401 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.9097 - val_sparse_categorical_crossentropy: 0.3268 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.2966 - sparse_categorical_accuracy: 0.9166 - sparse_categorical_crossentropy: 0.2966 - val_loss: 0.3237 - val_sparse_categorical_accuracy: 0.9126 - val_sparse_categorical_crossentropy: 0.3237 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.3084 - sparse_categorical_accuracy: 0.9135 - sparse_categorical_crossentropy: 0.3084 - val_loss: 0.2035 - val_sparse_categorical_accuracy: 0.9413 - val_sparse_categorical_crossentropy: 0.2035 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.2279 - sparse_categorical_accuracy: 0.9364 - sparse_categorical_crossentropy: 0.2279 - val_loss: 0.2140 - val_sparse_categorical_accuracy: 0.9438 - val_sparse_categorical_crossentropy: 0.2140 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 39s 417ms/step - loss: 0.2332 - sparse_categorical_accuracy: 0.9366 - sparse_categorical_crossentropy: 0.2332 - val_loss: 0.1676 - val_sparse_categorical_accuracy: 0.9530 - val_sparse_categorical_crossentropy: 0.1676 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.1905 - sparse_categorical_accuracy: 0.9482 - sparse_categorical_crossentropy: 0.1905 - val_loss: 0.2269 - val_sparse_categorical_accuracy: 0.9374 - val_sparse_categorical_crossentropy: 0.2269 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.1796 - sparse_categorical_accuracy: 0.9511 - sparse_categorical_crossentropy: 0.1796 - val_loss: 0.1686 - val_sparse_categorical_accuracy: 0.9522 - val_sparse_categorical_crossentropy: 0.1686 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1625 - sparse_categorical_accuracy: 0.9556 - sparse_categorical_crossentropy: 0.1625\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9556 - sparse_categorical_crossentropy: 0.1625 - val_loss: 0.2211 - val_sparse_categorical_accuracy: 0.9409 - val_sparse_categorical_crossentropy: 0.2211 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9632 - sparse_categorical_crossentropy: 0.1326 - val_loss: 0.1441 - val_sparse_categorical_accuracy: 0.9618 - val_sparse_categorical_crossentropy: 0.1441 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 38s 412ms/step - loss: 0.1082 - sparse_categorical_accuracy: 0.9701 - sparse_categorical_crossentropy: 0.1082 - val_loss: 0.1614 - val_sparse_categorical_accuracy: 0.9607 - val_sparse_categorical_crossentropy: 0.1614 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.0983 - sparse_categorical_accuracy: 0.9732 - sparse_categorical_crossentropy: 0.0983 - val_loss: 0.1758 - val_sparse_categorical_accuracy: 0.9572 - val_sparse_categorical_crossentropy: 0.1758 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2291 - sparse_categorical_accuracy: 0.9365 - sparse_categorical_crossentropy: 0.2291\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.2290 - sparse_categorical_accuracy: 0.9365 - sparse_categorical_crossentropy: 0.2290 - val_loss: 0.1791 - val_sparse_categorical_accuracy: 0.9496 - val_sparse_categorical_crossentropy: 0.1791 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.1216 - sparse_categorical_accuracy: 0.9657 - sparse_categorical_crossentropy: 0.1216 - val_loss: 0.1472 - val_sparse_categorical_accuracy: 0.9612 - val_sparse_categorical_crossentropy: 0.1472 - lr: 0.0025\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 39s 422ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9718 - sparse_categorical_crossentropy: 0.1028 - val_loss: 0.1452 - val_sparse_categorical_accuracy: 0.9625 - val_sparse_categorical_crossentropy: 0.1452 - lr: 0.0025\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 40s 428ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9755 - sparse_categorical_crossentropy: 0.0901 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9642 - val_sparse_categorical_crossentropy: 0.1407 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 40s 427ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9767 - sparse_categorical_crossentropy: 0.0834 - val_loss: 0.1370 - val_sparse_categorical_accuracy: 0.9655 - val_sparse_categorical_crossentropy: 0.1370 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9799 - sparse_categorical_crossentropy: 0.0734 - val_loss: 0.1435 - val_sparse_categorical_accuracy: 0.9656 - val_sparse_categorical_crossentropy: 0.1435 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 40s 425ms/step - loss: 0.0768 - sparse_categorical_accuracy: 0.9796 - sparse_categorical_crossentropy: 0.0768 - val_loss: 0.1464 - val_sparse_categorical_accuracy: 0.9662 - val_sparse_categorical_crossentropy: 0.1464 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 40s 426ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9819 - sparse_categorical_crossentropy: 0.0667 - val_loss: 0.1454 - val_sparse_categorical_accuracy: 0.9655 - val_sparse_categorical_crossentropy: 0.1454 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 40s 426ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9821 - sparse_categorical_crossentropy: 0.0666 - val_loss: 0.1570 - val_sparse_categorical_accuracy: 0.9647 - val_sparse_categorical_crossentropy: 0.1570 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.0648 - sparse_categorical_accuracy: 0.9828 - sparse_categorical_crossentropy: 0.0648 - val_loss: 0.1535 - val_sparse_categorical_accuracy: 0.9665 - val_sparse_categorical_crossentropy: 0.1535 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 41s 434ms/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9822 - sparse_categorical_crossentropy: 0.0669 - val_loss: 0.1502 - val_sparse_categorical_accuracy: 0.9647 - val_sparse_categorical_crossentropy: 0.1502 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9835 - sparse_categorical_crossentropy: 0.0615 - val_loss: 0.1590 - val_sparse_categorical_accuracy: 0.9661 - val_sparse_categorical_crossentropy: 0.1590 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0575 - sparse_categorical_accuracy: 0.9844 - sparse_categorical_crossentropy: 0.0575\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9844 - sparse_categorical_crossentropy: 0.0575 - val_loss: 0.1676 - val_sparse_categorical_accuracy: 0.9639 - val_sparse_categorical_crossentropy: 0.1676 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 40s 427ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9854 - sparse_categorical_crossentropy: 0.0538 - val_loss: 0.1528 - val_sparse_categorical_accuracy: 0.9648 - val_sparse_categorical_crossentropy: 0.1528 - lr: 0.0012\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 40s 422ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9873 - sparse_categorical_crossentropy: 0.0472 - val_loss: 0.1632 - val_sparse_categorical_accuracy: 0.9668 - val_sparse_categorical_crossentropy: 0.1632 - lr: 0.0012\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0481 - sparse_categorical_accuracy: 0.9870 - sparse_categorical_crossentropy: 0.0481 - val_loss: 0.1661 - val_sparse_categorical_accuracy: 0.9668 - val_sparse_categorical_crossentropy: 0.1661 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 40s 431ms/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9883 - sparse_categorical_crossentropy: 0.0457 - val_loss: 0.1678 - val_sparse_categorical_accuracy: 0.9667 - val_sparse_categorical_crossentropy: 0.1678 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0457 - sparse_categorical_accuracy: 0.9881 - sparse_categorical_crossentropy: 0.0457\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 40s 425ms/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9881 - sparse_categorical_crossentropy: 0.0457 - val_loss: 0.1817 - val_sparse_categorical_accuracy: 0.9655 - val_sparse_categorical_crossentropy: 0.1817 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 40s 425ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9889 - sparse_categorical_crossentropy: 0.0417 - val_loss: 0.1645 - val_sparse_categorical_accuracy: 0.9655 - val_sparse_categorical_crossentropy: 0.1645 - lr: 6.2500e-04\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.9890 - sparse_categorical_crossentropy: 0.0421 - val_loss: 0.1654 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1654 - lr: 6.2500e-04\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 40s 425ms/step - loss: 0.0395 - sparse_categorical_accuracy: 0.9892 - sparse_categorical_crossentropy: 0.0395 - val_loss: 0.1687 - val_sparse_categorical_accuracy: 0.9681 - val_sparse_categorical_crossentropy: 0.1687 - lr: 6.2500e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 40s 422ms/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9899 - sparse_categorical_crossentropy: 0.0378 - val_loss: 0.1686 - val_sparse_categorical_accuracy: 0.9682 - val_sparse_categorical_crossentropy: 0.1686 - lr: 6.2500e-04\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9898 - sparse_categorical_crossentropy: 0.0378 - val_loss: 0.1644 - val_sparse_categorical_accuracy: 0.9682 - val_sparse_categorical_crossentropy: 0.1644 - lr: 6.2500e-04\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 40s 432ms/step - loss: 0.0393 - sparse_categorical_accuracy: 0.9900 - sparse_categorical_crossentropy: 0.0393 - val_loss: 0.1640 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1640 - lr: 6.2500e-04\n",
      "Epoch 39/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0365 - sparse_categorical_accuracy: 0.9900 - sparse_categorical_crossentropy: 0.0365\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9900 - sparse_categorical_crossentropy: 0.0365 - val_loss: 0.1634 - val_sparse_categorical_accuracy: 0.9682 - val_sparse_categorical_crossentropy: 0.1634 - lr: 6.2500e-04\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.0364 - sparse_categorical_accuracy: 0.9899 - sparse_categorical_crossentropy: 0.0364 - val_loss: 0.1660 - val_sparse_categorical_accuracy: 0.9673 - val_sparse_categorical_crossentropy: 0.1660 - lr: 3.1250e-04\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.0395 - sparse_categorical_accuracy: 0.9897 - sparse_categorical_crossentropy: 0.0395 - val_loss: 0.1618 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.1618 - lr: 3.1250e-04\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 40s 426ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9906 - sparse_categorical_crossentropy: 0.0357 - val_loss: 0.1672 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1672 - lr: 3.1250e-04\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.9898 - sparse_categorical_crossentropy: 0.0376 - val_loss: 0.1633 - val_sparse_categorical_accuracy: 0.9688 - val_sparse_categorical_crossentropy: 0.1633 - lr: 3.1250e-04\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9906 - sparse_categorical_crossentropy: 0.0351 - val_loss: 0.1632 - val_sparse_categorical_accuracy: 0.9682 - val_sparse_categorical_crossentropy: 0.1632 - lr: 3.1250e-04\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 40s 429ms/step - loss: 0.0356 - sparse_categorical_accuracy: 0.9900 - sparse_categorical_crossentropy: 0.0356 - val_loss: 0.1610 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1610 - lr: 3.1250e-04\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9908 - sparse_categorical_crossentropy: 0.0346 - val_loss: 0.1624 - val_sparse_categorical_accuracy: 0.9694 - val_sparse_categorical_crossentropy: 0.1624 - lr: 3.1250e-04\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9910 - sparse_categorical_crossentropy: 0.0344 - val_loss: 0.1633 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.1633 - lr: 3.1250e-04\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 40s 432ms/step - loss: 0.0327 - sparse_categorical_accuracy: 0.9908 - sparse_categorical_crossentropy: 0.0327 - val_loss: 0.1669 - val_sparse_categorical_accuracy: 0.9685 - val_sparse_categorical_crossentropy: 0.1669 - lr: 3.1250e-04\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9911 - sparse_categorical_crossentropy: 0.0324 - val_loss: 0.1645 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1645 - lr: 3.1250e-04\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 41s 433ms/step - loss: 0.0358 - sparse_categorical_accuracy: 0.9905 - sparse_categorical_crossentropy: 0.0358 - val_loss: 0.1574 - val_sparse_categorical_accuracy: 0.9705 - val_sparse_categorical_crossentropy: 0.1574 - lr: 3.1250e-04\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 41s 437ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9910 - sparse_categorical_crossentropy: 0.0342 - val_loss: 0.1682 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1682 - lr: 3.1250e-04\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0338 - sparse_categorical_accuracy: 0.9908 - sparse_categorical_crossentropy: 0.0338 - val_loss: 0.1695 - val_sparse_categorical_accuracy: 0.9698 - val_sparse_categorical_crossentropy: 0.1695 - lr: 3.1250e-04\n",
      "Epoch 53/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0345 - sparse_categorical_accuracy: 0.9909 - sparse_categorical_crossentropy: 0.0345\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.0345 - sparse_categorical_accuracy: 0.9909 - sparse_categorical_crossentropy: 0.0345 - val_loss: 0.1670 - val_sparse_categorical_accuracy: 0.9691 - val_sparse_categorical_crossentropy: 0.1670 - lr: 3.1250e-04\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 40s 430ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9916 - sparse_categorical_crossentropy: 0.0314 - val_loss: 0.1667 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1667 - lr: 1.5625e-04\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 40s 424ms/step - loss: 0.0325 - sparse_categorical_accuracy: 0.9910 - sparse_categorical_crossentropy: 0.0325 - val_loss: 0.1723 - val_sparse_categorical_accuracy: 0.9691 - val_sparse_categorical_crossentropy: 0.1723 - lr: 1.5625e-04\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 0.1920 - sparse_categorical_accuracy: 0.9653 - sparse_categorical_crossentropy: 0.1920\n",
      "26/26 [==============================] - 5s 141ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 45s 430ms/step - loss: 1.4242 - sparse_categorical_accuracy: 0.6278 - sparse_categorical_crossentropy: 1.4242 - val_loss: 1.6619 - val_sparse_categorical_accuracy: 0.6100 - val_sparse_categorical_crossentropy: 1.6619 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 39s 413ms/step - loss: 0.7472 - sparse_categorical_accuracy: 0.7641 - sparse_categorical_crossentropy: 0.7472 - val_loss: 1.6973 - val_sparse_categorical_accuracy: 0.6026 - val_sparse_categorical_crossentropy: 1.6973 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.4182 - sparse_categorical_accuracy: 0.8768 - sparse_categorical_crossentropy: 0.4182 - val_loss: 1.6308 - val_sparse_categorical_accuracy: 0.6267 - val_sparse_categorical_crossentropy: 1.6308 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.3219 - sparse_categorical_accuracy: 0.9079 - sparse_categorical_crossentropy: 0.3219 - val_loss: 1.6320 - val_sparse_categorical_accuracy: 0.6228 - val_sparse_categorical_crossentropy: 1.6320 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 40s 426ms/step - loss: 0.2827 - sparse_categorical_accuracy: 0.9205 - sparse_categorical_crossentropy: 0.2827 - val_loss: 1.6636 - val_sparse_categorical_accuracy: 0.5885 - val_sparse_categorical_crossentropy: 1.6636 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2696 - sparse_categorical_accuracy: 0.9232 - sparse_categorical_crossentropy: 0.2696\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.2697 - sparse_categorical_accuracy: 0.9232 - sparse_categorical_crossentropy: 0.2697 - val_loss: 1.8720 - val_sparse_categorical_accuracy: 0.5308 - val_sparse_categorical_crossentropy: 1.8720 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 39s 417ms/step - loss: 0.2221 - sparse_categorical_accuracy: 0.9386 - sparse_categorical_crossentropy: 0.2221 - val_loss: 1.1251 - val_sparse_categorical_accuracy: 0.7199 - val_sparse_categorical_crossentropy: 1.1251 - lr: 0.0050\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.1546 - sparse_categorical_accuracy: 0.9576 - sparse_categorical_crossentropy: 0.1546 - val_loss: 1.3325 - val_sparse_categorical_accuracy: 0.6923 - val_sparse_categorical_crossentropy: 1.3325 - lr: 0.0050\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.1528 - sparse_categorical_accuracy: 0.9578 - sparse_categorical_crossentropy: 0.1528 - val_loss: 0.8795 - val_sparse_categorical_accuracy: 0.7818 - val_sparse_categorical_crossentropy: 0.8795 - lr: 0.0050\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 39s 413ms/step - loss: 0.1357 - sparse_categorical_accuracy: 0.9626 - sparse_categorical_crossentropy: 0.1357 - val_loss: 0.1338 - val_sparse_categorical_accuracy: 0.9635 - val_sparse_categorical_crossentropy: 0.1338 - lr: 0.0050\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9642 - sparse_categorical_crossentropy: 0.1307 - val_loss: 0.3503 - val_sparse_categorical_accuracy: 0.9020 - val_sparse_categorical_crossentropy: 0.3503 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.1138 - sparse_categorical_accuracy: 0.9686 - sparse_categorical_crossentropy: 0.1138 - val_loss: 0.1908 - val_sparse_categorical_accuracy: 0.9478 - val_sparse_categorical_crossentropy: 0.1908 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1122 - sparse_categorical_accuracy: 0.9681 - sparse_categorical_crossentropy: 0.1122\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 40s 422ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9681 - sparse_categorical_crossentropy: 0.1122 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.8406 - val_sparse_categorical_crossentropy: 0.6007 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9742 - sparse_categorical_crossentropy: 0.0950 - val_loss: 0.1473 - val_sparse_categorical_accuracy: 0.9618 - val_sparse_categorical_crossentropy: 0.1473 - lr: 0.0025\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 40s 429ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9780 - sparse_categorical_crossentropy: 0.0816 - val_loss: 0.1443 - val_sparse_categorical_accuracy: 0.9645 - val_sparse_categorical_crossentropy: 0.1443 - lr: 0.0025\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.0795 - sparse_categorical_accuracy: 0.9775 - sparse_categorical_crossentropy: 0.0795 - val_loss: 0.1391 - val_sparse_categorical_accuracy: 0.9662 - val_sparse_categorical_crossentropy: 0.1391 - lr: 0.0025\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9764 - sparse_categorical_crossentropy: 0.0873 - val_loss: 0.1716 - val_sparse_categorical_accuracy: 0.9547 - val_sparse_categorical_crossentropy: 0.1716 - lr: 0.0025\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 40s 427ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9805 - sparse_categorical_crossentropy: 0.0717 - val_loss: 0.1903 - val_sparse_categorical_accuracy: 0.9513 - val_sparse_categorical_crossentropy: 0.1903 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0722 - sparse_categorical_accuracy: 0.9809 - sparse_categorical_crossentropy: 0.0722\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.0722 - sparse_categorical_accuracy: 0.9809 - sparse_categorical_crossentropy: 0.0722 - val_loss: 0.1472 - val_sparse_categorical_accuracy: 0.9644 - val_sparse_categorical_crossentropy: 0.1472 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9825 - sparse_categorical_crossentropy: 0.0656 - val_loss: 0.1171 - val_sparse_categorical_accuracy: 0.9734 - val_sparse_categorical_crossentropy: 0.1171 - lr: 0.0012\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 40s 425ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9835 - sparse_categorical_crossentropy: 0.0601 - val_loss: 0.1176 - val_sparse_categorical_accuracy: 0.9722 - val_sparse_categorical_crossentropy: 0.1176 - lr: 0.0012\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 39s 413ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9851 - sparse_categorical_crossentropy: 0.0555 - val_loss: 0.1227 - val_sparse_categorical_accuracy: 0.9730 - val_sparse_categorical_crossentropy: 0.1227 - lr: 0.0012\n",
      "Epoch 23/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0604 - sparse_categorical_accuracy: 0.9835 - sparse_categorical_crossentropy: 0.0604\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 40s 427ms/step - loss: 0.0604 - sparse_categorical_accuracy: 0.9835 - sparse_categorical_crossentropy: 0.0604 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9707 - val_sparse_categorical_crossentropy: 0.1229 - lr: 0.0012\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 39s 417ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9845 - sparse_categorical_crossentropy: 0.0565 - val_loss: 0.1292 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1292 - lr: 6.2500e-04\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 39s 414ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9861 - sparse_categorical_crossentropy: 0.0529 - val_loss: 0.1202 - val_sparse_categorical_accuracy: 0.9721 - val_sparse_categorical_crossentropy: 0.1202 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 4s 136ms/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9697 - sparse_categorical_crossentropy: 0.1384\n",
      "26/26 [==============================] - 5s 133ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 45s 432ms/step - loss: 1.5881 - sparse_categorical_accuracy: 0.6210 - sparse_categorical_crossentropy: 1.5881 - val_loss: 1.4348 - val_sparse_categorical_accuracy: 0.6301 - val_sparse_categorical_crossentropy: 1.4348 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 1.1074 - sparse_categorical_accuracy: 0.6845 - sparse_categorical_crossentropy: 1.1074 - val_loss: 1.5761 - val_sparse_categorical_accuracy: 0.6369 - val_sparse_categorical_crossentropy: 1.5761 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.5913 - sparse_categorical_accuracy: 0.8199 - sparse_categorical_crossentropy: 0.5913 - val_loss: 1.2685 - val_sparse_categorical_accuracy: 0.6731 - val_sparse_categorical_crossentropy: 1.2685 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 41s 434ms/step - loss: 0.4118 - sparse_categorical_accuracy: 0.8811 - sparse_categorical_crossentropy: 0.4118 - val_loss: 0.6009 - val_sparse_categorical_accuracy: 0.8316 - val_sparse_categorical_crossentropy: 0.6009 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 40s 430ms/step - loss: 0.3262 - sparse_categorical_accuracy: 0.9066 - sparse_categorical_crossentropy: 0.3262 - val_loss: 1.0912 - val_sparse_categorical_accuracy: 0.7150 - val_sparse_categorical_crossentropy: 1.0912 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.2731 - sparse_categorical_accuracy: 0.9234 - sparse_categorical_crossentropy: 0.2731 - val_loss: 0.8186 - val_sparse_categorical_accuracy: 0.7691 - val_sparse_categorical_crossentropy: 0.8186 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.2387 - sparse_categorical_accuracy: 0.9351 - sparse_categorical_crossentropy: 0.2387 - val_loss: 0.3872 - val_sparse_categorical_accuracy: 0.9004 - val_sparse_categorical_crossentropy: 0.3872 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.9326 - sparse_categorical_crossentropy: 0.2510 - val_loss: 0.2167 - val_sparse_categorical_accuracy: 0.9410 - val_sparse_categorical_crossentropy: 0.2167 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9458 - sparse_categorical_crossentropy: 0.1963 - val_loss: 0.3471 - val_sparse_categorical_accuracy: 0.9019 - val_sparse_categorical_crossentropy: 0.3471 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 40s 432ms/step - loss: 0.1793 - sparse_categorical_accuracy: 0.9505 - sparse_categorical_crossentropy: 0.1793 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8833 - val_sparse_categorical_crossentropy: 0.4226 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2964 - sparse_categorical_accuracy: 0.9192 - sparse_categorical_crossentropy: 0.2964\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.2964 - sparse_categorical_accuracy: 0.9192 - sparse_categorical_crossentropy: 0.2964 - val_loss: 0.7333 - val_sparse_categorical_accuracy: 0.7926 - val_sparse_categorical_crossentropy: 0.7333 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 40s 422ms/step - loss: 0.1696 - sparse_categorical_accuracy: 0.9526 - sparse_categorical_crossentropy: 0.1696 - val_loss: 0.1974 - val_sparse_categorical_accuracy: 0.9424 - val_sparse_categorical_crossentropy: 0.1974 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.1387 - sparse_categorical_accuracy: 0.9617 - sparse_categorical_crossentropy: 0.1387 - val_loss: 0.1484 - val_sparse_categorical_accuracy: 0.9595 - val_sparse_categorical_crossentropy: 0.1484 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.1482 - sparse_categorical_accuracy: 0.9605 - sparse_categorical_crossentropy: 0.1482 - val_loss: 0.1638 - val_sparse_categorical_accuracy: 0.9558 - val_sparse_categorical_crossentropy: 0.1638 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.1240 - sparse_categorical_accuracy: 0.9660 - sparse_categorical_crossentropy: 0.1240 - val_loss: 0.1555 - val_sparse_categorical_accuracy: 0.9575 - val_sparse_categorical_crossentropy: 0.1555 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.1302 - sparse_categorical_accuracy: 0.9647 - sparse_categorical_crossentropy: 0.1302 - val_loss: 0.1312 - val_sparse_categorical_accuracy: 0.9644 - val_sparse_categorical_crossentropy: 0.1312 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9702 - sparse_categorical_crossentropy: 0.1079 - val_loss: 0.1287 - val_sparse_categorical_accuracy: 0.9658 - val_sparse_categorical_crossentropy: 0.1287 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.1161 - sparse_categorical_accuracy: 0.9690 - sparse_categorical_crossentropy: 0.1161 - val_loss: 0.1312 - val_sparse_categorical_accuracy: 0.9635 - val_sparse_categorical_crossentropy: 0.1312 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 39s 422ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9727 - sparse_categorical_crossentropy: 0.1041 - val_loss: 0.1265 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1265 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 40s 429ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9744 - sparse_categorical_crossentropy: 0.0943 - val_loss: 0.1391 - val_sparse_categorical_accuracy: 0.9650 - val_sparse_categorical_crossentropy: 0.1391 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 41s 433ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9769 - sparse_categorical_crossentropy: 0.0877 - val_loss: 0.1303 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.1303 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 40s 428ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9751 - sparse_categorical_crossentropy: 0.0923 - val_loss: 0.1273 - val_sparse_categorical_accuracy: 0.9674 - val_sparse_categorical_crossentropy: 0.1273 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 39s 422ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9773 - sparse_categorical_crossentropy: 0.0870 - val_loss: 0.1527 - val_sparse_categorical_accuracy: 0.9668 - val_sparse_categorical_crossentropy: 0.1527 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0953 - sparse_categorical_accuracy: 0.9749 - sparse_categorical_crossentropy: 0.0953\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0955 - sparse_categorical_accuracy: 0.9748 - sparse_categorical_crossentropy: 0.0955 - val_loss: 0.1393 - val_sparse_categorical_accuracy: 0.9648 - val_sparse_categorical_crossentropy: 0.1393 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 41s 437ms/step - loss: 0.0878 - sparse_categorical_accuracy: 0.9759 - sparse_categorical_crossentropy: 0.0878 - val_loss: 0.1387 - val_sparse_categorical_accuracy: 0.9684 - val_sparse_categorical_crossentropy: 0.1387 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9813 - sparse_categorical_crossentropy: 0.0674 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9681 - val_sparse_categorical_crossentropy: 0.1407 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 40s 424ms/step - loss: 0.0702 - sparse_categorical_accuracy: 0.9813 - sparse_categorical_crossentropy: 0.0702 - val_loss: 0.1413 - val_sparse_categorical_accuracy: 0.9699 - val_sparse_categorical_crossentropy: 0.1413 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.0671 - sparse_categorical_accuracy: 0.9820 - sparse_categorical_crossentropy: 0.0671 - val_loss: 0.1450 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.1450 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 40s 429ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9841 - sparse_categorical_crossentropy: 0.0605 - val_loss: 0.1332 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.1332 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0633 - sparse_categorical_accuracy: 0.9838 - sparse_categorical_crossentropy: 0.0633\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 39s 422ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9838 - sparse_categorical_crossentropy: 0.0633 - val_loss: 0.1403 - val_sparse_categorical_accuracy: 0.9673 - val_sparse_categorical_crossentropy: 0.1403 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 40s 424ms/step - loss: 0.0522 - sparse_categorical_accuracy: 0.9867 - sparse_categorical_crossentropy: 0.0522 - val_loss: 0.1367 - val_sparse_categorical_accuracy: 0.9701 - val_sparse_categorical_crossentropy: 0.1367 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.0517 - sparse_categorical_accuracy: 0.9861 - sparse_categorical_crossentropy: 0.0517 - val_loss: 0.1394 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1394 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.0512 - sparse_categorical_accuracy: 0.9867 - sparse_categorical_crossentropy: 0.0512 - val_loss: 0.1357 - val_sparse_categorical_accuracy: 0.9710 - val_sparse_categorical_crossentropy: 0.1357 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 39s 416ms/step - loss: 0.0523 - sparse_categorical_accuracy: 0.9860 - sparse_categorical_crossentropy: 0.0523 - val_loss: 0.1384 - val_sparse_categorical_accuracy: 0.9707 - val_sparse_categorical_crossentropy: 0.1384 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 39s 417ms/step - loss: 0.0488 - sparse_categorical_accuracy: 0.9869 - sparse_categorical_crossentropy: 0.0488 - val_loss: 0.1358 - val_sparse_categorical_accuracy: 0.9713 - val_sparse_categorical_crossentropy: 0.1358 - lr: 0.0012\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 39s 419ms/step - loss: 0.0458 - sparse_categorical_accuracy: 0.9876 - sparse_categorical_crossentropy: 0.0458 - val_loss: 0.1395 - val_sparse_categorical_accuracy: 0.9713 - val_sparse_categorical_crossentropy: 0.1395 - lr: 0.0012\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 40s 423ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9875 - sparse_categorical_crossentropy: 0.0472 - val_loss: 0.1468 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.1468 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0462 - sparse_categorical_accuracy: 0.9879 - sparse_categorical_crossentropy: 0.0462\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 39s 417ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9879 - sparse_categorical_crossentropy: 0.0462 - val_loss: 0.1424 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.1424 - lr: 0.0012\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 40s 429ms/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9875 - sparse_categorical_crossentropy: 0.0461 - val_loss: 0.1356 - val_sparse_categorical_accuracy: 0.9731 - val_sparse_categorical_crossentropy: 0.1356 - lr: 6.2500e-04\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 40s 426ms/step - loss: 0.0444 - sparse_categorical_accuracy: 0.9887 - sparse_categorical_crossentropy: 0.0444 - val_loss: 0.1339 - val_sparse_categorical_accuracy: 0.9731 - val_sparse_categorical_crossentropy: 0.1339 - lr: 6.2500e-04\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 40s 424ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9880 - sparse_categorical_crossentropy: 0.0456 - val_loss: 0.1359 - val_sparse_categorical_accuracy: 0.9722 - val_sparse_categorical_crossentropy: 0.1359 - lr: 6.2500e-04\n",
      "Epoch 42/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0436 - sparse_categorical_accuracy: 0.9879 - sparse_categorical_crossentropy: 0.0436\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9879 - sparse_categorical_crossentropy: 0.0435 - val_loss: 0.1427 - val_sparse_categorical_accuracy: 0.9710 - val_sparse_categorical_crossentropy: 0.1427 - lr: 6.2500e-04\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.0416 - sparse_categorical_accuracy: 0.9888 - sparse_categorical_crossentropy: 0.0416 - val_loss: 0.1380 - val_sparse_categorical_accuracy: 0.9724 - val_sparse_categorical_crossentropy: 0.1380 - lr: 3.1250e-04\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 39s 415ms/step - loss: 0.0396 - sparse_categorical_accuracy: 0.9894 - sparse_categorical_crossentropy: 0.0396 - val_loss: 0.1396 - val_sparse_categorical_accuracy: 0.9713 - val_sparse_categorical_crossentropy: 0.1396 - lr: 3.1250e-04\n",
      "26/26 [==============================] - 4s 147ms/step - loss: 0.1554 - sparse_categorical_accuracy: 0.9700 - sparse_categorical_crossentropy: 0.1554\n",
      "26/26 [==============================] - 5s 141ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 46s 434ms/step - loss: 1.2831 - sparse_categorical_accuracy: 0.6465 - sparse_categorical_crossentropy: 1.2831 - val_loss: 0.9259 - val_sparse_categorical_accuracy: 0.7001 - val_sparse_categorical_crossentropy: 0.9259 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 39s 420ms/step - loss: 0.7584 - sparse_categorical_accuracy: 0.7703 - sparse_categorical_crossentropy: 0.7584 - val_loss: 0.9909 - val_sparse_categorical_accuracy: 0.7272 - val_sparse_categorical_crossentropy: 0.9909 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 41s 433ms/step - loss: 0.5701 - sparse_categorical_accuracy: 0.8344 - sparse_categorical_crossentropy: 0.5701 - val_loss: 0.5481 - val_sparse_categorical_accuracy: 0.8379 - val_sparse_categorical_crossentropy: 0.5481 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 40s 422ms/step - loss: 0.4505 - sparse_categorical_accuracy: 0.8708 - sparse_categorical_crossentropy: 0.4505 - val_loss: 0.3170 - val_sparse_categorical_accuracy: 0.9045 - val_sparse_categorical_crossentropy: 0.3170 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 39s 418ms/step - loss: 0.3647 - sparse_categorical_accuracy: 0.8960 - sparse_categorical_crossentropy: 0.3647 - val_loss: 0.2538 - val_sparse_categorical_accuracy: 0.9206 - val_sparse_categorical_crossentropy: 0.2538 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 40s 420ms/step - loss: 0.3302 - sparse_categorical_accuracy: 0.9070 - sparse_categorical_crossentropy: 0.3302 - val_loss: 0.2637 - val_sparse_categorical_accuracy: 0.9220 - val_sparse_categorical_crossentropy: 0.2637 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 39s 421ms/step - loss: 0.3195 - sparse_categorical_accuracy: 0.9100 - sparse_categorical_crossentropy: 0.3195 - val_loss: 0.2117 - val_sparse_categorical_accuracy: 0.9383 - val_sparse_categorical_crossentropy: 0.2117 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 41s 434ms/step - loss: 0.2760 - sparse_categorical_accuracy: 0.9232 - sparse_categorical_crossentropy: 0.2760 - val_loss: 0.2104 - val_sparse_categorical_accuracy: 0.9377 - val_sparse_categorical_crossentropy: 0.2104 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 40s 422ms/step - loss: 0.2690 - sparse_categorical_accuracy: 0.9251 - sparse_categorical_crossentropy: 0.2690 - val_loss: 0.2608 - val_sparse_categorical_accuracy: 0.9228 - val_sparse_categorical_crossentropy: 0.2608 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 44s 468ms/step - loss: 0.2508 - sparse_categorical_accuracy: 0.9311 - sparse_categorical_crossentropy: 0.2508 - val_loss: 0.1683 - val_sparse_categorical_accuracy: 0.9519 - val_sparse_categorical_crossentropy: 0.1683 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 44s 473ms/step - loss: 0.2288 - sparse_categorical_accuracy: 0.9370 - sparse_categorical_crossentropy: 0.2288 - val_loss: 0.1764 - val_sparse_categorical_accuracy: 0.9501 - val_sparse_categorical_crossentropy: 0.1764 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 44s 474ms/step - loss: 0.2161 - sparse_categorical_accuracy: 0.9392 - sparse_categorical_crossentropy: 0.2161 - val_loss: 0.1653 - val_sparse_categorical_accuracy: 0.9513 - val_sparse_categorical_crossentropy: 0.1653 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1985 - sparse_categorical_accuracy: 0.9441 - sparse_categorical_crossentropy: 0.1985\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 44s 473ms/step - loss: 0.1984 - sparse_categorical_accuracy: 0.9441 - sparse_categorical_crossentropy: 0.1984 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9516 - val_sparse_categorical_crossentropy: 0.1796 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 44s 474ms/step - loss: 0.1526 - sparse_categorical_accuracy: 0.9569 - sparse_categorical_crossentropy: 0.1526 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9621 - val_sparse_categorical_crossentropy: 0.1407 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 41s 437ms/step - loss: 0.1281 - sparse_categorical_accuracy: 0.9638 - sparse_categorical_crossentropy: 0.1281 - val_loss: 0.1403 - val_sparse_categorical_accuracy: 0.9636 - val_sparse_categorical_crossentropy: 0.1403 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 44s 473ms/step - loss: 0.1239 - sparse_categorical_accuracy: 0.9659 - sparse_categorical_crossentropy: 0.1239 - val_loss: 0.1352 - val_sparse_categorical_accuracy: 0.9639 - val_sparse_categorical_crossentropy: 0.1352 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 44s 479ms/step - loss: 0.1247 - sparse_categorical_accuracy: 0.9662 - sparse_categorical_crossentropy: 0.1247 - val_loss: 0.1486 - val_sparse_categorical_accuracy: 0.9607 - val_sparse_categorical_crossentropy: 0.1486 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 45s 484ms/step - loss: 0.1233 - sparse_categorical_accuracy: 0.9658 - sparse_categorical_crossentropy: 0.1233 - val_loss: 0.1404 - val_sparse_categorical_accuracy: 0.9651 - val_sparse_categorical_crossentropy: 0.1404 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 44s 481ms/step - loss: 0.1139 - sparse_categorical_accuracy: 0.9687 - sparse_categorical_crossentropy: 0.1139 - val_loss: 0.1521 - val_sparse_categorical_accuracy: 0.9599 - val_sparse_categorical_crossentropy: 0.1521 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 45s 482ms/step - loss: 0.1363 - sparse_categorical_accuracy: 0.9617 - sparse_categorical_crossentropy: 0.1363 - val_loss: 0.1340 - val_sparse_categorical_accuracy: 0.9639 - val_sparse_categorical_crossentropy: 0.1340 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1096 - sparse_categorical_accuracy: 0.9693 - sparse_categorical_crossentropy: 0.1096\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 45s 482ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9692 - sparse_categorical_crossentropy: 0.1096 - val_loss: 0.1380 - val_sparse_categorical_accuracy: 0.9648 - val_sparse_categorical_crossentropy: 0.1380 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 45s 486ms/step - loss: 0.0929 - sparse_categorical_accuracy: 0.9745 - sparse_categorical_crossentropy: 0.0929 - val_loss: 0.1278 - val_sparse_categorical_accuracy: 0.9678 - val_sparse_categorical_crossentropy: 0.1278 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 46s 493ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9769 - sparse_categorical_crossentropy: 0.0832 - val_loss: 0.1402 - val_sparse_categorical_accuracy: 0.9667 - val_sparse_categorical_crossentropy: 0.1402 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 46s 494ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9769 - sparse_categorical_crossentropy: 0.0831 - val_loss: 0.1409 - val_sparse_categorical_accuracy: 0.9639 - val_sparse_categorical_crossentropy: 0.1409 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0992 - sparse_categorical_accuracy: 0.9727 - sparse_categorical_crossentropy: 0.0992\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 47s 505ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9727 - sparse_categorical_crossentropy: 0.0992 - val_loss: 0.1335 - val_sparse_categorical_accuracy: 0.9641 - val_sparse_categorical_crossentropy: 0.1335 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 46s 501ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9779 - sparse_categorical_crossentropy: 0.0801 - val_loss: 0.1220 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1220 - lr: 0.0012\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 46s 495ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9804 - sparse_categorical_crossentropy: 0.0726 - val_loss: 0.1243 - val_sparse_categorical_accuracy: 0.9701 - val_sparse_categorical_crossentropy: 0.1243 - lr: 0.0012\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 45s 487ms/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9809 - sparse_categorical_crossentropy: 0.0698 - val_loss: 0.1277 - val_sparse_categorical_accuracy: 0.9696 - val_sparse_categorical_crossentropy: 0.1277 - lr: 0.0012\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 44s 478ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9811 - sparse_categorical_crossentropy: 0.0714 - val_loss: 0.1234 - val_sparse_categorical_accuracy: 0.9693 - val_sparse_categorical_crossentropy: 0.1234 - lr: 0.0012\n",
      "Epoch 30/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0671 - sparse_categorical_accuracy: 0.9821 - sparse_categorical_crossentropy: 0.0671\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 42s 450ms/step - loss: 0.0671 - sparse_categorical_accuracy: 0.9821 - sparse_categorical_crossentropy: 0.0671 - val_loss: 0.1293 - val_sparse_categorical_accuracy: 0.9687 - val_sparse_categorical_crossentropy: 0.1293 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 41s 445ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9825 - sparse_categorical_crossentropy: 0.0645 - val_loss: 0.1293 - val_sparse_categorical_accuracy: 0.9691 - val_sparse_categorical_crossentropy: 0.1293 - lr: 6.2500e-04\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 41s 448ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9832 - sparse_categorical_crossentropy: 0.0617 - val_loss: 0.1275 - val_sparse_categorical_accuracy: 0.9681 - val_sparse_categorical_crossentropy: 0.1275 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.1399 - sparse_categorical_accuracy: 0.9674 - sparse_categorical_crossentropy: 0.1399\n",
      "26/26 [==============================] - 4s 115ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 48s 462ms/step - loss: 1.2449 - sparse_categorical_accuracy: 0.6526 - sparse_categorical_crossentropy: 1.2449 - val_loss: 0.9826 - val_sparse_categorical_accuracy: 0.7201 - val_sparse_categorical_crossentropy: 0.9826 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 42s 454ms/step - loss: 0.6462 - sparse_categorical_accuracy: 0.8050 - sparse_categorical_crossentropy: 0.6462 - val_loss: 0.5086 - val_sparse_categorical_accuracy: 0.8399 - val_sparse_categorical_crossentropy: 0.5086 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 42s 452ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.8682 - sparse_categorical_crossentropy: 0.4526 - val_loss: 0.3234 - val_sparse_categorical_accuracy: 0.9005 - val_sparse_categorical_crossentropy: 0.3234 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 41s 445ms/step - loss: 0.3787 - sparse_categorical_accuracy: 0.8912 - sparse_categorical_crossentropy: 0.3787 - val_loss: 0.5899 - val_sparse_categorical_accuracy: 0.8247 - val_sparse_categorical_crossentropy: 0.5899 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 42s 453ms/step - loss: 0.3441 - sparse_categorical_accuracy: 0.9030 - sparse_categorical_crossentropy: 0.3441 - val_loss: 0.2463 - val_sparse_categorical_accuracy: 0.9295 - val_sparse_categorical_crossentropy: 0.2463 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 41s 448ms/step - loss: 0.2926 - sparse_categorical_accuracy: 0.9177 - sparse_categorical_crossentropy: 0.2926 - val_loss: 0.2599 - val_sparse_categorical_accuracy: 0.9222 - val_sparse_categorical_crossentropy: 0.2599 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 41s 446ms/step - loss: 0.2656 - sparse_categorical_accuracy: 0.9255 - sparse_categorical_crossentropy: 0.2656 - val_loss: 0.2290 - val_sparse_categorical_accuracy: 0.9380 - val_sparse_categorical_crossentropy: 0.2290 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 41s 447ms/step - loss: 0.2446 - sparse_categorical_accuracy: 0.9310 - sparse_categorical_crossentropy: 0.2446 - val_loss: 0.1973 - val_sparse_categorical_accuracy: 0.9418 - val_sparse_categorical_crossentropy: 0.1973 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 42s 449ms/step - loss: 0.2201 - sparse_categorical_accuracy: 0.9385 - sparse_categorical_crossentropy: 0.2201 - val_loss: 0.2217 - val_sparse_categorical_accuracy: 0.9395 - val_sparse_categorical_crossentropy: 0.2217 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 42s 449ms/step - loss: 0.2146 - sparse_categorical_accuracy: 0.9400 - sparse_categorical_crossentropy: 0.2146 - val_loss: 0.1750 - val_sparse_categorical_accuracy: 0.9516 - val_sparse_categorical_crossentropy: 0.1750 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 42s 459ms/step - loss: 0.2058 - sparse_categorical_accuracy: 0.9425 - sparse_categorical_crossentropy: 0.2058 - val_loss: 0.2644 - val_sparse_categorical_accuracy: 0.9232 - val_sparse_categorical_crossentropy: 0.2644 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 42s 451ms/step - loss: 0.2215 - sparse_categorical_accuracy: 0.9367 - sparse_categorical_crossentropy: 0.2215 - val_loss: 0.1711 - val_sparse_categorical_accuracy: 0.9539 - val_sparse_categorical_crossentropy: 0.1711 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 42s 458ms/step - loss: 0.1885 - sparse_categorical_accuracy: 0.9485 - sparse_categorical_crossentropy: 0.1885 - val_loss: 0.1720 - val_sparse_categorical_accuracy: 0.9526 - val_sparse_categorical_crossentropy: 0.1720 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 42s 450ms/step - loss: 0.1846 - sparse_categorical_accuracy: 0.9496 - sparse_categorical_crossentropy: 0.1846 - val_loss: 0.1601 - val_sparse_categorical_accuracy: 0.9550 - val_sparse_categorical_crossentropy: 0.1601 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 41s 447ms/step - loss: 0.1722 - sparse_categorical_accuracy: 0.9525 - sparse_categorical_crossentropy: 0.1722 - val_loss: 0.1683 - val_sparse_categorical_accuracy: 0.9533 - val_sparse_categorical_crossentropy: 0.1683 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 45s 487ms/step - loss: 0.1553 - sparse_categorical_accuracy: 0.9564 - sparse_categorical_crossentropy: 0.1553 - val_loss: 0.1676 - val_sparse_categorical_accuracy: 0.9558 - val_sparse_categorical_crossentropy: 0.1676 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 45s 483ms/step - loss: 0.1527 - sparse_categorical_accuracy: 0.9579 - sparse_categorical_crossentropy: 0.1527 - val_loss: 0.1609 - val_sparse_categorical_accuracy: 0.9553 - val_sparse_categorical_crossentropy: 0.1609 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 45s 486ms/step - loss: 0.1485 - sparse_categorical_accuracy: 0.9587 - sparse_categorical_crossentropy: 0.1485 - val_loss: 0.1762 - val_sparse_categorical_accuracy: 0.9562 - val_sparse_categorical_crossentropy: 0.1762 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 45s 482ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9584 - sparse_categorical_crossentropy: 0.1508 - val_loss: 0.1526 - val_sparse_categorical_accuracy: 0.9602 - val_sparse_categorical_crossentropy: 0.1526 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 45s 483ms/step - loss: 0.1270 - sparse_categorical_accuracy: 0.9653 - sparse_categorical_crossentropy: 0.1270 - val_loss: 0.1428 - val_sparse_categorical_accuracy: 0.9599 - val_sparse_categorical_crossentropy: 0.1428 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 45s 485ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9658 - sparse_categorical_crossentropy: 0.1301 - val_loss: 0.1615 - val_sparse_categorical_accuracy: 0.9642 - val_sparse_categorical_crossentropy: 0.1615 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 45s 485ms/step - loss: 0.1295 - sparse_categorical_accuracy: 0.9644 - sparse_categorical_crossentropy: 0.1295 - val_loss: 0.1459 - val_sparse_categorical_accuracy: 0.9644 - val_sparse_categorical_crossentropy: 0.1459 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 45s 485ms/step - loss: 0.1259 - sparse_categorical_accuracy: 0.9655 - sparse_categorical_crossentropy: 0.1259 - val_loss: 0.1498 - val_sparse_categorical_accuracy: 0.9627 - val_sparse_categorical_crossentropy: 0.1498 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 41s 447ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9681 - sparse_categorical_crossentropy: 0.1196 - val_loss: 0.1377 - val_sparse_categorical_accuracy: 0.9635 - val_sparse_categorical_crossentropy: 0.1377 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1186 - sparse_categorical_accuracy: 0.9682 - sparse_categorical_crossentropy: 0.1186\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 41s 445ms/step - loss: 0.1186 - sparse_categorical_accuracy: 0.9682 - sparse_categorical_crossentropy: 0.1186 - val_loss: 0.1473 - val_sparse_categorical_accuracy: 0.9644 - val_sparse_categorical_crossentropy: 0.1473 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 40s 432ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9725 - sparse_categorical_crossentropy: 0.1011 - val_loss: 0.1295 - val_sparse_categorical_accuracy: 0.9670 - val_sparse_categorical_crossentropy: 0.1295 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 41s 447ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9780 - sparse_categorical_crossentropy: 0.0800 - val_loss: 0.1282 - val_sparse_categorical_accuracy: 0.9676 - val_sparse_categorical_crossentropy: 0.1282 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 41s 448ms/step - loss: 0.0796 - sparse_categorical_accuracy: 0.9784 - sparse_categorical_crossentropy: 0.0796 - val_loss: 0.1226 - val_sparse_categorical_accuracy: 0.9701 - val_sparse_categorical_crossentropy: 0.1226 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 41s 444ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9801 - sparse_categorical_crossentropy: 0.0739 - val_loss: 0.1395 - val_sparse_categorical_accuracy: 0.9665 - val_sparse_categorical_crossentropy: 0.1395 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 41s 446ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9798 - sparse_categorical_crossentropy: 0.0746 - val_loss: 0.1267 - val_sparse_categorical_accuracy: 0.9691 - val_sparse_categorical_crossentropy: 0.1267 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 41s 445ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9814 - sparse_categorical_crossentropy: 0.0685 - val_loss: 0.1325 - val_sparse_categorical_accuracy: 0.9707 - val_sparse_categorical_crossentropy: 0.1325 - lr: 0.0050\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 42s 450ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9825 - sparse_categorical_crossentropy: 0.0650 - val_loss: 0.1388 - val_sparse_categorical_accuracy: 0.9704 - val_sparse_categorical_crossentropy: 0.1388 - lr: 0.0050\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 42s 456ms/step - loss: 0.0702 - sparse_categorical_accuracy: 0.9810 - sparse_categorical_crossentropy: 0.0702 - val_loss: 0.1436 - val_sparse_categorical_accuracy: 0.9667 - val_sparse_categorical_crossentropy: 0.1436 - lr: 0.0050\n",
      "Epoch 34/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0651 - sparse_categorical_accuracy: 0.9826 - sparse_categorical_crossentropy: 0.0651\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 42s 455ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9826 - sparse_categorical_crossentropy: 0.0650 - val_loss: 0.1570 - val_sparse_categorical_accuracy: 0.9642 - val_sparse_categorical_crossentropy: 0.1570 - lr: 0.0050\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 42s 454ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9840 - sparse_categorical_crossentropy: 0.0583 - val_loss: 0.1416 - val_sparse_categorical_accuracy: 0.9702 - val_sparse_categorical_crossentropy: 0.1416 - lr: 0.0025\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 42s 453ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9847 - sparse_categorical_crossentropy: 0.0549 - val_loss: 0.1326 - val_sparse_categorical_accuracy: 0.9724 - val_sparse_categorical_crossentropy: 0.1326 - lr: 0.0025\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 42s 454ms/step - loss: 0.0503 - sparse_categorical_accuracy: 0.9868 - sparse_categorical_crossentropy: 0.0503 - val_loss: 0.1234 - val_sparse_categorical_accuracy: 0.9721 - val_sparse_categorical_crossentropy: 0.1234 - lr: 0.0025\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 43s 461ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9863 - sparse_categorical_crossentropy: 0.0504 - val_loss: 0.1251 - val_sparse_categorical_accuracy: 0.9722 - val_sparse_categorical_crossentropy: 0.1251 - lr: 0.0025\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 42s 457ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9868 - sparse_categorical_crossentropy: 0.0493 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9734 - val_sparse_categorical_crossentropy: 0.1350 - lr: 0.0025\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 42s 457ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9860 - sparse_categorical_crossentropy: 0.0505 - val_loss: 0.1276 - val_sparse_categorical_accuracy: 0.9721 - val_sparse_categorical_crossentropy: 0.1276 - lr: 0.0025\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 42s 454ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9875 - sparse_categorical_crossentropy: 0.0454 - val_loss: 0.1259 - val_sparse_categorical_accuracy: 0.9724 - val_sparse_categorical_crossentropy: 0.1259 - lr: 0.0025\n",
      "Epoch 42/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0473 - sparse_categorical_accuracy: 0.9869 - sparse_categorical_crossentropy: 0.0473\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 42s 456ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9869 - sparse_categorical_crossentropy: 0.0473 - val_loss: 0.1380 - val_sparse_categorical_accuracy: 0.9707 - val_sparse_categorical_crossentropy: 0.1380 - lr: 0.0025\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 42s 449ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9876 - sparse_categorical_crossentropy: 0.0453 - val_loss: 0.1344 - val_sparse_categorical_accuracy: 0.9727 - val_sparse_categorical_crossentropy: 0.1344 - lr: 0.0012\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 42s 449ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9879 - sparse_categorical_crossentropy: 0.0443 - val_loss: 0.1371 - val_sparse_categorical_accuracy: 0.9719 - val_sparse_categorical_crossentropy: 0.1371 - lr: 0.0012\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.1593 - sparse_categorical_accuracy: 0.9691 - sparse_categorical_crossentropy: 0.1593\n",
      "26/26 [==============================] - 4s 114ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 48s 466ms/step - loss: 1.6029 - sparse_categorical_accuracy: 0.6225 - sparse_categorical_crossentropy: 1.6029 - val_loss: 1.5426 - val_sparse_categorical_accuracy: 0.6301 - val_sparse_categorical_crossentropy: 1.5426 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 42s 453ms/step - loss: 1.5316 - sparse_categorical_accuracy: 0.6299 - sparse_categorical_crossentropy: 1.5316 - val_loss: 1.4638 - val_sparse_categorical_accuracy: 0.6301 - val_sparse_categorical_crossentropy: 1.4638 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 42s 454ms/step - loss: 1.1777 - sparse_categorical_accuracy: 0.6664 - sparse_categorical_crossentropy: 1.1777 - val_loss: 0.7422 - val_sparse_categorical_accuracy: 0.7708 - val_sparse_categorical_crossentropy: 0.7422 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 42s 449ms/step - loss: 0.7436 - sparse_categorical_accuracy: 0.7747 - sparse_categorical_crossentropy: 0.7436 - val_loss: 1.6025 - val_sparse_categorical_accuracy: 0.6310 - val_sparse_categorical_crossentropy: 1.6025 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 42s 458ms/step - loss: 0.5905 - sparse_categorical_accuracy: 0.8264 - sparse_categorical_crossentropy: 0.5905 - val_loss: 0.4002 - val_sparse_categorical_accuracy: 0.8795 - val_sparse_categorical_crossentropy: 0.4002 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 42s 453ms/step - loss: 0.5199 - sparse_categorical_accuracy: 0.8488 - sparse_categorical_crossentropy: 0.5199 - val_loss: 0.3524 - val_sparse_categorical_accuracy: 0.8934 - val_sparse_categorical_crossentropy: 0.3524 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 41s 447ms/step - loss: 0.4386 - sparse_categorical_accuracy: 0.8724 - sparse_categorical_crossentropy: 0.4386 - val_loss: 0.2816 - val_sparse_categorical_accuracy: 0.9109 - val_sparse_categorical_crossentropy: 0.2816 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 42s 456ms/step - loss: 0.3978 - sparse_categorical_accuracy: 0.8856 - sparse_categorical_crossentropy: 0.3978 - val_loss: 0.3427 - val_sparse_categorical_accuracy: 0.8947 - val_sparse_categorical_crossentropy: 0.3427 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 42s 451ms/step - loss: 0.3647 - sparse_categorical_accuracy: 0.8958 - sparse_categorical_crossentropy: 0.3647 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8637 - val_sparse_categorical_crossentropy: 0.4359 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 42s 449ms/step - loss: 0.3908 - sparse_categorical_accuracy: 0.8889 - sparse_categorical_crossentropy: 0.3908 - val_loss: 0.2292 - val_sparse_categorical_accuracy: 0.9323 - val_sparse_categorical_crossentropy: 0.2292 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 42s 448ms/step - loss: 0.3029 - sparse_categorical_accuracy: 0.9136 - sparse_categorical_crossentropy: 0.3029 - val_loss: 0.2300 - val_sparse_categorical_accuracy: 0.9332 - val_sparse_categorical_crossentropy: 0.2300 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 42s 451ms/step - loss: 0.2890 - sparse_categorical_accuracy: 0.9180 - sparse_categorical_crossentropy: 0.2890 - val_loss: 0.2141 - val_sparse_categorical_accuracy: 0.9349 - val_sparse_categorical_crossentropy: 0.2141 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 42s 453ms/step - loss: 0.2673 - sparse_categorical_accuracy: 0.9236 - sparse_categorical_crossentropy: 0.2673 - val_loss: 0.1997 - val_sparse_categorical_accuracy: 0.9427 - val_sparse_categorical_crossentropy: 0.1997 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 42s 452ms/step - loss: 0.2588 - sparse_categorical_accuracy: 0.9276 - sparse_categorical_crossentropy: 0.2588 - val_loss: 0.1926 - val_sparse_categorical_accuracy: 0.9443 - val_sparse_categorical_crossentropy: 0.1926 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 42s 453ms/step - loss: 0.2495 - sparse_categorical_accuracy: 0.9297 - sparse_categorical_crossentropy: 0.2495 - val_loss: 0.1960 - val_sparse_categorical_accuracy: 0.9444 - val_sparse_categorical_crossentropy: 0.1960 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 42s 452ms/step - loss: 0.2608 - sparse_categorical_accuracy: 0.9279 - sparse_categorical_crossentropy: 0.2608 - val_loss: 0.2071 - val_sparse_categorical_accuracy: 0.9375 - val_sparse_categorical_crossentropy: 0.2071 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 42s 453ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.9318 - sparse_categorical_crossentropy: 0.2389 - val_loss: 0.1985 - val_sparse_categorical_accuracy: 0.9443 - val_sparse_categorical_crossentropy: 0.1985 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2419 - sparse_categorical_accuracy: 0.9315 - sparse_categorical_crossentropy: 0.2419\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 42s 453ms/step - loss: 0.2420 - sparse_categorical_accuracy: 0.9315 - sparse_categorical_crossentropy: 0.2420 - val_loss: 0.2284 - val_sparse_categorical_accuracy: 0.9374 - val_sparse_categorical_crossentropy: 0.2284 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 42s 452ms/step - loss: 0.2027 - sparse_categorical_accuracy: 0.9435 - sparse_categorical_crossentropy: 0.2027 - val_loss: 0.1795 - val_sparse_categorical_accuracy: 0.9513 - val_sparse_categorical_crossentropy: 0.1795 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 42s 452ms/step - loss: 0.1642 - sparse_categorical_accuracy: 0.9540 - sparse_categorical_crossentropy: 0.1642 - val_loss: 0.1673 - val_sparse_categorical_accuracy: 0.9526 - val_sparse_categorical_crossentropy: 0.1673 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 42s 452ms/step - loss: 0.1580 - sparse_categorical_accuracy: 0.9565 - sparse_categorical_crossentropy: 0.1580 - val_loss: 0.1695 - val_sparse_categorical_accuracy: 0.9536 - val_sparse_categorical_crossentropy: 0.1695 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 43s 462ms/step - loss: 0.1460 - sparse_categorical_accuracy: 0.9594 - sparse_categorical_crossentropy: 0.1460 - val_loss: 0.1649 - val_sparse_categorical_accuracy: 0.9567 - val_sparse_categorical_crossentropy: 0.1649 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 41s 442ms/step - loss: 0.1444 - sparse_categorical_accuracy: 0.9607 - sparse_categorical_crossentropy: 0.1444 - val_loss: 0.1578 - val_sparse_categorical_accuracy: 0.9558 - val_sparse_categorical_crossentropy: 0.1578 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 42s 445ms/step - loss: 0.1483 - sparse_categorical_accuracy: 0.9592 - sparse_categorical_crossentropy: 0.1483 - val_loss: 0.1675 - val_sparse_categorical_accuracy: 0.9553 - val_sparse_categorical_crossentropy: 0.1675 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1446 - sparse_categorical_accuracy: 0.9583 - sparse_categorical_crossentropy: 0.1446\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 44s 470ms/step - loss: 0.1446 - sparse_categorical_accuracy: 0.9583 - sparse_categorical_crossentropy: 0.1446 - val_loss: 0.1596 - val_sparse_categorical_accuracy: 0.9532 - val_sparse_categorical_crossentropy: 0.1596 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 44s 477ms/step - loss: 0.1224 - sparse_categorical_accuracy: 0.9660 - sparse_categorical_crossentropy: 0.1224 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9604 - val_sparse_categorical_crossentropy: 0.1538 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 45s 483ms/step - loss: 0.1166 - sparse_categorical_accuracy: 0.9687 - sparse_categorical_crossentropy: 0.1166 - val_loss: 0.1596 - val_sparse_categorical_accuracy: 0.9585 - val_sparse_categorical_crossentropy: 0.1596 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 42s 456ms/step - loss: 0.1114 - sparse_categorical_accuracy: 0.9683 - sparse_categorical_crossentropy: 0.1114 - val_loss: 0.1535 - val_sparse_categorical_accuracy: 0.9592 - val_sparse_categorical_crossentropy: 0.1535 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1054 - sparse_categorical_accuracy: 0.9704 - sparse_categorical_crossentropy: 0.1054\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 41s 443ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9704 - sparse_categorical_crossentropy: 0.1054 - val_loss: 0.1616 - val_sparse_categorical_accuracy: 0.9573 - val_sparse_categorical_crossentropy: 0.1616 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 42s 456ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9714 - sparse_categorical_crossentropy: 0.1010 - val_loss: 0.1519 - val_sparse_categorical_accuracy: 0.9599 - val_sparse_categorical_crossentropy: 0.1519 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 44s 478ms/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9736 - sparse_categorical_crossentropy: 0.0965 - val_loss: 0.1634 - val_sparse_categorical_accuracy: 0.9590 - val_sparse_categorical_crossentropy: 0.1634 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.1753 - sparse_categorical_accuracy: 0.9554 - sparse_categorical_crossentropy: 0.1753\n",
      "26/26 [==============================] - 5s 142ms/step\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(5))\n",
    "\n",
    "for aug in [\"time\", \"freq\"]:\n",
    "    results = []\n",
    "    EXPERIMENT_NAME = f\"article_net_{aug}\"\n",
    "    if os.path.exists(EXPERIMENT_NAME):\n",
    "        shutil.rmtree(EXPERIMENT_NAME)\n",
    "        os.mkdir(EXPERIMENT_NAME)\n",
    "    else:\n",
    "        os.mkdir(EXPERIMENT_NAME)\n",
    "\n",
    "    for seed in TRAINING_SEEDS:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        if aug == \"time\":\n",
    "            model = create_model(time=True)\n",
    "        else:\n",
    "            model = create_model(freq=True)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "            loss=losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=MAX_EPOCHS,\n",
    "            validation_data=val_ds,\n",
    "            shuffle=True,\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "\n",
    "        with open(os.path.join(EXPERIMENT_NAME, f\"history_{seed}.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(history.history, file)\n",
    "\n",
    "        eval_results = model.evaluate(test_ds)\n",
    "\n",
    "        predictions = model.predict(test_ds)\n",
    "        with open(os.path.join(EXPERIMENT_NAME, f\"predictions_{seed}.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(predictions, file)\n",
    "\n",
    "        results += [{\n",
    "            'seed': seed,\n",
    "            'results': dict(zip(model.metrics_names, eval_results))\n",
    "        }]\n",
    "        gc.collect()\n",
    "\n",
    "    results_temp = pd.DataFrame(results)\n",
    "    results_df = pd.concat([results_temp.drop([\"results\"], axis=1), results_temp[\"results\"].apply(pd.Series)], axis=1)\n",
    "    results_df.to_csv(os.path.join(EXPERIMENT_NAME, 'results.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T06:47:49.297941Z",
     "end_time": "2023-04-24T10:41:46.406449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   seed      loss  sparse_categorical_accuracy  \\\n0     0  0.138397                     0.969671   \n1     1  0.155362                     0.969979   \n2     2  0.139853                     0.967368   \n3     3  0.159299                     0.969134   \n4     4  0.175304                     0.955390   \n\n   sparse_categorical_crossentropy  \n0                         0.138397  \n1                         0.155362  \n2                         0.139853  \n3                         0.159299  \n4                         0.175304  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed</th>\n      <th>loss</th>\n      <th>sparse_categorical_accuracy</th>\n      <th>sparse_categorical_crossentropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.138397</td>\n      <td>0.969671</td>\n      <td>0.138397</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.155362</td>\n      <td>0.969979</td>\n      <td>0.155362</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.139853</td>\n      <td>0.967368</td>\n      <td>0.139853</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.159299</td>\n      <td>0.969134</td>\n      <td>0.159299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.175304</td>\n      <td>0.955390</td>\n      <td>0.175304</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T10:41:46.408442Z",
     "end_time": "2023-04-24T10:41:46.422399Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
