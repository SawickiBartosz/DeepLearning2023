{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T22:17:51.121667Z",
     "end_time": "2023-04-23T22:17:54.655143Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import losses, optimizers, metrics, callbacks\n",
    "\n",
    "import SpeechModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T22:17:54.656139Z",
     "end_time": "2023-04-23T22:17:55.161978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T22:17:55.162975Z",
     "end_time": "2023-04-23T22:17:55.208458Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 12\n",
    "MAX_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T22:17:55.180552Z",
     "end_time": "2023-04-23T22:17:55.216432Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45586 files belonging to 12 classes.\n",
      "Found 6513 files belonging to 12 classes.\n",
      "Found 13024 files belonging to 12 classes.\n",
      "label names: ['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/train\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/val\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/test\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print(\"label names:\", label_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:17:55.194505Z",
     "end_time": "2023-04-23T22:18:00.717440Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio, labels\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(squeeze, tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:18:00.719433Z",
     "end_time": "2023-04-23T22:18:00.765280Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model from article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " normalized_spectrogram_model (  (None, None, 80)    0           ['input[0][0]']                  \n",
      " Functional)                                                                                      \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, None, 80, 1)  0           ['normalized_spectrogram_model[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, None, 80, 10  60          ['tf.expand_dims[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, None, 80, 10  40         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, None, 80, 1)  51          ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, None, 80, 1)  4          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " squeeze_last_dim (Lambda)      (None, None, 80)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, None, 128)    74240       ['squeeze_last_dim[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, None, 128)   98816       ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 128)          0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          16512       ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, None)         0           ['dense[0][0]',                  \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " attSoftmax (Softmax)           (None, None)         0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 128)          0           ['attSoftmax[0][0]',             \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 12)           396         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 200,455\n",
      "Trainable params: 200,433\n",
      "Non-trainable params: 22\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SpeechModels.AttRNNSpeechModel(N_CLASS, samplingrate=16000, inputLength=None)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:18:00.766277Z",
     "end_time": "2023-04-23T22:18:01.816763Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "weights = {\n",
    "    0: 27.606189,\n",
    "    1: 27.454890,\n",
    "    2: 27.676583,\n",
    "    3: 27.420211,\n",
    "    4: 27.629614,\n",
    "    5: 27.512886,\n",
    "    6: 27.512886,\n",
    "    7: 161.997512,\n",
    "    8: 27.362605,\n",
    "    9: 1.586856,\n",
    "    10: 27.420211,\n",
    "    11: 27.397139\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:18:01.792842Z",
     "end_time": "2023-04-23T22:18:01.818756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T22:18:01.801813Z",
     "end_time": "2023-04-23T22:18:01.830716Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=3,\n",
    "                                        min_lr=0.00001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T22:18:01.833705Z",
     "end_time": "2023-04-23T22:18:50.736897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "90/90 [==============================] - 33s 185ms/step - loss: 17.1710 - sparse_categorical_accuracy: 0.3431 - sparse_categorical_crossentropy: 1.8149 - val_loss: 1.3042 - val_sparse_categorical_accuracy: 0.6059 - val_sparse_categorical_crossentropy: 1.3042 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 5.6544 - sparse_categorical_accuracy: 0.7021 - sparse_categorical_crossentropy: 0.8228 - val_loss: 0.9593 - val_sparse_categorical_accuracy: 0.6670 - val_sparse_categorical_crossentropy: 0.9593 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=2,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    class_weight=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Training will be repeated 5 times with different weights initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"article_net_weighted\"\n",
    "if os.path.exists(EXPERIMENT_NAME):\n",
    "    shutil.rmtree(EXPERIMENT_NAME)\n",
    "    os.mkdir(EXPERIMENT_NAME)\n",
    "else:\n",
    "    os.mkdir(EXPERIMENT_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:18:50.737894Z",
     "end_time": "2023-04-23T22:18:50.756838Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 191ms/step - loss: 18.2065 - sparse_categorical_accuracy: 0.2857 - sparse_categorical_crossentropy: 1.8730 - val_loss: 1.9502 - val_sparse_categorical_accuracy: 0.6114 - val_sparse_categorical_crossentropy: 1.9502 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 18s 186ms/step - loss: 7.3855 - sparse_categorical_accuracy: 0.6666 - sparse_categorical_crossentropy: 0.9683 - val_loss: 2.3031 - val_sparse_categorical_accuracy: 0.0539 - val_sparse_categorical_crossentropy: 2.3031 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 181ms/step - loss: 4.3818 - sparse_categorical_accuracy: 0.7894 - sparse_categorical_crossentropy: 0.6230 - val_loss: 1.5949 - val_sparse_categorical_accuracy: 0.4526 - val_sparse_categorical_crossentropy: 1.5949 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 4.0786 - sparse_categorical_accuracy: 0.8175 - sparse_categorical_crossentropy: 0.5515\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 182ms/step - loss: 4.0776 - sparse_categorical_accuracy: 0.8175 - sparse_categorical_crossentropy: 0.5514 - val_loss: 1.6690 - val_sparse_categorical_accuracy: 0.4448 - val_sparse_categorical_crossentropy: 1.6690 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 180ms/step - loss: 2.4757 - sparse_categorical_accuracy: 0.8739 - sparse_categorical_crossentropy: 0.3800 - val_loss: 0.5706 - val_sparse_categorical_accuracy: 0.8009 - val_sparse_categorical_crossentropy: 0.5706 - lr: 0.0050\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 180ms/step - loss: 1.7075 - sparse_categorical_accuracy: 0.9123 - sparse_categorical_crossentropy: 0.2649 - val_loss: 0.4016 - val_sparse_categorical_accuracy: 0.8644 - val_sparse_categorical_crossentropy: 0.4016 - lr: 0.0050\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 1.3475 - sparse_categorical_accuracy: 0.9286 - sparse_categorical_crossentropy: 0.2154 - val_loss: 0.2847 - val_sparse_categorical_accuracy: 0.9045 - val_sparse_categorical_crossentropy: 0.2847 - lr: 0.0050\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 18s 182ms/step - loss: 1.0605 - sparse_categorical_accuracy: 0.9415 - sparse_categorical_crossentropy: 0.1764 - val_loss: 0.2059 - val_sparse_categorical_accuracy: 0.9378 - val_sparse_categorical_crossentropy: 0.2059 - lr: 0.0050\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 0.9219 - sparse_categorical_accuracy: 0.9483 - sparse_categorical_crossentropy: 0.1575 - val_loss: 0.2370 - val_sparse_categorical_accuracy: 0.9266 - val_sparse_categorical_crossentropy: 0.2370 - lr: 0.0050\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 1.2710 - sparse_categorical_accuracy: 0.9356 - sparse_categorical_crossentropy: 0.1962 - val_loss: 0.2576 - val_sparse_categorical_accuracy: 0.9188 - val_sparse_categorical_crossentropy: 0.2576 - lr: 0.0050\n",
      "Epoch 11/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.9709 - sparse_categorical_accuracy: 0.9424 - sparse_categorical_crossentropy: 0.1733\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.9727 - sparse_categorical_accuracy: 0.9424 - sparse_categorical_crossentropy: 0.1733 - val_loss: 0.2941 - val_sparse_categorical_accuracy: 0.9125 - val_sparse_categorical_crossentropy: 0.2941 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 16s 172ms/step - loss: 1.0840 - sparse_categorical_accuracy: 0.9457 - sparse_categorical_crossentropy: 0.1622 - val_loss: 0.2387 - val_sparse_categorical_accuracy: 0.9269 - val_sparse_categorical_crossentropy: 0.2387 - lr: 0.0025\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 0.6003 - sparse_categorical_accuracy: 0.9665 - sparse_categorical_crossentropy: 0.0988 - val_loss: 0.1867 - val_sparse_categorical_accuracy: 0.9455 - val_sparse_categorical_crossentropy: 0.1867 - lr: 0.0025\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.4976 - sparse_categorical_accuracy: 0.9740 - sparse_categorical_crossentropy: 0.0783 - val_loss: 0.1779 - val_sparse_categorical_accuracy: 0.9512 - val_sparse_categorical_crossentropy: 0.1779 - lr: 0.0025\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 0.4348 - sparse_categorical_accuracy: 0.9791 - sparse_categorical_crossentropy: 0.0633 - val_loss: 0.1929 - val_sparse_categorical_accuracy: 0.9498 - val_sparse_categorical_crossentropy: 0.1929 - lr: 0.0025\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.4021 - sparse_categorical_accuracy: 0.9817 - sparse_categorical_crossentropy: 0.0559 - val_loss: 0.1835 - val_sparse_categorical_accuracy: 0.9544 - val_sparse_categorical_crossentropy: 0.1835 - lr: 0.0025\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 0.3859 - sparse_categorical_accuracy: 0.9832 - sparse_categorical_crossentropy: 0.0525 - val_loss: 0.1954 - val_sparse_categorical_accuracy: 0.9518 - val_sparse_categorical_crossentropy: 0.1954 - lr: 0.0025\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 16s 171ms/step - loss: 0.3564 - sparse_categorical_accuracy: 0.9850 - sparse_categorical_crossentropy: 0.0465 - val_loss: 0.1970 - val_sparse_categorical_accuracy: 0.9530 - val_sparse_categorical_crossentropy: 0.1970 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.3334 - sparse_categorical_accuracy: 0.9856 - sparse_categorical_crossentropy: 0.0442\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 16s 172ms/step - loss: 0.3332 - sparse_categorical_accuracy: 0.9856 - sparse_categorical_crossentropy: 0.0442 - val_loss: 0.2053 - val_sparse_categorical_accuracy: 0.9526 - val_sparse_categorical_crossentropy: 0.2053 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 16s 172ms/step - loss: 0.2962 - sparse_categorical_accuracy: 0.9878 - sparse_categorical_crossentropy: 0.0374 - val_loss: 0.2075 - val_sparse_categorical_accuracy: 0.9555 - val_sparse_categorical_crossentropy: 0.2075 - lr: 0.0012\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 173ms/step - loss: 0.3696 - sparse_categorical_accuracy: 0.9830 - sparse_categorical_crossentropy: 0.0512 - val_loss: 0.2074 - val_sparse_categorical_accuracy: 0.9510 - val_sparse_categorical_crossentropy: 0.2074 - lr: 0.0012\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.3012 - sparse_categorical_accuracy: 0.9874 - sparse_categorical_crossentropy: 0.0385 - val_loss: 0.2068 - val_sparse_categorical_accuracy: 0.9572 - val_sparse_categorical_crossentropy: 0.2068 - lr: 0.0012\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 16s 166ms/step - loss: 0.2722 - sparse_categorical_accuracy: 0.9895 - sparse_categorical_crossentropy: 0.0328 - val_loss: 0.2154 - val_sparse_categorical_accuracy: 0.9561 - val_sparse_categorical_crossentropy: 0.2154 - lr: 0.0012\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 16s 172ms/step - loss: 0.2929 - sparse_categorical_accuracy: 0.9885 - sparse_categorical_crossentropy: 0.0350 - val_loss: 0.2142 - val_sparse_categorical_accuracy: 0.9524 - val_sparse_categorical_crossentropy: 0.2142 - lr: 0.0012\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2542 - sparse_categorical_accuracy: 0.9899 - sparse_categorical_crossentropy: 0.0307\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 16s 171ms/step - loss: 0.2541 - sparse_categorical_accuracy: 0.9899 - sparse_categorical_crossentropy: 0.0307 - val_loss: 0.2188 - val_sparse_categorical_accuracy: 0.9558 - val_sparse_categorical_crossentropy: 0.2188 - lr: 0.0012\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 0.2282 - sparse_categorical_accuracy: 0.9913 - sparse_categorical_crossentropy: 0.0264 - val_loss: 0.2218 - val_sparse_categorical_accuracy: 0.9556 - val_sparse_categorical_crossentropy: 0.2218 - lr: 6.2500e-04\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.2200 - sparse_categorical_accuracy: 0.9917 - sparse_categorical_crossentropy: 0.0260 - val_loss: 0.2322 - val_sparse_categorical_accuracy: 0.9541 - val_sparse_categorical_crossentropy: 0.2322 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 95ms/step - loss: 0.2057 - sparse_categorical_accuracy: 0.9538 - sparse_categorical_crossentropy: 0.2057\n",
      "26/26 [==============================] - 3s 86ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 22s 183ms/step - loss: 19.3684 - sparse_categorical_accuracy: 0.3326 - sparse_categorical_crossentropy: 1.9157 - val_loss: 2.6223 - val_sparse_categorical_accuracy: 0.0281 - val_sparse_categorical_crossentropy: 2.6223 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 6.5410 - sparse_categorical_accuracy: 0.7075 - sparse_categorical_crossentropy: 0.8667 - val_loss: 2.1695 - val_sparse_categorical_accuracy: 0.6108 - val_sparse_categorical_crossentropy: 2.1695 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 4.1347 - sparse_categorical_accuracy: 0.8114 - sparse_categorical_crossentropy: 0.5659 - val_loss: 1.8802 - val_sparse_categorical_accuracy: 0.3375 - val_sparse_categorical_crossentropy: 1.8802 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 2.9953 - sparse_categorical_accuracy: 0.8559 - sparse_categorical_crossentropy: 0.4315 - val_loss: 1.3269 - val_sparse_categorical_accuracy: 0.5425 - val_sparse_categorical_crossentropy: 1.3269 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 2.1469 - sparse_categorical_accuracy: 0.8922 - sparse_categorical_crossentropy: 0.3240 - val_loss: 0.8149 - val_sparse_categorical_accuracy: 0.7301 - val_sparse_categorical_crossentropy: 0.8149 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 1.9652 - sparse_categorical_accuracy: 0.9019 - sparse_categorical_crossentropy: 0.3041 - val_loss: 0.4011 - val_sparse_categorical_accuracy: 0.8719 - val_sparse_categorical_crossentropy: 0.4011 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 1.7526 - sparse_categorical_accuracy: 0.9129 - sparse_categorical_crossentropy: 0.2658 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.7718 - val_sparse_categorical_crossentropy: 0.7103 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 1.9392 - sparse_categorical_accuracy: 0.9045 - sparse_categorical_crossentropy: 0.2977 - val_loss: 0.3315 - val_sparse_categorical_accuracy: 0.8981 - val_sparse_categorical_crossentropy: 0.3315 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 1.4681 - sparse_categorical_accuracy: 0.9248 - sparse_categorical_crossentropy: 0.2325 - val_loss: 0.2445 - val_sparse_categorical_accuracy: 0.9234 - val_sparse_categorical_crossentropy: 0.2445 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 2.1407 - sparse_categorical_accuracy: 0.9032 - sparse_categorical_crossentropy: 0.3098 - val_loss: 0.5465 - val_sparse_categorical_accuracy: 0.8274 - val_sparse_categorical_crossentropy: 0.5465 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 1.7332 - sparse_categorical_accuracy: 0.9168 - sparse_categorical_crossentropy: 0.2619 - val_loss: 0.3829 - val_sparse_categorical_accuracy: 0.8805 - val_sparse_categorical_crossentropy: 0.3829 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 1.1099 - sparse_categorical_accuracy: 0.9425 - sparse_categorical_crossentropy: 0.1742\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 1.1096 - sparse_categorical_accuracy: 0.9425 - sparse_categorical_crossentropy: 0.1742 - val_loss: 0.3271 - val_sparse_categorical_accuracy: 0.8956 - val_sparse_categorical_crossentropy: 0.3271 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.6735 - sparse_categorical_accuracy: 0.9641 - sparse_categorical_crossentropy: 0.1106 - val_loss: 0.1734 - val_sparse_categorical_accuracy: 0.9481 - val_sparse_categorical_crossentropy: 0.1734 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 0.5096 - sparse_categorical_accuracy: 0.9739 - sparse_categorical_crossentropy: 0.0801 - val_loss: 0.1570 - val_sparse_categorical_accuracy: 0.9549 - val_sparse_categorical_crossentropy: 0.1570 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 16s 171ms/step - loss: 0.4300 - sparse_categorical_accuracy: 0.9797 - sparse_categorical_crossentropy: 0.0627 - val_loss: 0.1605 - val_sparse_categorical_accuracy: 0.9569 - val_sparse_categorical_crossentropy: 0.1605 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.3625 - sparse_categorical_accuracy: 0.9832 - sparse_categorical_crossentropy: 0.0517 - val_loss: 0.1622 - val_sparse_categorical_accuracy: 0.9579 - val_sparse_categorical_crossentropy: 0.1622 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.3239 - sparse_categorical_accuracy: 0.9850 - sparse_categorical_crossentropy: 0.0446 - val_loss: 0.1691 - val_sparse_categorical_accuracy: 0.9562 - val_sparse_categorical_crossentropy: 0.1691 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 0.3136 - sparse_categorical_accuracy: 0.9851 - sparse_categorical_crossentropy: 0.0437 - val_loss: 0.1968 - val_sparse_categorical_accuracy: 0.9562 - val_sparse_categorical_crossentropy: 0.1968 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.4669 - sparse_categorical_accuracy: 0.9753 - sparse_categorical_crossentropy: 0.0759\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.4667 - sparse_categorical_accuracy: 0.9753 - sparse_categorical_crossentropy: 0.0758 - val_loss: 0.2136 - val_sparse_categorical_accuracy: 0.9455 - val_sparse_categorical_crossentropy: 0.2136 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.3581 - sparse_categorical_accuracy: 0.9796 - sparse_categorical_crossentropy: 0.0593 - val_loss: 0.1814 - val_sparse_categorical_accuracy: 0.9522 - val_sparse_categorical_crossentropy: 0.1814 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.2666 - sparse_categorical_accuracy: 0.9865 - sparse_categorical_crossentropy: 0.0399 - val_loss: 0.1785 - val_sparse_categorical_accuracy: 0.9578 - val_sparse_categorical_crossentropy: 0.1785 - lr: 0.0025\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.1897 - sparse_categorical_accuracy: 0.9545 - sparse_categorical_crossentropy: 0.1897\n",
      "26/26 [==============================] - 4s 97ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 22s 183ms/step - loss: 14.9965 - sparse_categorical_accuracy: 0.4186 - sparse_categorical_crossentropy: 1.6085 - val_loss: 1.4703 - val_sparse_categorical_accuracy: 0.5055 - val_sparse_categorical_crossentropy: 1.4703 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 7.4787 - sparse_categorical_accuracy: 0.6762 - sparse_categorical_crossentropy: 0.9523 - val_loss: 1.1884 - val_sparse_categorical_accuracy: 0.6054 - val_sparse_categorical_crossentropy: 1.1884 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 4.7987 - sparse_categorical_accuracy: 0.7738 - sparse_categorical_crossentropy: 0.6727 - val_loss: 0.6702 - val_sparse_categorical_accuracy: 0.7878 - val_sparse_categorical_crossentropy: 0.6702 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 3.7105 - sparse_categorical_accuracy: 0.8248 - sparse_categorical_crossentropy: 0.5294 - val_loss: 0.5331 - val_sparse_categorical_accuracy: 0.8253 - val_sparse_categorical_crossentropy: 0.5331 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 18s 186ms/step - loss: 3.4327 - sparse_categorical_accuracy: 0.8433 - sparse_categorical_crossentropy: 0.4838 - val_loss: 0.8082 - val_sparse_categorical_accuracy: 0.7623 - val_sparse_categorical_crossentropy: 0.8082 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 3.5738 - sparse_categorical_accuracy: 0.8372 - sparse_categorical_crossentropy: 0.5097 - val_loss: 0.4302 - val_sparse_categorical_accuracy: 0.8634 - val_sparse_categorical_crossentropy: 0.4302 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 2.5126 - sparse_categorical_accuracy: 0.8746 - sparse_categorical_crossentropy: 0.3790 - val_loss: 0.3564 - val_sparse_categorical_accuracy: 0.8856 - val_sparse_categorical_crossentropy: 0.3564 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 1.9375 - sparse_categorical_accuracy: 0.9064 - sparse_categorical_crossentropy: 0.2876 - val_loss: 0.3980 - val_sparse_categorical_accuracy: 0.8739 - val_sparse_categorical_crossentropy: 0.3980 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 16s 172ms/step - loss: 1.6994 - sparse_categorical_accuracy: 0.9079 - sparse_categorical_crossentropy: 0.2833 - val_loss: 0.3646 - val_sparse_categorical_accuracy: 0.8853 - val_sparse_categorical_crossentropy: 0.3646 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 16s 171ms/step - loss: 2.1498 - sparse_categorical_accuracy: 0.8958 - sparse_categorical_crossentropy: 0.3239 - val_loss: 0.2756 - val_sparse_categorical_accuracy: 0.9125 - val_sparse_categorical_crossentropy: 0.2756 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 1.8742 - sparse_categorical_accuracy: 0.9047 - sparse_categorical_crossentropy: 0.2961 - val_loss: 0.3580 - val_sparse_categorical_accuracy: 0.8891 - val_sparse_categorical_crossentropy: 0.3580 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 16s 172ms/step - loss: 1.8762 - sparse_categorical_accuracy: 0.9027 - sparse_categorical_crossentropy: 0.3028 - val_loss: 0.4502 - val_sparse_categorical_accuracy: 0.8664 - val_sparse_categorical_crossentropy: 0.4502 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 2.3624 - sparse_categorical_accuracy: 0.8717 - sparse_categorical_crossentropy: 0.4074\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 2.3618 - sparse_categorical_accuracy: 0.8717 - sparse_categorical_crossentropy: 0.4074 - val_loss: 0.2974 - val_sparse_categorical_accuracy: 0.9062 - val_sparse_categorical_crossentropy: 0.2974 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 1.1551 - sparse_categorical_accuracy: 0.9366 - sparse_categorical_crossentropy: 0.1945 - val_loss: 0.2280 - val_sparse_categorical_accuracy: 0.9277 - val_sparse_categorical_crossentropy: 0.2280 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.7626 - sparse_categorical_accuracy: 0.9558 - sparse_categorical_crossentropy: 0.1351 - val_loss: 0.2159 - val_sparse_categorical_accuracy: 0.9355 - val_sparse_categorical_crossentropy: 0.2159 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 0.6598 - sparse_categorical_accuracy: 0.9602 - sparse_categorical_crossentropy: 0.1231 - val_loss: 0.2016 - val_sparse_categorical_accuracy: 0.9441 - val_sparse_categorical_crossentropy: 0.2016 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 0.5718 - sparse_categorical_accuracy: 0.9685 - sparse_categorical_crossentropy: 0.0999 - val_loss: 0.2334 - val_sparse_categorical_accuracy: 0.9358 - val_sparse_categorical_crossentropy: 0.2334 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 0.5938 - sparse_categorical_accuracy: 0.9662 - sparse_categorical_crossentropy: 0.1066 - val_loss: 0.2390 - val_sparse_categorical_accuracy: 0.9389 - val_sparse_categorical_crossentropy: 0.2390 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.6026 - sparse_categorical_accuracy: 0.9648 - sparse_categorical_crossentropy: 0.1087\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 0.6024 - sparse_categorical_accuracy: 0.9648 - sparse_categorical_crossentropy: 0.1087 - val_loss: 0.2439 - val_sparse_categorical_accuracy: 0.9367 - val_sparse_categorical_crossentropy: 0.2439 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 0.4412 - sparse_categorical_accuracy: 0.9734 - sparse_categorical_crossentropy: 0.0807 - val_loss: 0.1964 - val_sparse_categorical_accuracy: 0.9487 - val_sparse_categorical_crossentropy: 0.1964 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 0.3756 - sparse_categorical_accuracy: 0.9790 - sparse_categorical_crossentropy: 0.0650 - val_loss: 0.2019 - val_sparse_categorical_accuracy: 0.9503 - val_sparse_categorical_crossentropy: 0.2019 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.3240 - sparse_categorical_accuracy: 0.9836 - sparse_categorical_crossentropy: 0.0512 - val_loss: 0.1970 - val_sparse_categorical_accuracy: 0.9529 - val_sparse_categorical_crossentropy: 0.1970 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.2973 - sparse_categorical_accuracy: 0.9859 - sparse_categorical_crossentropy: 0.0441 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9550 - val_sparse_categorical_crossentropy: 0.1996 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.2672 - sparse_categorical_accuracy: 0.9879 - sparse_categorical_crossentropy: 0.0391 - val_loss: 0.2113 - val_sparse_categorical_accuracy: 0.9564 - val_sparse_categorical_crossentropy: 0.2113 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.3522 - sparse_categorical_accuracy: 0.9807 - sparse_categorical_crossentropy: 0.0607 - val_loss: 0.2180 - val_sparse_categorical_accuracy: 0.9512 - val_sparse_categorical_crossentropy: 0.2180 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.3133 - sparse_categorical_accuracy: 0.9830 - sparse_categorical_crossentropy: 0.0536 - val_loss: 0.2282 - val_sparse_categorical_accuracy: 0.9495 - val_sparse_categorical_crossentropy: 0.2282 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2878 - sparse_categorical_accuracy: 0.9858 - sparse_categorical_crossentropy: 0.0447\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.9859 - sparse_categorical_crossentropy: 0.0446 - val_loss: 0.2262 - val_sparse_categorical_accuracy: 0.9526 - val_sparse_categorical_crossentropy: 0.2262 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.2527 - sparse_categorical_accuracy: 0.9878 - sparse_categorical_crossentropy: 0.0392 - val_loss: 0.2163 - val_sparse_categorical_accuracy: 0.9538 - val_sparse_categorical_crossentropy: 0.2163 - lr: 0.0012\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 16s 171ms/step - loss: 0.2126 - sparse_categorical_accuracy: 0.9897 - sparse_categorical_crossentropy: 0.0330 - val_loss: 0.2178 - val_sparse_categorical_accuracy: 0.9539 - val_sparse_categorical_crossentropy: 0.2178 - lr: 0.0012\n",
      "26/26 [==============================] - 3s 101ms/step - loss: 0.2303 - sparse_categorical_accuracy: 0.9508 - sparse_categorical_crossentropy: 0.2303\n",
      "26/26 [==============================] - 4s 99ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 191ms/step - loss: 13.8010 - sparse_categorical_accuracy: 0.4492 - sparse_categorical_crossentropy: 1.5247 - val_loss: 1.6754 - val_sparse_categorical_accuracy: 0.3966 - val_sparse_categorical_crossentropy: 1.6754 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 16s 172ms/step - loss: 7.8254 - sparse_categorical_accuracy: 0.6505 - sparse_categorical_crossentropy: 0.9970 - val_loss: 1.7091 - val_sparse_categorical_accuracy: 0.4479 - val_sparse_categorical_crossentropy: 1.7091 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 16s 170ms/step - loss: 4.8531 - sparse_categorical_accuracy: 0.7707 - sparse_categorical_crossentropy: 0.6664 - val_loss: 0.6425 - val_sparse_categorical_accuracy: 0.7820 - val_sparse_categorical_crossentropy: 0.6425 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 16s 171ms/step - loss: 3.3861 - sparse_categorical_accuracy: 0.8343 - sparse_categorical_crossentropy: 0.4894 - val_loss: 0.5909 - val_sparse_categorical_accuracy: 0.8093 - val_sparse_categorical_crossentropy: 0.5909 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 18s 184ms/step - loss: 2.6845 - sparse_categorical_accuracy: 0.8659 - sparse_categorical_crossentropy: 0.3990 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8812 - val_sparse_categorical_crossentropy: 0.3703 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 18s 182ms/step - loss: 2.1774 - sparse_categorical_accuracy: 0.8851 - sparse_categorical_crossentropy: 0.3435 - val_loss: 0.3707 - val_sparse_categorical_accuracy: 0.8813 - val_sparse_categorical_crossentropy: 0.3707 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 1.9609 - sparse_categorical_accuracy: 0.8947 - sparse_categorical_crossentropy: 0.3188 - val_loss: 0.8723 - val_sparse_categorical_accuracy: 0.7365 - val_sparse_categorical_crossentropy: 0.8723 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 4.2980 - sparse_categorical_accuracy: 0.8122 - sparse_categorical_crossentropy: 0.5750 - val_loss: 0.4268 - val_sparse_categorical_accuracy: 0.8650 - val_sparse_categorical_crossentropy: 0.4268 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 2.5608 - sparse_categorical_accuracy: 0.8760 - sparse_categorical_crossentropy: 0.3763\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 18s 181ms/step - loss: 2.5602 - sparse_categorical_accuracy: 0.8760 - sparse_categorical_crossentropy: 0.3764 - val_loss: 0.3667 - val_sparse_categorical_accuracy: 0.8796 - val_sparse_categorical_crossentropy: 0.3667 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 18s 184ms/step - loss: 1.5078 - sparse_categorical_accuracy: 0.9195 - sparse_categorical_crossentropy: 0.2403 - val_loss: 0.2769 - val_sparse_categorical_accuracy: 0.9076 - val_sparse_categorical_crossentropy: 0.2769 - lr: 0.0050\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 180ms/step - loss: 1.0406 - sparse_categorical_accuracy: 0.9402 - sparse_categorical_crossentropy: 0.1789 - val_loss: 0.2447 - val_sparse_categorical_accuracy: 0.9212 - val_sparse_categorical_crossentropy: 0.2447 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 18s 188ms/step - loss: 0.8342 - sparse_categorical_accuracy: 0.9512 - sparse_categorical_crossentropy: 0.1501 - val_loss: 0.2576 - val_sparse_categorical_accuracy: 0.9232 - val_sparse_categorical_crossentropy: 0.2576 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 18s 184ms/step - loss: 0.8662 - sparse_categorical_accuracy: 0.9499 - sparse_categorical_crossentropy: 0.1561 - val_loss: 0.2376 - val_sparse_categorical_accuracy: 0.9277 - val_sparse_categorical_crossentropy: 0.2376 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.7494 - sparse_categorical_accuracy: 0.9554 - sparse_categorical_crossentropy: 0.1347 - val_loss: 0.2269 - val_sparse_categorical_accuracy: 0.9343 - val_sparse_categorical_crossentropy: 0.2269 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.6376 - sparse_categorical_accuracy: 0.9629 - sparse_categorical_crossentropy: 0.1118 - val_loss: 0.2505 - val_sparse_categorical_accuracy: 0.9298 - val_sparse_categorical_crossentropy: 0.2505 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.6140 - sparse_categorical_accuracy: 0.9641 - sparse_categorical_crossentropy: 0.1084 - val_loss: 0.2649 - val_sparse_categorical_accuracy: 0.9301 - val_sparse_categorical_crossentropy: 0.2649 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.8340 - sparse_categorical_accuracy: 0.9528 - sparse_categorical_crossentropy: 0.1427\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.8354 - sparse_categorical_accuracy: 0.9528 - sparse_categorical_crossentropy: 0.1427 - val_loss: 0.3451 - val_sparse_categorical_accuracy: 0.9125 - val_sparse_categorical_crossentropy: 0.3451 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 180ms/step - loss: 0.9716 - sparse_categorical_accuracy: 0.9520 - sparse_categorical_crossentropy: 0.1495 - val_loss: 0.2486 - val_sparse_categorical_accuracy: 0.9304 - val_sparse_categorical_crossentropy: 0.2486 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 18s 181ms/step - loss: 0.5843 - sparse_categorical_accuracy: 0.9675 - sparse_categorical_crossentropy: 0.0995 - val_loss: 0.2227 - val_sparse_categorical_accuracy: 0.9401 - val_sparse_categorical_crossentropy: 0.2227 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.4265 - sparse_categorical_accuracy: 0.9760 - sparse_categorical_crossentropy: 0.0705 - val_loss: 0.2152 - val_sparse_categorical_accuracy: 0.9453 - val_sparse_categorical_crossentropy: 0.2152 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.3755 - sparse_categorical_accuracy: 0.9816 - sparse_categorical_crossentropy: 0.0554 - val_loss: 0.2198 - val_sparse_categorical_accuracy: 0.9481 - val_sparse_categorical_crossentropy: 0.2198 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.3418 - sparse_categorical_accuracy: 0.9838 - sparse_categorical_crossentropy: 0.0475 - val_loss: 0.2281 - val_sparse_categorical_accuracy: 0.9460 - val_sparse_categorical_crossentropy: 0.2281 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.3285 - sparse_categorical_accuracy: 0.9849 - sparse_categorical_crossentropy: 0.0447 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9495 - val_sparse_categorical_crossentropy: 0.2272 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.3014 - sparse_categorical_accuracy: 0.9875 - sparse_categorical_crossentropy: 0.0381 - val_loss: 0.2349 - val_sparse_categorical_accuracy: 0.9493 - val_sparse_categorical_crossentropy: 0.2349 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2886 - sparse_categorical_accuracy: 0.9885 - sparse_categorical_crossentropy: 0.0342 - val_loss: 0.2397 - val_sparse_categorical_accuracy: 0.9492 - val_sparse_categorical_crossentropy: 0.2397 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2716 - sparse_categorical_accuracy: 0.9888 - sparse_categorical_crossentropy: 0.0319\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.9888 - sparse_categorical_crossentropy: 0.0319 - val_loss: 0.2477 - val_sparse_categorical_accuracy: 0.9487 - val_sparse_categorical_crossentropy: 0.2477 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.2556 - sparse_categorical_accuracy: 0.9904 - sparse_categorical_crossentropy: 0.0284 - val_loss: 0.2491 - val_sparse_categorical_accuracy: 0.9510 - val_sparse_categorical_crossentropy: 0.2491 - lr: 0.0012\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2526 - sparse_categorical_accuracy: 0.9901 - sparse_categorical_crossentropy: 0.0286 - val_loss: 0.2543 - val_sparse_categorical_accuracy: 0.9501 - val_sparse_categorical_crossentropy: 0.2543 - lr: 0.0012\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2534 - sparse_categorical_accuracy: 0.9900 - sparse_categorical_crossentropy: 0.0287 - val_loss: 0.2634 - val_sparse_categorical_accuracy: 0.9489 - val_sparse_categorical_crossentropy: 0.2634 - lr: 0.0012\n",
      "Epoch 30/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2434 - sparse_categorical_accuracy: 0.9911 - sparse_categorical_crossentropy: 0.0262\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2433 - sparse_categorical_accuracy: 0.9911 - sparse_categorical_crossentropy: 0.0262 - val_loss: 0.2629 - val_sparse_categorical_accuracy: 0.9506 - val_sparse_categorical_crossentropy: 0.2629 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 0.2301 - sparse_categorical_accuracy: 0.9918 - sparse_categorical_crossentropy: 0.0240 - val_loss: 0.2651 - val_sparse_categorical_accuracy: 0.9499 - val_sparse_categorical_crossentropy: 0.2651 - lr: 6.2500e-04\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 0.2245 - sparse_categorical_accuracy: 0.9925 - sparse_categorical_crossentropy: 0.0227 - val_loss: 0.2688 - val_sparse_categorical_accuracy: 0.9510 - val_sparse_categorical_crossentropy: 0.2688 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.2435 - sparse_categorical_accuracy: 0.9506 - sparse_categorical_crossentropy: 0.2435\n",
      "26/26 [==============================] - 4s 116ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 192ms/step - loss: 15.2779 - sparse_categorical_accuracy: 0.3952 - sparse_categorical_crossentropy: 1.6484 - val_loss: 1.4903 - val_sparse_categorical_accuracy: 0.5262 - val_sparse_categorical_crossentropy: 1.4903 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 6.7346 - sparse_categorical_accuracy: 0.7096 - sparse_categorical_crossentropy: 0.8755 - val_loss: 0.9350 - val_sparse_categorical_accuracy: 0.6951 - val_sparse_categorical_crossentropy: 0.9350 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 4.8388 - sparse_categorical_accuracy: 0.7707 - sparse_categorical_crossentropy: 0.6966 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.7867 - val_sparse_categorical_crossentropy: 0.6507 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 3.5361 - sparse_categorical_accuracy: 0.8353 - sparse_categorical_crossentropy: 0.5069 - val_loss: 0.4440 - val_sparse_categorical_accuracy: 0.8624 - val_sparse_categorical_crossentropy: 0.4440 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 2.9551 - sparse_categorical_accuracy: 0.8609 - sparse_categorical_crossentropy: 0.4271 - val_loss: 0.4728 - val_sparse_categorical_accuracy: 0.8494 - val_sparse_categorical_crossentropy: 0.4728 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 2.9384 - sparse_categorical_accuracy: 0.8633 - sparse_categorical_crossentropy: 0.4196 - val_loss: 0.5946 - val_sparse_categorical_accuracy: 0.8084 - val_sparse_categorical_crossentropy: 0.5946 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 3.1325 - sparse_categorical_accuracy: 0.8583 - sparse_categorical_crossentropy: 0.4445 - val_loss: 0.3476 - val_sparse_categorical_accuracy: 0.8934 - val_sparse_categorical_crossentropy: 0.3476 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 1.9800 - sparse_categorical_accuracy: 0.9039 - sparse_categorical_crossentropy: 0.2969 - val_loss: 0.2917 - val_sparse_categorical_accuracy: 0.9028 - val_sparse_categorical_crossentropy: 0.2917 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 1.7699 - sparse_categorical_accuracy: 0.9166 - sparse_categorical_crossentropy: 0.2665 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8704 - val_sparse_categorical_crossentropy: 0.4495 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 2.0371 - sparse_categorical_accuracy: 0.9017 - sparse_categorical_crossentropy: 0.3085 - val_loss: 0.3251 - val_sparse_categorical_accuracy: 0.8988 - val_sparse_categorical_crossentropy: 0.3251 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 1.4564 - sparse_categorical_accuracy: 0.9217 - sparse_categorical_crossentropy: 0.2436 - val_loss: 0.2887 - val_sparse_categorical_accuracy: 0.9090 - val_sparse_categorical_crossentropy: 0.2887 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 1.1962 - sparse_categorical_accuracy: 0.9352 - sparse_categorical_crossentropy: 0.2000 - val_loss: 0.2613 - val_sparse_categorical_accuracy: 0.9218 - val_sparse_categorical_crossentropy: 0.2613 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 1.0418 - sparse_categorical_accuracy: 0.9429 - sparse_categorical_crossentropy: 0.1751 - val_loss: 0.2496 - val_sparse_categorical_accuracy: 0.9266 - val_sparse_categorical_crossentropy: 0.2496 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 17s 177ms/step - loss: 1.2043 - sparse_categorical_accuracy: 0.9370 - sparse_categorical_crossentropy: 0.1984 - val_loss: 0.1992 - val_sparse_categorical_accuracy: 0.9400 - val_sparse_categorical_crossentropy: 0.1992 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 18s 183ms/step - loss: 1.0717 - sparse_categorical_accuracy: 0.9406 - sparse_categorical_crossentropy: 0.1823 - val_loss: 0.2266 - val_sparse_categorical_accuracy: 0.9329 - val_sparse_categorical_crossentropy: 0.2266 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 18s 181ms/step - loss: 0.9853 - sparse_categorical_accuracy: 0.9439 - sparse_categorical_crossentropy: 0.1775 - val_loss: 0.3007 - val_sparse_categorical_accuracy: 0.9174 - val_sparse_categorical_crossentropy: 0.3007 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 2.7318 - sparse_categorical_accuracy: 0.8810 - sparse_categorical_crossentropy: 0.3825\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 18s 182ms/step - loss: 2.7308 - sparse_categorical_accuracy: 0.8810 - sparse_categorical_crossentropy: 0.3823 - val_loss: 0.5966 - val_sparse_categorical_accuracy: 0.8042 - val_sparse_categorical_crossentropy: 0.5966 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 17s 178ms/step - loss: 1.4470 - sparse_categorical_accuracy: 0.9246 - sparse_categorical_crossentropy: 0.2306 - val_loss: 0.2359 - val_sparse_categorical_accuracy: 0.9272 - val_sparse_categorical_crossentropy: 0.2359 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.8621 - sparse_categorical_accuracy: 0.9520 - sparse_categorical_crossentropy: 0.1475 - val_loss: 0.2156 - val_sparse_categorical_accuracy: 0.9383 - val_sparse_categorical_crossentropy: 0.2156 - lr: 0.0050\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.2175 - sparse_categorical_accuracy: 0.9356 - sparse_categorical_crossentropy: 0.2175\n",
      "26/26 [==============================] - 4s 121ms/step\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(5))\n",
    "results = []\n",
    "for seed in TRAINING_SEEDS:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    model = SpeechModels.AttRNNSpeechModel(N_CLASS, samplingrate=16000, inputLength=None)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "        loss=losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        class_weight=weights\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(EXPERIMENT_NAME, f\"history_{seed}.pkl\"), \"wb\") as file:\n",
    "        pickle.dump(history.history, file)\n",
    "\n",
    "    eval_results = model.evaluate(test_ds)\n",
    "\n",
    "    predictions = model.predict(test_ds)\n",
    "    with open(os.path.join(EXPERIMENT_NAME, f\"predictions_{seed}.pkl\"), \"wb\") as file:\n",
    "        pickle.dump(predictions, file)\n",
    "\n",
    "    results += [{\n",
    "        'seed': seed,\n",
    "        'results': dict(zip(model.metrics_names, eval_results))\n",
    "    }]\n",
    "    gc.collect()\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results = pd.concat([results.drop([\"results\"], axis=1), results[\"results\"].apply(pd.Series)], axis=1)\n",
    "results.to_csv(os.path.join(EXPERIMENT_NAME, 'results.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:18:50.757834Z",
     "end_time": "2023-04-23T22:55:52.206669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T22:55:52.207666Z",
     "end_time": "2023-04-23T22:55:52.223611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   seed      loss  sparse_categorical_accuracy  \\\n0     0  0.205750                     0.953778   \n1     1  0.189699                     0.954469   \n2     2  0.230322                     0.950783   \n3     3  0.243537                     0.950630   \n4     4  0.217451                     0.935580   \n\n   sparse_categorical_crossentropy  \n0                         0.205750  \n1                         0.189699  \n2                         0.230322  \n3                         0.243537  \n4                         0.217451  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed</th>\n      <th>loss</th>\n      <th>sparse_categorical_accuracy</th>\n      <th>sparse_categorical_crossentropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.205750</td>\n      <td>0.953778</td>\n      <td>0.205750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.189699</td>\n      <td>0.954469</td>\n      <td>0.189699</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.230322</td>\n      <td>0.950783</td>\n      <td>0.230322</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.243537</td>\n      <td>0.950630</td>\n      <td>0.243537</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.217451</td>\n      <td>0.935580</td>\n      <td>0.217451</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
