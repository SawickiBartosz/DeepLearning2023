{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lightning\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "from load_data import AudioTrainDataset, TargetEncoder, RemoveSampleRate, PaddingZeros"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:19.182946Z",
     "end_time": "2023-04-22T17:58:23.313097Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "{1: 'bed',\n 2: 'bird',\n 3: 'cat',\n 4: 'dog',\n 5: 'down',\n 6: 'eight',\n 7: 'five',\n 8: 'four',\n 9: 'go',\n 10: 'happy',\n 11: 'house',\n 12: 'left',\n 13: 'marvin',\n 14: 'nine',\n 15: 'no',\n 16: 'off',\n 17: 'on',\n 18: 'one',\n 19: 'right',\n 20: 'seven',\n 21: 'sheila',\n 22: 'silence',\n 23: 'six',\n 24: 'stop',\n 25: 'three',\n 26: 'tree',\n 27: 'two',\n 28: 'up',\n 29: 'wow',\n 30: 'yes',\n 31: 'zero'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(\"tensorflow-speech-recognition-challenge\", \"train\", \"audio\")\n",
    "dataset = AudioTrainDataset(DATA_PATH)\n",
    "\n",
    "labels_list, labels_dict = dataset.find_classes(DATA_PATH)\n",
    "labels_dict = {idx: name for name, idx in labels_dict.items()}\n",
    "labels_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:23.316100Z",
     "end_time": "2023-04-22T17:58:23.625615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "NUM_WORKERS = 6\n",
    "BATCH_SIZE = 256"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:23.626616Z",
     "end_time": "2023-04-22T17:58:23.670533Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
    "extractor = bundle.get_model().to(device=torch.device('cuda'))\n",
    "# freeze weights\n",
    "for param in extractor.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:23.643530Z",
     "end_time": "2023-04-22T17:58:24.612523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    PaddingZeros(16000),\n",
    "    RemoveSampleRate()\n",
    "])\n",
    "raw_dataset = AudioTrainDataset(DATA_PATH, target_transform=TargetEncoder(class_dict=labels_dict), transform=transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:24.615523Z",
     "end_time": "2023-04-22T17:58:24.922523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(45587, 6512, 13024)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = torch.Generator().manual_seed(42)\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(raw_dataset, [0.7, 0.1, 0.2],\n",
    "                                                                           generator=gen)\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:24.921523Z",
     "end_time": "2023-04-22T17:58:24.939523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(179, 26, 51)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True,\n",
    "                                  generator=torch.random.manual_seed(123))\n",
    "valid_dataset_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "test_dataset_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "len(train_dataset_loader), len(valid_dataset_loader), len(test_dataset_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:24.934522Z",
     "end_time": "2023-04-22T17:58:24.999523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MyLSTM(lightning.LightningModule):\n",
    "    def __init__(self,\n",
    "                 extractor: torchaudio.models.Wav2Vec2Model,\n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 target_size):\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "        lstm_input_size = 768 * 12\n",
    "        self.num_layers= num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(lstm_input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.hidden2label = torch.nn.Linear(hidden_size, target_size)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=target_size)\n",
    "        self.valid_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=target_size)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=target_size)\n",
    "        self.test_conf_mat = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze()\n",
    "        x, _ = self.extractor.extract_features(x)\n",
    "        x = torch.cat(x, dim=-1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        label_space = self.hidden2label(lstm_out[:, -1])\n",
    "        return self.softmax(label_space)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        self.train_acc(y_hat, torch.argmax(y, dim=-1))\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc_step\", self.train_acc)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log('train_acc', self.train_acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx = 0):\n",
    "        x, y = batch\n",
    "        return self(x)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        self.valid_acc(y_hat, torch.argmax(y, dim=-1))\n",
    "        self.log('val_loss', loss, on_epoch=True)\n",
    "        self.log('val_acc', self.valid_acc, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        y_class = torch.argmax(y, dim=-1)\n",
    "        self.test_acc(y_hat, y_class)\n",
    "        self.test_conf_mat(y_hat, y_class)\n",
    "        self.log('test_loss', loss, on_epoch=True)\n",
    "        self.log('test_acc', self.test_acc, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.3, patience=3),\n",
    "                \"monitor\": \"val_loss\",\n",
    "            }\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:24.977523Z",
     "end_time": "2023-04-22T17:58:24.999523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 16000])\n"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_y in train_dataset_loader:\n",
    "    print(batch_x.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:58:24.982523Z",
     "end_time": "2023-04-22T17:58:39.787404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m MyLSTM(extractor, \u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m12\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_x,  batch_y \u001B[38;5;129;01min\u001B[39;00m train_dataset_loader:\n\u001B[1;32m----> 3\u001B[0m     y_hat \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_x\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[8], line 24\u001B[0m, in \u001B[0;36mMyLSTM.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     22\u001B[0m x, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextractor\u001B[38;5;241m.\u001B[39mextract_features(x)\n\u001B[0;32m     23\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(x, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 24\u001B[0m lstm_out, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m label_space \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden2label(lstm_out[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax(label_space)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[0;32m    811\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 812\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    813\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    814\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    815\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[0;32m    816\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu"
     ]
    }
   ],
   "source": [
    "model = MyLSTM(extractor, 32, 1, 12)\n",
    "for batch_x,  batch_y in train_dataset_loader:\n",
    "    y_hat = model(batch_x.to(device=torch.device('cuda')))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T17:46:15.790135Z",
     "end_time": "2023-04-22T17:46:52.518447Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                      | Params\n",
      "------------------------------------------------------------\n",
      "0 | extractor     | Wav2Vec2Model             | 94.4 M\n",
      "1 | lstm          | LSTM                      | 1.2 M \n",
      "2 | hidden2label  | Linear                    | 396   \n",
      "3 | softmax       | Softmax                   | 0     \n",
      "4 | train_acc     | MulticlassAccuracy        | 0     \n",
      "5 | valid_acc     | MulticlassAccuracy        | 0     \n",
      "6 | test_acc      | MulticlassAccuracy        | 0     \n",
      "7 | test_conf_mat | MulticlassConfusionMatrix | 0     \n",
      "------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "94.4 M    Non-trainable params\n",
      "95.6 M    Total params\n",
      "382.311   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 179/179 [00:56<00:00,  3.16it/s, v_num=28, train_loss_step=1.890]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▍         | 1/26 [00:00<00:10,  2.33it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 2/26 [00:00<00:08,  2.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  12%|█▏        | 3/26 [00:00<00:07,  3.16it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 4/26 [00:01<00:06,  3.31it/s]\u001B[A\n",
      "Validation DataLoader 0:  19%|█▉        | 5/26 [00:01<00:06,  3.48it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 6/26 [00:01<00:05,  3.58it/s]\u001B[A\n",
      "Validation DataLoader 0:  27%|██▋       | 7/26 [00:01<00:05,  3.67it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 8/26 [00:02<00:04,  3.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▍      | 9/26 [00:02<00:04,  3.77it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 10/26 [00:02<00:04,  3.80it/s]\u001B[A\n",
      "Validation DataLoader 0:  42%|████▏     | 11/26 [00:02<00:03,  3.84it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 12/26 [00:03<00:03,  3.88it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 13/26 [00:03<00:03,  3.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 14/26 [00:03<00:03,  3.95it/s]\u001B[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 15/26 [00:03<00:02,  3.98it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 16/26 [00:03<00:02,  4.00it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 17/26 [00:04<00:02,  4.03it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 18/26 [00:04<00:01,  4.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 19/26 [00:04<00:01,  4.02it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 20/26 [00:04<00:01,  4.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  81%|████████  | 21/26 [00:05<00:01,  4.02it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 22/26 [00:05<00:00,  4.03it/s]\u001B[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 23/26 [00:05<00:00,  4.05it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 24/26 [00:05<00:00,  4.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 25/26 [00:06<00:00,  4.04it/s]\u001B[A\n",
      "Epoch 0: 100%|██████████| 179/179 [01:17<00:00,  2.30it/s, v_num=28, train_loss_step=1.890]\n",
      "Epoch 1: 100%|██████████| 179/179 [00:57<00:00,  3.11it/s, v_num=28, train_loss_step=2.040, train_loss_epoch=2.030]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▍         | 1/26 [00:00<00:12,  2.02it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 2/26 [00:00<00:08,  2.78it/s]\u001B[A\n",
      "Validation DataLoader 0:  12%|█▏        | 3/26 [00:00<00:07,  3.18it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 4/26 [00:01<00:06,  3.42it/s]\u001B[A\n",
      "Validation DataLoader 0:  19%|█▉        | 5/26 [00:01<00:05,  3.59it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 6/26 [00:01<00:05,  3.70it/s]\u001B[A\n",
      "Validation DataLoader 0:  27%|██▋       | 7/26 [00:01<00:05,  3.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 8/26 [00:02<00:04,  3.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▍      | 9/26 [00:02<00:04,  3.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 10/26 [00:02<00:04,  3.94it/s]\u001B[A\n",
      "Validation DataLoader 0:  42%|████▏     | 11/26 [00:02<00:03,  3.97it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 12/26 [00:02<00:03,  4.01it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 13/26 [00:03<00:03,  4.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 14/26 [00:03<00:02,  4.07it/s]\u001B[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 15/26 [00:03<00:02,  4.09it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 16/26 [00:03<00:02,  4.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 17/26 [00:04<00:02,  4.13it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 18/26 [00:04<00:01,  4.14it/s]\u001B[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 19/26 [00:04<00:01,  4.16it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 20/26 [00:04<00:01,  4.18it/s]\u001B[A\n",
      "Validation DataLoader 0:  81%|████████  | 21/26 [00:05<00:01,  4.19it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 22/26 [00:05<00:00,  4.20it/s]\u001B[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 23/26 [00:05<00:00,  4.21it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 24/26 [00:05<00:00,  4.22it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 25/26 [00:05<00:00,  4.23it/s]\u001B[A\n",
      "Epoch 1: 100%|██████████| 179/179 [01:17<00:00,  2.30it/s, v_num=28, train_loss_step=2.040, train_loss_epoch=2.030]\n",
      "Epoch 1: 100%|██████████| 179/179 [01:17<00:00,  2.30it/s, v_num=28, train_loss_step=2.040, train_loss_epoch=1.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 179/179 [01:19<00:00,  2.25it/s, v_num=28, train_loss_step=2.040, train_loss_epoch=1.990]\n"
     ]
    }
   ],
   "source": [
    "model = MyLSTM(extractor, 32, 1, 12)\n",
    "trainer = lightning.Trainer(max_epochs=2, logger=True)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "trainer.fit(model, train_dataloaders=train_dataset_loader, val_dataloaders=valid_dataset_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T18:00:31.813228Z",
     "end_time": "2023-04-22T18:03:56.522485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Piotrek\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory cnn_lstm\\lightning_logs\\version_0\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                      | Params\n",
      "------------------------------------------------------------\n",
      "0 | extractor     | Wav2Vec2Model             | 94.4 M\n",
      "1 | lstm          | LSTM                      | 1.2 M \n",
      "2 | hidden2label  | Linear                    | 396   \n",
      "3 | softmax       | Softmax                   | 0     \n",
      "4 | train_acc     | MulticlassAccuracy        | 0     \n",
      "5 | valid_acc     | MulticlassAccuracy        | 0     \n",
      "6 | test_acc      | MulticlassAccuracy        | 0     \n",
      "7 | test_conf_mat | MulticlassConfusionMatrix | 0     \n",
      "------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "94.4 M    Non-trainable params\n",
      "95.6 M    Total params\n",
      "382.311   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 179/179 [00:57<00:00,  3.12it/s, v_num=0, train_loss_step=2.040]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▍         | 1/26 [00:00<00:13,  1.87it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 2/26 [00:00<00:09,  2.58it/s]\u001B[A\n",
      "Validation DataLoader 0:  12%|█▏        | 3/26 [00:01<00:07,  2.96it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 4/26 [00:01<00:07,  3.14it/s]\u001B[A\n",
      "Validation DataLoader 0:  19%|█▉        | 5/26 [00:01<00:06,  3.34it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 6/26 [00:01<00:05,  3.48it/s]\u001B[A\n",
      "Validation DataLoader 0:  27%|██▋       | 7/26 [00:01<00:05,  3.60it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 8/26 [00:02<00:04,  3.69it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▍      | 9/26 [00:02<00:04,  3.77it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 10/26 [00:02<00:04,  3.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  42%|████▏     | 11/26 [00:02<00:03,  3.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 12/26 [00:03<00:03,  3.91it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 13/26 [00:03<00:03,  3.90it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 14/26 [00:03<00:03,  3.90it/s]\u001B[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 15/26 [00:03<00:02,  3.90it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 16/26 [00:04<00:02,  3.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 17/26 [00:04<00:02,  3.93it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 18/26 [00:04<00:02,  3.93it/s]\u001B[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 19/26 [00:04<00:01,  3.95it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 20/26 [00:05<00:01,  3.96it/s]\u001B[A\n",
      "Validation DataLoader 0:  81%|████████  | 21/26 [00:05<00:01,  3.98it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 22/26 [00:05<00:00,  4.01it/s]\u001B[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 23/26 [00:05<00:00,  4.02it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 24/26 [00:05<00:00,  4.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 25/26 [00:06<00:00,  4.05it/s]\u001B[A\n",
      "Epoch 0: 100%|██████████| 179/179 [01:19<00:00,  2.26it/s, v_num=0, train_loss_step=2.040]\n",
      "Epoch 0: 100%|██████████| 179/179 [01:19<00:00,  2.26it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 179/179 [00:57<00:00,  3.12it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=2.040]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▍         | 1/26 [00:00<00:11,  2.19it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 2/26 [00:00<00:08,  2.91it/s]\u001B[A\n",
      "Validation DataLoader 0:  12%|█▏        | 3/26 [00:00<00:07,  3.22it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 4/26 [00:01<00:06,  3.49it/s]\u001B[A\n",
      "Validation DataLoader 0:  19%|█▉        | 5/26 [00:01<00:05,  3.68it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 6/26 [00:01<00:05,  3.81it/s]\u001B[A\n",
      "Validation DataLoader 0:  27%|██▋       | 7/26 [00:01<00:04,  3.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 8/26 [00:01<00:04,  4.00it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▍      | 9/26 [00:02<00:04,  4.07it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 10/26 [00:02<00:03,  4.13it/s]\u001B[A\n",
      "Validation DataLoader 0:  42%|████▏     | 11/26 [00:02<00:03,  4.17it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 12/26 [00:02<00:03,  4.21it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 13/26 [00:03<00:03,  4.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 14/26 [00:03<00:02,  4.28it/s]\u001B[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 15/26 [00:03<00:02,  4.30it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 16/26 [00:03<00:02,  4.32it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 17/26 [00:03<00:02,  4.34it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 18/26 [00:04<00:01,  4.36it/s]\u001B[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 19/26 [00:04<00:01,  4.38it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 20/26 [00:04<00:01,  4.37it/s]\u001B[A\n",
      "Validation DataLoader 0:  81%|████████  | 21/26 [00:04<00:01,  4.37it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 22/26 [00:05<00:00,  4.34it/s]\u001B[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 23/26 [00:05<00:00,  4.36it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 24/26 [00:05<00:00,  4.34it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 25/26 [00:05<00:00,  4.36it/s]\u001B[A\n",
      "Epoch 1: 100%|██████████| 179/179 [01:17<00:00,  2.30it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=2.040]\n",
      "Epoch 1: 100%|██████████| 179/179 [01:17<00:00,  2.30it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 1.978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 179/179 [00:57<00:00,  3.12it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=1.990]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▍         | 1/26 [00:00<00:11,  2.27it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 2/26 [00:00<00:07,  3.03it/s]\u001B[A\n",
      "Validation DataLoader 0:  12%|█▏        | 3/26 [00:00<00:06,  3.40it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 4/26 [00:01<00:06,  3.62it/s]\u001B[A\n",
      "Validation DataLoader 0:  19%|█▉        | 5/26 [00:01<00:05,  3.78it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 6/26 [00:01<00:05,  3.84it/s]\u001B[A\n",
      "Validation DataLoader 0:  27%|██▋       | 7/26 [00:01<00:04,  3.94it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 8/26 [00:01<00:04,  4.02it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▍      | 9/26 [00:02<00:04,  4.09it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 10/26 [00:02<00:03,  4.14it/s]\u001B[A\n",
      "Validation DataLoader 0:  42%|████▏     | 11/26 [00:02<00:03,  4.18it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 12/26 [00:02<00:03,  4.20it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 13/26 [00:03<00:03,  4.23it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 14/26 [00:03<00:02,  4.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 15/26 [00:03<00:02,  4.26it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 16/26 [00:03<00:02,  4.28it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 17/26 [00:03<00:02,  4.30it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 18/26 [00:04<00:01,  4.32it/s]\u001B[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 19/26 [00:04<00:01,  4.34it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 20/26 [00:04<00:01,  4.36it/s]\u001B[A\n",
      "Validation DataLoader 0:  81%|████████  | 21/26 [00:04<00:01,  4.37it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 22/26 [00:05<00:00,  4.38it/s]\u001B[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 23/26 [00:05<00:00,  4.40it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 24/26 [00:05<00:00,  4.41it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 25/26 [00:05<00:00,  4.42it/s]\u001B[A\n",
      "Epoch 2: 100%|██████████| 179/179 [01:17<00:00,  2.31it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=1.990]\n",
      "Epoch 2: 100%|██████████| 179/179 [01:17<00:00,  2.31it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=1.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 1.978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 179/179 [00:56<00:00,  3.19it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.990]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▍         | 1/26 [00:00<00:11,  2.12it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 2/26 [00:00<00:08,  2.87it/s]\u001B[A\n",
      "Validation DataLoader 0:  12%|█▏        | 3/26 [00:00<00:07,  3.17it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 4/26 [00:01<00:06,  3.41it/s]\u001B[A\n",
      "Validation DataLoader 0:  19%|█▉        | 5/26 [00:01<00:05,  3.53it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 6/26 [00:01<00:05,  3.59it/s]\u001B[A\n",
      "Validation DataLoader 0:  27%|██▋       | 7/26 [00:01<00:05,  3.68it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 8/26 [00:02<00:04,  3.67it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▍      | 9/26 [00:02<00:04,  3.74it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 10/26 [00:02<00:04,  3.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  42%|████▏     | 11/26 [00:02<00:03,  3.81it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 12/26 [00:03<00:03,  3.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 13/26 [00:03<00:03,  3.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 14/26 [00:03<00:03,  3.85it/s]\u001B[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 15/26 [00:03<00:02,  3.87it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 16/26 [00:04<00:02,  3.87it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 17/26 [00:04<00:02,  3.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 18/26 [00:04<00:02,  3.90it/s]\u001B[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 19/26 [00:04<00:01,  3.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 20/26 [00:05<00:01,  3.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  81%|████████  | 21/26 [00:05<00:01,  3.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 22/26 [00:05<00:01,  3.94it/s]\u001B[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 23/26 [00:05<00:00,  3.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 24/26 [00:06<00:00,  3.93it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 25/26 [00:06<00:00,  3.93it/s]\u001B[A\n",
      "Epoch 3: 100%|██████████| 179/179 [01:17<00:00,  2.32it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.990]\n",
      "Epoch 3: 100%|██████████| 179/179 [01:17<00:00,  2.32it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 1.978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  19%|█▉        | 34/179 [00:23<01:39,  1.46it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=1.990] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piotrek\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "Restoring states from the checkpoint path at cnn_lstm\\lightning_logs\\version_0\\checkpoints\\epoch=3-step=716.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at cnn_lstm\\lightning_logs\\version_0\\checkpoints\\epoch=3-step=716.ckpt\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "predictions = []\n",
    "for i in range(5):\n",
    "    lightning.pytorch.seed_everything(i)\n",
    "    model = MyLSTM(extractor, 32, 1, 12)\n",
    "    early_stopping = lightning.pytorch.callbacks.EarlyStopping('val_loss', verbose=True)\n",
    "    logger = lightning.pytorch.loggers.tensorboard.TensorBoardLogger(save_dir=\"cnn_lstm\", version=i)\n",
    "    trainer = lightning.Trainer(max_epochs=200, callbacks=[early_stopping], logger=logger)\n",
    "    trainer.fit(model, train_dataloaders=train_dataset_loader, val_dataloaders=valid_dataset_loader)\n",
    "    res = trainer.test(dataloaders=test_dataset_loader, ckpt_path='best')\n",
    "    test_pred_tensor = torch.cat(trainer.predict(dataloaders=test_dataset_loader, ckpt_path='best'))\n",
    "    results.append(res[0])\n",
    "    predictions.append(test_pred_tensor)\n",
    "torch.save(torch.stack(predictions), \"wav2vec_lstm.ts\")\n",
    "pd.DataFrame(results).to_csv(\"wav2vec_lstm.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T23:25:42.557530Z",
     "end_time": "2023-04-22T00:44:35.695274Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
