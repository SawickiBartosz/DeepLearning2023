{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lightning\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "\n",
    "from .load_data import AudioTrainDataset, PaddingZeros, CustomSpectogram, TargetEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:24:34.461936Z",
     "end_time": "2023-04-19T22:24:38.222937Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{1: 'bed',\n 2: 'bird',\n 3: 'cat',\n 4: 'dog',\n 5: 'down',\n 6: 'eight',\n 7: 'five',\n 8: 'four',\n 9: 'go',\n 10: 'happy',\n 11: 'house',\n 12: 'left',\n 13: 'marvin',\n 14: 'nine',\n 15: 'no',\n 16: 'off',\n 17: 'on',\n 18: 'one',\n 19: 'right',\n 20: 'seven',\n 21: 'sheila',\n 22: 'silence',\n 23: 'six',\n 24: 'stop',\n 25: 'three',\n 26: 'tree',\n 27: 'two',\n 28: 'up',\n 29: 'wow',\n 30: 'yes',\n 31: 'zero'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(\"tensorflow-speech-recognition-challenge\", \"train\", \"audio\")\n",
    "dataset = AudioTrainDataset(DATA_PATH)\n",
    "\n",
    "labels_list, labels_dict = dataset.find_classes(DATA_PATH)\n",
    "labels_dict = {idx: name for name, idx in labels_dict.items()}\n",
    "labels_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:24:38.225937Z",
     "end_time": "2023-04-19T22:24:38.548925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "NUM_WORKERS = 6\n",
    "BATCH_SIZE = 512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:24:38.550568Z",
     "end_time": "2023-04-19T22:24:38.592930Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    PaddingZeros(16000),\n",
    "    CustomSpectogram(n_fft=1024, power=2),\n",
    "])\n",
    "\n",
    "features_dataset = AudioTrainDataset(DATA_PATH, transform=transforms,\n",
    "                                     target_transform=TargetEncoder(class_dict=labels_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:24:38.566930Z",
     "end_time": "2023-04-19T22:24:38.859404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(45587, 6512, 13024)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = torch.Generator().manual_seed(42)\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(features_dataset, [0.7, 0.1, 0.2],\n",
    "                                                                           generator=gen)\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:24:38.861404Z",
     "end_time": "2023-04-19T22:24:38.875404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Studies\\DataScience-1sem\\DeepLearning\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(90, 13, 26)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True,\n",
    "                                  generator=torch.random.manual_seed(123))\n",
    "valid_dataset_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "test_dataset_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "len(train_dataset_loader), len(valid_dataset_loader), len(test_dataset_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:24:38.878404Z",
     "end_time": "2023-04-19T22:24:38.920540Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MyLSTM(lightning.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, target_size):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers=1, batch_first=True)\n",
    "        self.hidden2label = torch.nn.Linear(hidden_size, target_size)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=target_size)\n",
    "        self.valid_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=target_size)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=target_size)\n",
    "        self.test_conf_mat = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_squeeze = x.squeeze()\n",
    "        lstm_out, _ = self.lstm(x_squeeze)\n",
    "        label_space = self.hidden2label(lstm_out[:, -1])\n",
    "        return self.softmax(label_space)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        self.train_acc(y_hat, torch.argmax(y, dim=-1))\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc_step\", self.train_acc)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log('train_acc', self.train_acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        return self(x)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        self.valid_acc(y_hat, torch.argmax(y, dim=-1))\n",
    "        self.log('val_loss', loss, on_epoch=True)\n",
    "        self.log('val_acc', self.valid_acc, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        y_class = torch.argmax(y, dim=-1)\n",
    "        self.test_acc(y_hat, y_class)\n",
    "        self.test_conf_mat(y_hat, y_class)\n",
    "        self.log('test_loss', loss, on_epoch=True)\n",
    "        self.log('test_acc', self.test_acc, on_epoch=True)\n",
    "        self.log('test_confustion_matrix', self.test_conf_mat)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.3, patience=3),\n",
    "                \"monitor\": \"val_loss\",\n",
    "            }\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:24:38.892405Z",
     "end_time": "2023-04-19T22:24:38.923541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                      | Params\n",
      "------------------------------------------------------------\n",
      "0 | lstm          | LSTM                      | 329 K \n",
      "1 | hidden2label  | Linear                    | 1.5 K \n",
      "2 | softmax       | Softmax                   | 0     \n",
      "3 | train_acc     | MulticlassAccuracy        | 0     \n",
      "4 | valid_acc     | MulticlassAccuracy        | 0     \n",
      "5 | test_acc      | MulticlassAccuracy        | 0     \n",
      "6 | test_conf_mat | MulticlassConfusionMatrix | 0     \n",
      "------------------------------------------------------------\n",
      "330 K     Trainable params\n",
      "0         Non-trainable params\n",
      "330 K     Total params\n",
      "1.323     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ed4cdcfe3e2425d9e1c9a3af3fe41f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5ad6f1c24da47779e305f4f1bd9bea1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8666a86b05254d718044179000b419da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9cd5827ae2b42ba9510bbc4f7906189"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "model = MyLSTM(513, 128, 12)\n",
    "trainer = lightning.Trainer(max_epochs=2, logger=True)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "trainer.fit(model, train_dataloaders=train_dataset_loader, val_dataloaders=valid_dataset_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:39:40.123632Z",
     "end_time": "2023-04-19T22:42:41.676275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                      | Params\n",
      "------------------------------------------------------------\n",
      "0 | lstm          | LSTM                      | 82.9 K\n",
      "1 | hidden2label  | Linear                    | 1.5 K \n",
      "2 | softmax       | Softmax                   | 0     \n",
      "3 | train_acc     | MulticlassAccuracy        | 0     \n",
      "4 | valid_acc     | MulticlassAccuracy        | 0     \n",
      "5 | test_acc      | MulticlassAccuracy        | 0     \n",
      "6 | test_conf_mat | MulticlassConfusionMatrix | 0     \n",
      "------------------------------------------------------------\n",
      "84.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "84.5 K    Total params\n",
      "0.338     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 90/90 [00:28<00:00,  3.12it/s, v_num=5, train_loss_step=2.040]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 1/13 [00:00<00:04,  2.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 2/13 [00:00<00:02,  5.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 3/13 [00:00<00:01,  7.16it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 4/13 [00:00<00:01,  8.72it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 5/13 [00:00<00:00, 10.06it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 6/13 [00:00<00:00, 11.24it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 7/13 [00:00<00:00, 12.30it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 8/13 [00:00<00:00, 13.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 9/13 [00:00<00:00, 14.02it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 10/13 [00:00<00:00, 14.73it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 11/13 [00:00<00:00, 15.34it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 12/13 [00:00<00:00, 15.94it/s]\u001B[A\n",
      "Epoch 0: 100%|██████████| 90/90 [00:54<00:00,  1.66it/s, v_num=5, train_loss_step=2.040]\n",
      "Epoch 1: 100%|██████████| 90/90 [00:29<00:00,  3.02it/s, v_num=5, train_loss_step=1.880, train_loss_epoch=2.090]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 1/13 [00:00<00:04,  2.87it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 2/13 [00:00<00:02,  5.12it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 3/13 [00:00<00:01,  7.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 4/13 [00:00<00:01,  8.64it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 5/13 [00:00<00:00, 10.06it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 6/13 [00:00<00:00, 11.29it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 7/13 [00:00<00:00, 12.33it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 8/13 [00:00<00:00, 13.30it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 9/13 [00:00<00:00, 14.14it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 10/13 [00:00<00:00, 14.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 11/13 [00:00<00:00, 14.84it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 12/13 [00:00<00:00, 15.44it/s]\u001B[A\n",
      "Epoch 1: 100%|██████████| 90/90 [00:54<00:00,  1.64it/s, v_num=5, train_loss_step=1.880, train_loss_epoch=2.090]\n",
      "Epoch 2: 100%|██████████| 90/90 [00:30<00:00,  2.99it/s, v_num=5, train_loss_step=2.040, train_loss_epoch=1.990]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 1/13 [00:00<00:03,  3.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 2/13 [00:00<00:01,  6.45it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 3/13 [00:00<00:01,  8.64it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 4/13 [00:00<00:00, 10.36it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 5/13 [00:00<00:00, 11.84it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 6/13 [00:00<00:00, 13.07it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 7/13 [00:00<00:00, 13.99it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 8/13 [00:00<00:00, 14.91it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 9/13 [00:00<00:00, 15.69it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 10/13 [00:00<00:00, 16.43it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 11/13 [00:00<00:00, 17.07it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 12/13 [00:00<00:00, 17.69it/s]\u001B[A\n",
      "Epoch 2: 100%|██████████| 90/90 [00:55<00:00,  1.62it/s, v_num=5, train_loss_step=2.040, train_loss_epoch=1.990]\n",
      "Epoch 3: 100%|██████████| 90/90 [00:30<00:00,  2.91it/s, v_num=5, train_loss_step=1.930, train_loss_epoch=1.990]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/13 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 1/13 [00:00<00:02,  5.07it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▌        | 2/13 [00:00<00:01,  8.63it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 3/13 [00:00<00:00, 11.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 4/13 [00:00<00:00, 13.17it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 5/13 [00:00<00:00, 14.68it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 6/13 [00:00<00:00, 16.06it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 7/13 [00:00<00:00, 16.88it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 8/13 [00:00<00:00, 17.79it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 9/13 [00:00<00:00, 18.53it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 10/13 [00:00<00:00, 19.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▍ | 11/13 [00:00<00:00, 19.69it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 12/13 [00:00<00:00, 20.25it/s]\u001B[A\n",
      "Epoch 3: 100%|██████████| 90/90 [00:56<00:00,  1.59it/s, v_num=5, train_loss_step=1.930, train_loss_epoch=1.990]\n",
      "Epoch 3: 100%|██████████| 90/90 [00:56<00:00,  1.59it/s, v_num=5, train_loss_step=1.930, train_loss_epoch=1.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 90/90 [00:56<00:00,  1.59it/s, v_num=5, train_loss_step=1.930, train_loss_epoch=1.990]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 26/26 [00:01<00:00, 20.42it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The metric `tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  463,    1],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  463,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  483,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  462,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  482,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  492,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  497,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  450,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    1,    0,  466,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  500,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 8185,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   54,   25]],\n       device='cuda:0')` does not contain a single element, thus it cannot be converted to a scalar.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m     trainer \u001B[38;5;241m=\u001B[39m lightning\u001B[38;5;241m.\u001B[39mTrainer(max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, callbacks\u001B[38;5;241m=\u001B[39m[early_stopping])\n\u001B[0;32m      7\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mfit(model, train_dataloaders\u001B[38;5;241m=\u001B[39mtrain_dataset_loader, val_dataloaders\u001B[38;5;241m=\u001B[39mvalid_dataset_loader)\n\u001B[1;32m----> 8\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_dataset_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     results\u001B[38;5;241m.\u001B[39mappend(res[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     10\u001B[0m results\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:706\u001B[0m, in \u001B[0;36mTrainer.test\u001B[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001B[0m\n\u001B[0;32m    704\u001B[0m     model \u001B[38;5;241m=\u001B[39m _maybe_unwrap_optimized(model)\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[1;32m--> 706\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_test_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\n\u001B[0;32m    708\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 44\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[0;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:749\u001B[0m, in \u001B[0;36mTrainer._test_impl\u001B[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001B[0m\n\u001B[0;32m    744\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mattach_data(model, test_dataloaders\u001B[38;5;241m=\u001B[39mdataloaders, datamodule\u001B[38;5;241m=\u001B[39mdatamodule)\n\u001B[0;32m    746\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[0;32m    747\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn, ckpt_path, model_provided\u001B[38;5;241m=\u001B[39mmodel_provided, model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    748\u001B[0m )\n\u001B[1;32m--> 749\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    750\u001B[0m \u001B[38;5;66;03m# remove the tensors from the test results\u001B[39;00m\n\u001B[0;32m    751\u001B[0m results \u001B[38;5;241m=\u001B[39m convert_tensors_to_scalars(results)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:935\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m    930\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[0;32m    932\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    933\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m--> 935\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    937\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    938\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[0;32m    939\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    940\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:971\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    968\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun-stage\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    970\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluating:\n\u001B[1;32m--> 971\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluation_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[0;32m    973\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_loop\u001B[38;5;241m.\u001B[39mrun()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:177\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    175\u001B[0m     context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mno_grad\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[1;32m--> 177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loop_run(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:122\u001B[0m, in \u001B[0;36m_EvaluationLoop.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_store_dataloader_outputs()\n\u001B[1;32m--> 122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_run_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:255\u001B[0m, in \u001B[0;36m_EvaluationLoop.on_run_end\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    252\u001B[0m     dl_outputs\u001B[38;5;241m.\u001B[39mupdate(epoch_end_logged_outputs)\n\u001B[0;32m    254\u001B[0m \u001B[38;5;66;03m# log metrics\u001B[39;00m\n\u001B[1;32m--> 255\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_logger_connector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_eval_end_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_logged_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# hook\u001B[39;00m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_evaluation_end()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:141\u001B[0m, in \u001B[0;36m_LoggerConnector.log_eval_end_metrics\u001B[1;34m(self, metrics)\u001B[0m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;66;03m# log all the metrics as a single dict\u001B[39;00m\n\u001B[1;32m--> 141\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:96\u001B[0m, in \u001B[0;36m_LoggerConnector.log_metrics\u001B[1;34m(self, metrics, step)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_logged_metrics\u001B[38;5;241m.\u001B[39mupdate(metrics)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m# turn all tensors to scalars\u001B[39;00m\n\u001B[1;32m---> 96\u001B[0m scalar_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_tensors_to_scalars\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     99\u001B[0m     step \u001B[38;5;241m=\u001B[39m scalar_metrics\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\fabric\\utilities\\apply_func.py:126\u001B[0m, in \u001B[0;36mconvert_tensors_to_scalars\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    121\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    122\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe metric `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` does not contain a single element, thus it cannot be converted to a scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m         )\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_to_collection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_item\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py:59\u001B[0m, in \u001B[0;36mapply_to_collection\u001B[1;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001B[0m\n\u001B[0;32m     57\u001B[0m out \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m---> 59\u001B[0m     v \u001B[38;5;241m=\u001B[39m apply_to_collection(\n\u001B[0;32m     60\u001B[0m         v,\n\u001B[0;32m     61\u001B[0m         dtype,\n\u001B[0;32m     62\u001B[0m         function,\n\u001B[0;32m     63\u001B[0m         \u001B[38;5;241m*\u001B[39margs,\n\u001B[0;32m     64\u001B[0m         wrong_dtype\u001B[38;5;241m=\u001B[39mwrong_dtype,\n\u001B[0;32m     65\u001B[0m         include_none\u001B[38;5;241m=\u001B[39minclude_none,\n\u001B[0;32m     66\u001B[0m         allow_frozen\u001B[38;5;241m=\u001B[39mallow_frozen,\n\u001B[0;32m     67\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     68\u001B[0m     )\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m include_none \u001B[38;5;129;01mor\u001B[39;00m v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     70\u001B[0m         out\u001B[38;5;241m.\u001B[39mappend((k, v))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py:51\u001B[0m, in \u001B[0;36mapply_to_collection\u001B[1;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# Breaking condition\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, dtype) \u001B[38;5;129;01mand\u001B[39;00m (wrong_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, wrong_dtype)):\n\u001B[1;32m---> 51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(data, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     53\u001B[0m elem_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(data)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# Recursively apply to collection items\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\fabric\\utilities\\apply_func.py:121\u001B[0m, in \u001B[0;36mconvert_tensors_to_scalars.<locals>.to_item\u001B[1;34m(value)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_item\u001B[39m(value: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mbool\u001B[39m]:\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m value\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 121\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    122\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe metric `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` does not contain a single element, thus it cannot be converted to a scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m         )\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[1;31mValueError\u001B[0m: The metric `tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  463,    1],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  463,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  483,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  462,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  482,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  492,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  497,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  450,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    1,    0,  466,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  500,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 8185,    0],\n        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   54,   25]],\n       device='cuda:0')` does not contain a single element, thus it cannot be converted to a scalar."
     ]
    }
   ],
   "source": [
    "early_stopping = lightning.pytorch.callbacks.EarlyStopping('val_loss')\n",
    "results = []\n",
    "for i in range(5):\n",
    "    lightning.pytorch.seed_everything(i)\n",
    "    model = MyLSTM(32, 128, 12)\n",
    "    trainer = lightning.Trainer(max_epochs=4, callbacks=[early_stopping])\n",
    "    trainer.fit(model, train_dataloaders=train_dataset_loader, val_dataloaders=valid_dataset_loader)\n",
    "    res = trainer.test(dataloaders=test_dataset_loader)\n",
    "    results.append(res[0])\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T22:27:51.969076Z",
     "end_time": "2023-04-19T22:27:52.168074Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
