{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T15:10:55.033099Z",
     "end_time": "2023-04-23T15:10:57.976116Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import losses, optimizers, metrics, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T15:10:57.977115Z",
     "end_time": "2023-04-23T15:10:58.803114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T15:10:58.556115Z",
     "end_time": "2023-04-23T15:10:58.804114Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 12\n",
    "MAX_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T15:10:58.572115Z",
     "end_time": "2023-04-23T15:10:58.804114Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45586 files belonging to 12 classes.\n",
      "Found 6513 files belonging to 12 classes.\n",
      "Found 13024 files belonging to 12 classes.\n",
      "label names: ['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/train\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/val\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/test\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print(\"label names:\", label_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:10:58.591114Z",
     "end_time": "2023-04-23T15:11:04.028745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(squeeze, tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:11:04.030743Z",
     "end_time": "2023-04-23T15:11:04.092223Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + LSTM Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " tf.signal.stft (TFOpLambda)    (None, 125, 513)     0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.abs (TFOpLambda)       (None, 125, 513)     0           ['tf.signal.stft[0][0]']         \n",
      "                                                                                                  \n",
      " tf.tensordot (TFOpLambda)      (None, 125, 80)      0           ['tf.math.abs[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 125, 80)     0           ['tf.tensordot[0][0]']           \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.log (TFOpLambda)       (None, 125, 80)      0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.math.log[0][0]']            \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 125, 80)      0           ['tf.math.log[0][0]',            \n",
      "                                                                  'tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.reduce_std (TFOpLambda  ()                  0           ['tf.math.log[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 125, 80)      0           ['tf.math.subtract[0][0]',       \n",
      "                                                                  'tf.math.reduce_std[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 125, 32)      12832       ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 256)          164864      ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 12)           3084        ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,780\n",
      "Trainable params: 180,780\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from SpeechModels import get_melspec_model\n",
    "import tensorflow.keras.layers as L\n",
    "from keras.models import Model\n",
    "\n",
    "def CNN_LSTM(n_out, input_length, kernel_size):\n",
    "\n",
    "    mel_spec_model = get_melspec_model(input_length)\n",
    "    inputs, outputs = mel_spec_model.inputs, mel_spec_model.outputs\n",
    "    o_shape = outputs[0].shape\n",
    "    y1 = L.Conv1D(32, kernel_size, activation='relu', padding='same', input_shape=o_shape[1:])(outputs[0])\n",
    "\n",
    "    x = L.Bidirectional(L.LSTM(128, return_sequences=False))(y1)  # [b_s, seq_len, vec_dim]\n",
    "\n",
    "    output = L.Dense(n_out, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = CNN_LSTM(N_CLASS, 16000, 5)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:11:04.095223Z",
     "end_time": "2023-04-23T15:11:05.169848Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T15:11:05.173848Z",
     "end_time": "2023-04-23T15:11:05.206848Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    ")\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath=\"simple_cnn.h5\",\n",
    "    monitor=\"val_sparse_categorical_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=3, min_lr=0.00001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T15:11:05.201848Z",
     "end_time": "2023-04-23T15:11:39.645738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "90/90 [==============================] - 22s 115ms/step - loss: 1.4897 - sparse_categorical_accuracy: 0.6263 - sparse_categorical_crossentropy: 1.4897 - val_loss: 1.3607 - val_sparse_categorical_accuracy: 0.6329 - val_sparse_categorical_crossentropy: 1.3607 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 13s 129ms/step - loss: 1.1501 - sparse_categorical_accuracy: 0.6571 - sparse_categorical_crossentropy: 1.1501 - val_loss: 1.0418 - val_sparse_categorical_accuracy: 0.6664 - val_sparse_categorical_crossentropy: 1.0418 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=2,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Training will be repeated 5 times with different weights initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"cnn_lstm_simple\"\n",
    "if os.path.exists(EXPERIMENT_NAME):\n",
    "    shutil.rmtree(EXPERIMENT_NAME)\n",
    "    os.mkdir(EXPERIMENT_NAME)\n",
    "else:\n",
    "    os.mkdir(EXPERIMENT_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:11:39.646739Z",
     "end_time": "2023-04-23T15:11:39.662751Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 14s 117ms/step - loss: 1.4694 - sparse_categorical_accuracy: 0.6248 - sparse_categorical_crossentropy: 1.4694 - val_loss: 1.3282 - val_sparse_categorical_accuracy: 0.6349 - val_sparse_categorical_crossentropy: 1.3282 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 11s 109ms/step - loss: 1.1510 - sparse_categorical_accuracy: 0.6630 - sparse_categorical_crossentropy: 1.1510 - val_loss: 0.9581 - val_sparse_categorical_accuracy: 0.6969 - val_sparse_categorical_crossentropy: 0.9581 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.8099 - sparse_categorical_accuracy: 0.7415 - sparse_categorical_crossentropy: 0.8099 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.7695 - val_sparse_categorical_crossentropy: 0.7036 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.6383 - sparse_categorical_accuracy: 0.8007 - sparse_categorical_crossentropy: 0.6383 - val_loss: 0.6279 - val_sparse_categorical_accuracy: 0.7982 - val_sparse_categorical_crossentropy: 0.6279 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 11s 109ms/step - loss: 0.5898 - sparse_categorical_accuracy: 0.8142 - sparse_categorical_crossentropy: 0.5898 - val_loss: 0.4943 - val_sparse_categorical_accuracy: 0.8452 - val_sparse_categorical_crossentropy: 0.4943 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.4430 - sparse_categorical_accuracy: 0.8640 - sparse_categorical_crossentropy: 0.4430 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.8747 - val_sparse_categorical_crossentropy: 0.3917 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.3844 - sparse_categorical_accuracy: 0.8822 - sparse_categorical_crossentropy: 0.3844 - val_loss: 0.3563 - val_sparse_categorical_accuracy: 0.8895 - val_sparse_categorical_crossentropy: 0.3563 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 11s 111ms/step - loss: 0.3586 - sparse_categorical_accuracy: 0.8876 - sparse_categorical_crossentropy: 0.3586 - val_loss: 0.3602 - val_sparse_categorical_accuracy: 0.8856 - val_sparse_categorical_crossentropy: 0.3602 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 11s 111ms/step - loss: 0.3821 - sparse_categorical_accuracy: 0.8797 - sparse_categorical_crossentropy: 0.3821 - val_loss: 0.3307 - val_sparse_categorical_accuracy: 0.8950 - val_sparse_categorical_crossentropy: 0.3307 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 11s 109ms/step - loss: 0.3337 - sparse_categorical_accuracy: 0.8946 - sparse_categorical_crossentropy: 0.3337 - val_loss: 0.2907 - val_sparse_categorical_accuracy: 0.9088 - val_sparse_categorical_crossentropy: 0.2907 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 11s 109ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.9070 - sparse_categorical_crossentropy: 0.2989 - val_loss: 0.2780 - val_sparse_categorical_accuracy: 0.9091 - val_sparse_categorical_crossentropy: 0.2780 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 11s 109ms/step - loss: 0.2817 - sparse_categorical_accuracy: 0.9127 - sparse_categorical_crossentropy: 0.2817 - val_loss: 0.3057 - val_sparse_categorical_accuracy: 0.9045 - val_sparse_categorical_crossentropy: 0.3057 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.2730 - sparse_categorical_accuracy: 0.9145 - sparse_categorical_crossentropy: 0.2730 - val_loss: 0.2699 - val_sparse_categorical_accuracy: 0.9146 - val_sparse_categorical_crossentropy: 0.2699 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.2488 - sparse_categorical_accuracy: 0.9230 - sparse_categorical_crossentropy: 0.2488 - val_loss: 0.2663 - val_sparse_categorical_accuracy: 0.9172 - val_sparse_categorical_crossentropy: 0.2663 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.2349 - sparse_categorical_accuracy: 0.9270 - sparse_categorical_crossentropy: 0.2349 - val_loss: 0.2489 - val_sparse_categorical_accuracy: 0.9209 - val_sparse_categorical_crossentropy: 0.2489 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.2330 - sparse_categorical_accuracy: 0.9265 - sparse_categorical_crossentropy: 0.2330 - val_loss: 0.2419 - val_sparse_categorical_accuracy: 0.9255 - val_sparse_categorical_crossentropy: 0.2419 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.2211 - sparse_categorical_accuracy: 0.9314 - sparse_categorical_crossentropy: 0.2211 - val_loss: 0.2408 - val_sparse_categorical_accuracy: 0.9271 - val_sparse_categorical_crossentropy: 0.2408 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 0.2068 - sparse_categorical_accuracy: 0.9350 - sparse_categorical_crossentropy: 0.2068 - val_loss: 0.2372 - val_sparse_categorical_accuracy: 0.9281 - val_sparse_categorical_crossentropy: 0.2372 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.2108 - sparse_categorical_accuracy: 0.9339 - sparse_categorical_crossentropy: 0.2108 - val_loss: 0.2336 - val_sparse_categorical_accuracy: 0.9261 - val_sparse_categorical_crossentropy: 0.2336 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 9s 97ms/step - loss: 0.2202 - sparse_categorical_accuracy: 0.9293 - sparse_categorical_crossentropy: 0.2202 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 0.9277 - val_sparse_categorical_crossentropy: 0.2324 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2020 - sparse_categorical_accuracy: 0.9360 - sparse_categorical_crossentropy: 0.2020\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 10s 105ms/step - loss: 0.2020 - sparse_categorical_accuracy: 0.9360 - sparse_categorical_crossentropy: 0.2020 - val_loss: 0.2510 - val_sparse_categorical_accuracy: 0.9240 - val_sparse_categorical_crossentropy: 0.2510 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.1690 - sparse_categorical_accuracy: 0.9468 - sparse_categorical_crossentropy: 0.1690 - val_loss: 0.1951 - val_sparse_categorical_accuracy: 0.9381 - val_sparse_categorical_crossentropy: 0.1951 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9567 - sparse_categorical_crossentropy: 0.1393 - val_loss: 0.1970 - val_sparse_categorical_accuracy: 0.9423 - val_sparse_categorical_crossentropy: 0.1970 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.1364 - sparse_categorical_accuracy: 0.9583 - sparse_categorical_crossentropy: 0.1364 - val_loss: 0.1911 - val_sparse_categorical_accuracy: 0.9420 - val_sparse_categorical_crossentropy: 0.1911 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 11s 109ms/step - loss: 0.1235 - sparse_categorical_accuracy: 0.9625 - sparse_categorical_crossentropy: 0.1235 - val_loss: 0.1850 - val_sparse_categorical_accuracy: 0.9446 - val_sparse_categorical_crossentropy: 0.1850 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.1118 - sparse_categorical_accuracy: 0.9657 - sparse_categorical_crossentropy: 0.1118 - val_loss: 0.1986 - val_sparse_categorical_accuracy: 0.9392 - val_sparse_categorical_crossentropy: 0.1986 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 9s 96ms/step - loss: 0.1129 - sparse_categorical_accuracy: 0.9656 - sparse_categorical_crossentropy: 0.1129 - val_loss: 0.1854 - val_sparse_categorical_accuracy: 0.9461 - val_sparse_categorical_crossentropy: 0.1854 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 11s 112ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9632 - sparse_categorical_crossentropy: 0.1202 - val_loss: 0.1945 - val_sparse_categorical_accuracy: 0.9421 - val_sparse_categorical_crossentropy: 0.1945 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 11s 110ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9629 - sparse_categorical_crossentropy: 0.1206 - val_loss: 0.2033 - val_sparse_categorical_accuracy: 0.9417 - val_sparse_categorical_crossentropy: 0.2033 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1089 - sparse_categorical_accuracy: 0.9666 - sparse_categorical_crossentropy: 0.1089\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9666 - sparse_categorical_crossentropy: 0.1088 - val_loss: 0.1909 - val_sparse_categorical_accuracy: 0.9423 - val_sparse_categorical_crossentropy: 0.1909 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9657 - sparse_categorical_crossentropy: 0.1133 - val_loss: 0.2759 - val_sparse_categorical_accuracy: 0.9175 - val_sparse_categorical_crossentropy: 0.2759 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.1238 - sparse_categorical_accuracy: 0.9607 - sparse_categorical_crossentropy: 0.1238 - val_loss: 0.1885 - val_sparse_categorical_accuracy: 0.9460 - val_sparse_categorical_crossentropy: 0.1885 - lr: 0.0025\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9421 - sparse_categorical_crossentropy: 0.2022\n",
      "26/26 [==============================] - 3s 92ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 14s 115ms/step - loss: 1.4498 - sparse_categorical_accuracy: 0.6254 - sparse_categorical_crossentropy: 1.4498 - val_loss: 1.2969 - val_sparse_categorical_accuracy: 0.6320 - val_sparse_categorical_crossentropy: 1.2969 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 11s 114ms/step - loss: 1.1336 - sparse_categorical_accuracy: 0.6642 - sparse_categorical_crossentropy: 1.1336 - val_loss: 0.9837 - val_sparse_categorical_accuracy: 0.6960 - val_sparse_categorical_crossentropy: 0.9837 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 11s 114ms/step - loss: 0.8306 - sparse_categorical_accuracy: 0.7335 - sparse_categorical_crossentropy: 0.8306 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.7812 - val_sparse_categorical_crossentropy: 0.6975 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 11s 114ms/step - loss: 0.6089 - sparse_categorical_accuracy: 0.8088 - sparse_categorical_crossentropy: 0.6089 - val_loss: 0.6330 - val_sparse_categorical_accuracy: 0.7975 - val_sparse_categorical_crossentropy: 0.6330 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 11s 113ms/step - loss: 0.5221 - sparse_categorical_accuracy: 0.8355 - sparse_categorical_crossentropy: 0.5221 - val_loss: 0.4299 - val_sparse_categorical_accuracy: 0.8620 - val_sparse_categorical_crossentropy: 0.4299 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 11s 115ms/step - loss: 0.4312 - sparse_categorical_accuracy: 0.8655 - sparse_categorical_crossentropy: 0.4312 - val_loss: 0.4645 - val_sparse_categorical_accuracy: 0.8537 - val_sparse_categorical_crossentropy: 0.4645 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 11s 115ms/step - loss: 0.3986 - sparse_categorical_accuracy: 0.8770 - sparse_categorical_crossentropy: 0.3986 - val_loss: 0.3833 - val_sparse_categorical_accuracy: 0.8782 - val_sparse_categorical_crossentropy: 0.3833 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 11s 114ms/step - loss: 0.3574 - sparse_categorical_accuracy: 0.8893 - sparse_categorical_crossentropy: 0.3574 - val_loss: 0.3562 - val_sparse_categorical_accuracy: 0.8871 - val_sparse_categorical_crossentropy: 0.3562 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 11s 114ms/step - loss: 0.3511 - sparse_categorical_accuracy: 0.8920 - sparse_categorical_crossentropy: 0.3511 - val_loss: 0.3141 - val_sparse_categorical_accuracy: 0.8991 - val_sparse_categorical_crossentropy: 0.3141 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 11s 115ms/step - loss: 0.3119 - sparse_categorical_accuracy: 0.9041 - sparse_categorical_crossentropy: 0.3119 - val_loss: 0.3031 - val_sparse_categorical_accuracy: 0.9028 - val_sparse_categorical_crossentropy: 0.3031 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 11s 116ms/step - loss: 0.3016 - sparse_categorical_accuracy: 0.9060 - sparse_categorical_crossentropy: 0.3016 - val_loss: 0.3388 - val_sparse_categorical_accuracy: 0.8968 - val_sparse_categorical_crossentropy: 0.3388 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 11s 116ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.8989 - sparse_categorical_crossentropy: 0.3233 - val_loss: 0.2909 - val_sparse_categorical_accuracy: 0.9120 - val_sparse_categorical_crossentropy: 0.2909 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 0.2646 - sparse_categorical_accuracy: 0.9180 - sparse_categorical_crossentropy: 0.2646 - val_loss: 0.4464 - val_sparse_categorical_accuracy: 0.8617 - val_sparse_categorical_crossentropy: 0.4464 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 11s 116ms/step - loss: 0.3114 - sparse_categorical_accuracy: 0.9037 - sparse_categorical_crossentropy: 0.3114 - val_loss: 0.4329 - val_sparse_categorical_accuracy: 0.8583 - val_sparse_categorical_crossentropy: 0.4329 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.3985 - sparse_categorical_accuracy: 0.8758 - sparse_categorical_crossentropy: 0.3985\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 11s 116ms/step - loss: 0.3984 - sparse_categorical_accuracy: 0.8758 - sparse_categorical_crossentropy: 0.3984 - val_loss: 0.3156 - val_sparse_categorical_accuracy: 0.9013 - val_sparse_categorical_crossentropy: 0.3156 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 12s 119ms/step - loss: 0.2373 - sparse_categorical_accuracy: 0.9271 - sparse_categorical_crossentropy: 0.2373 - val_loss: 0.2501 - val_sparse_categorical_accuracy: 0.9222 - val_sparse_categorical_crossentropy: 0.2501 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 11s 116ms/step - loss: 0.2061 - sparse_categorical_accuracy: 0.9360 - sparse_categorical_crossentropy: 0.2061 - val_loss: 0.2335 - val_sparse_categorical_accuracy: 0.9251 - val_sparse_categorical_crossentropy: 0.2335 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 0.1855 - sparse_categorical_accuracy: 0.9420 - sparse_categorical_crossentropy: 0.1855 - val_loss: 0.2266 - val_sparse_categorical_accuracy: 0.9317 - val_sparse_categorical_crossentropy: 0.2266 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 0.1854 - sparse_categorical_accuracy: 0.9431 - sparse_categorical_crossentropy: 0.1854 - val_loss: 0.2265 - val_sparse_categorical_accuracy: 0.9306 - val_sparse_categorical_crossentropy: 0.2265 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 12s 120ms/step - loss: 0.1711 - sparse_categorical_accuracy: 0.9467 - sparse_categorical_crossentropy: 0.1711 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9272 - val_sparse_categorical_crossentropy: 0.2272 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 0.1654 - sparse_categorical_accuracy: 0.9493 - sparse_categorical_crossentropy: 0.1654 - val_loss: 0.2168 - val_sparse_categorical_accuracy: 0.9341 - val_sparse_categorical_crossentropy: 0.2168 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 12s 121ms/step - loss: 0.1655 - sparse_categorical_accuracy: 0.9484 - sparse_categorical_crossentropy: 0.1655 - val_loss: 0.2156 - val_sparse_categorical_accuracy: 0.9337 - val_sparse_categorical_crossentropy: 0.2156 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.1503 - sparse_categorical_accuracy: 0.9529 - sparse_categorical_crossentropy: 0.1503 - val_loss: 0.2027 - val_sparse_categorical_accuracy: 0.9344 - val_sparse_categorical_crossentropy: 0.2027 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.1420 - sparse_categorical_accuracy: 0.9570 - sparse_categorical_crossentropy: 0.1420 - val_loss: 0.2168 - val_sparse_categorical_accuracy: 0.9340 - val_sparse_categorical_crossentropy: 0.2168 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.1308 - sparse_categorical_accuracy: 0.9600 - sparse_categorical_crossentropy: 0.1308 - val_loss: 0.1998 - val_sparse_categorical_accuracy: 0.9397 - val_sparse_categorical_crossentropy: 0.1998 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.1531 - sparse_categorical_accuracy: 0.9516 - sparse_categorical_crossentropy: 0.1531 - val_loss: 0.2061 - val_sparse_categorical_accuracy: 0.9381 - val_sparse_categorical_crossentropy: 0.2061 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.1386 - sparse_categorical_accuracy: 0.9566 - sparse_categorical_crossentropy: 0.1386 - val_loss: 0.2041 - val_sparse_categorical_accuracy: 0.9374 - val_sparse_categorical_crossentropy: 0.2041 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1253 - sparse_categorical_accuracy: 0.9611 - sparse_categorical_crossentropy: 0.1253\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 10s 105ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9611 - sparse_categorical_crossentropy: 0.1253 - val_loss: 0.2075 - val_sparse_categorical_accuracy: 0.9375 - val_sparse_categorical_crossentropy: 0.2075 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.1116 - sparse_categorical_accuracy: 0.9661 - sparse_categorical_crossentropy: 0.1116 - val_loss: 0.1848 - val_sparse_categorical_accuracy: 0.9446 - val_sparse_categorical_crossentropy: 0.1848 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9733 - sparse_categorical_crossentropy: 0.0939 - val_loss: 0.1857 - val_sparse_categorical_accuracy: 0.9463 - val_sparse_categorical_crossentropy: 0.1857 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.0836 - sparse_categorical_accuracy: 0.9762 - sparse_categorical_crossentropy: 0.0836 - val_loss: 0.1898 - val_sparse_categorical_accuracy: 0.9450 - val_sparse_categorical_crossentropy: 0.1898 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9787 - sparse_categorical_crossentropy: 0.0781 - val_loss: 0.1960 - val_sparse_categorical_accuracy: 0.9429 - val_sparse_categorical_crossentropy: 0.1960 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0871 - sparse_categorical_accuracy: 0.9750 - sparse_categorical_crossentropy: 0.0871\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 10s 105ms/step - loss: 0.0871 - sparse_categorical_accuracy: 0.9750 - sparse_categorical_crossentropy: 0.0871 - val_loss: 0.1892 - val_sparse_categorical_accuracy: 0.9453 - val_sparse_categorical_crossentropy: 0.1892 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 10s 104ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9814 - sparse_categorical_crossentropy: 0.0701 - val_loss: 0.1815 - val_sparse_categorical_accuracy: 0.9480 - val_sparse_categorical_crossentropy: 0.1815 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9840 - sparse_categorical_crossentropy: 0.0637 - val_loss: 0.1872 - val_sparse_categorical_accuracy: 0.9463 - val_sparse_categorical_crossentropy: 0.1872 - lr: 0.0012\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9857 - sparse_categorical_crossentropy: 0.0590 - val_loss: 0.1850 - val_sparse_categorical_accuracy: 0.9466 - val_sparse_categorical_crossentropy: 0.1850 - lr: 0.0012\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0560 - sparse_categorical_accuracy: 0.9869 - sparse_categorical_crossentropy: 0.0560\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.0560 - sparse_categorical_accuracy: 0.9869 - sparse_categorical_crossentropy: 0.0560 - val_loss: 0.1863 - val_sparse_categorical_accuracy: 0.9467 - val_sparse_categorical_crossentropy: 0.1863 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 10s 104ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9880 - sparse_categorical_crossentropy: 0.0524 - val_loss: 0.1830 - val_sparse_categorical_accuracy: 0.9467 - val_sparse_categorical_crossentropy: 0.1830 - lr: 6.2500e-04\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9889 - sparse_categorical_crossentropy: 0.0506 - val_loss: 0.1841 - val_sparse_categorical_accuracy: 0.9469 - val_sparse_categorical_crossentropy: 0.1841 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.2028 - sparse_categorical_accuracy: 0.9426 - sparse_categorical_crossentropy: 0.2028\n",
      "26/26 [==============================] - 3s 89ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 13s 106ms/step - loss: 1.4895 - sparse_categorical_accuracy: 0.6246 - sparse_categorical_crossentropy: 1.4895 - val_loss: 1.3282 - val_sparse_categorical_accuracy: 0.6367 - val_sparse_categorical_crossentropy: 1.3282 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 1.1669 - sparse_categorical_accuracy: 0.6581 - sparse_categorical_crossentropy: 1.1669 - val_loss: 0.9948 - val_sparse_categorical_accuracy: 0.6839 - val_sparse_categorical_crossentropy: 0.9948 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.7904 - sparse_categorical_accuracy: 0.7498 - sparse_categorical_crossentropy: 0.7904 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.7751 - val_sparse_categorical_crossentropy: 0.6882 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.6376 - sparse_categorical_accuracy: 0.8001 - sparse_categorical_crossentropy: 0.6376 - val_loss: 0.5639 - val_sparse_categorical_accuracy: 0.8176 - val_sparse_categorical_crossentropy: 0.5639 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 10s 105ms/step - loss: 0.5467 - sparse_categorical_accuracy: 0.8287 - sparse_categorical_crossentropy: 0.5467 - val_loss: 0.4547 - val_sparse_categorical_accuracy: 0.8604 - val_sparse_categorical_crossentropy: 0.4547 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.4655 - sparse_categorical_accuracy: 0.8558 - sparse_categorical_crossentropy: 0.4655 - val_loss: 0.4126 - val_sparse_categorical_accuracy: 0.8700 - val_sparse_categorical_crossentropy: 0.4126 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 10s 105ms/step - loss: 0.4406 - sparse_categorical_accuracy: 0.8638 - sparse_categorical_crossentropy: 0.4406 - val_loss: 0.4069 - val_sparse_categorical_accuracy: 0.8696 - val_sparse_categorical_crossentropy: 0.4069 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 10s 100ms/step - loss: 0.3817 - sparse_categorical_accuracy: 0.8827 - sparse_categorical_crossentropy: 0.3817 - val_loss: 0.4072 - val_sparse_categorical_accuracy: 0.8684 - val_sparse_categorical_crossentropy: 0.4072 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.4150 - sparse_categorical_accuracy: 0.8708 - sparse_categorical_crossentropy: 0.4150 - val_loss: 0.3511 - val_sparse_categorical_accuracy: 0.8893 - val_sparse_categorical_crossentropy: 0.3511 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 10s 104ms/step - loss: 0.3424 - sparse_categorical_accuracy: 0.8938 - sparse_categorical_crossentropy: 0.3424 - val_loss: 0.3359 - val_sparse_categorical_accuracy: 0.8950 - val_sparse_categorical_crossentropy: 0.3359 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 10s 101ms/step - loss: 0.3201 - sparse_categorical_accuracy: 0.9009 - sparse_categorical_crossentropy: 0.3201 - val_loss: 0.3178 - val_sparse_categorical_accuracy: 0.8999 - val_sparse_categorical_crossentropy: 0.3178 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 12s 121ms/step - loss: 0.3111 - sparse_categorical_accuracy: 0.9042 - sparse_categorical_crossentropy: 0.3111 - val_loss: 0.3690 - val_sparse_categorical_accuracy: 0.8841 - val_sparse_categorical_crossentropy: 0.3690 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 11s 116ms/step - loss: 0.3140 - sparse_categorical_accuracy: 0.9033 - sparse_categorical_crossentropy: 0.3140 - val_loss: 0.2897 - val_sparse_categorical_accuracy: 0.9091 - val_sparse_categorical_crossentropy: 0.2897 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 11s 112ms/step - loss: 0.3353 - sparse_categorical_accuracy: 0.8952 - sparse_categorical_crossentropy: 0.3353 - val_loss: 0.2902 - val_sparse_categorical_accuracy: 0.9119 - val_sparse_categorical_crossentropy: 0.2902 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 10s 101ms/step - loss: 0.2829 - sparse_categorical_accuracy: 0.9129 - sparse_categorical_crossentropy: 0.2829 - val_loss: 0.2830 - val_sparse_categorical_accuracy: 0.9140 - val_sparse_categorical_crossentropy: 0.2830 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 10s 101ms/step - loss: 0.2719 - sparse_categorical_accuracy: 0.9154 - sparse_categorical_crossentropy: 0.2719 - val_loss: 0.3140 - val_sparse_categorical_accuracy: 0.9036 - val_sparse_categorical_crossentropy: 0.3140 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 10s 101ms/step - loss: 0.2484 - sparse_categorical_accuracy: 0.9230 - sparse_categorical_crossentropy: 0.2484 - val_loss: 0.2612 - val_sparse_categorical_accuracy: 0.9183 - val_sparse_categorical_crossentropy: 0.2612 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 10s 100ms/step - loss: 0.2313 - sparse_categorical_accuracy: 0.9279 - sparse_categorical_crossentropy: 0.2313 - val_loss: 0.2764 - val_sparse_categorical_accuracy: 0.9174 - val_sparse_categorical_crossentropy: 0.2764 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.2662 - sparse_categorical_accuracy: 0.9176 - sparse_categorical_crossentropy: 0.2662 - val_loss: 0.2881 - val_sparse_categorical_accuracy: 0.9100 - val_sparse_categorical_crossentropy: 0.2881 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2321 - sparse_categorical_accuracy: 0.9274 - sparse_categorical_crossentropy: 0.2321\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 10s 100ms/step - loss: 0.2321 - sparse_categorical_accuracy: 0.9275 - sparse_categorical_crossentropy: 0.2321 - val_loss: 0.2667 - val_sparse_categorical_accuracy: 0.9179 - val_sparse_categorical_crossentropy: 0.2667 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 10s 104ms/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9412 - sparse_categorical_crossentropy: 0.1929 - val_loss: 0.2181 - val_sparse_categorical_accuracy: 0.9304 - val_sparse_categorical_crossentropy: 0.2181 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9492 - sparse_categorical_crossentropy: 0.1671 - val_loss: 0.2199 - val_sparse_categorical_accuracy: 0.9304 - val_sparse_categorical_crossentropy: 0.2199 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 10s 105ms/step - loss: 0.1686 - sparse_categorical_accuracy: 0.9480 - sparse_categorical_crossentropy: 0.1686 - val_loss: 0.2195 - val_sparse_categorical_accuracy: 0.9344 - val_sparse_categorical_crossentropy: 0.2195 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9558 - sparse_categorical_crossentropy: 0.1465 - val_loss: 0.2231 - val_sparse_categorical_accuracy: 0.9318 - val_sparse_categorical_crossentropy: 0.2231 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 10s 104ms/step - loss: 0.1565 - sparse_categorical_accuracy: 0.9513 - sparse_categorical_crossentropy: 0.1565 - val_loss: 0.2071 - val_sparse_categorical_accuracy: 0.9344 - val_sparse_categorical_crossentropy: 0.2071 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.1450 - sparse_categorical_accuracy: 0.9549 - sparse_categorical_crossentropy: 0.1450 - val_loss: 0.2021 - val_sparse_categorical_accuracy: 0.9375 - val_sparse_categorical_crossentropy: 0.2021 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 0.1480 - sparse_categorical_accuracy: 0.9554 - sparse_categorical_crossentropy: 0.1480 - val_loss: 0.2008 - val_sparse_categorical_accuracy: 0.9394 - val_sparse_categorical_crossentropy: 0.2008 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 12s 118ms/step - loss: 0.1340 - sparse_categorical_accuracy: 0.9586 - sparse_categorical_crossentropy: 0.1340 - val_loss: 0.2019 - val_sparse_categorical_accuracy: 0.9383 - val_sparse_categorical_crossentropy: 0.2019 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9600 - sparse_categorical_crossentropy: 0.1296 - val_loss: 0.2012 - val_sparse_categorical_accuracy: 0.9361 - val_sparse_categorical_crossentropy: 0.2012 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1212 - sparse_categorical_accuracy: 0.9629 - sparse_categorical_crossentropy: 0.1212\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 11s 114ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9629 - sparse_categorical_crossentropy: 0.1213 - val_loss: 0.2012 - val_sparse_categorical_accuracy: 0.9390 - val_sparse_categorical_crossentropy: 0.2012 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9691 - sparse_categorical_crossentropy: 0.1041 - val_loss: 0.1939 - val_sparse_categorical_accuracy: 0.9426 - val_sparse_categorical_crossentropy: 0.1939 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9723 - sparse_categorical_crossentropy: 0.0952 - val_loss: 0.1906 - val_sparse_categorical_accuracy: 0.9421 - val_sparse_categorical_crossentropy: 0.1906 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.0837 - sparse_categorical_accuracy: 0.9763 - sparse_categorical_crossentropy: 0.0837 - val_loss: 0.1945 - val_sparse_categorical_accuracy: 0.9440 - val_sparse_categorical_crossentropy: 0.1945 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 11s 116ms/step - loss: 0.0770 - sparse_categorical_accuracy: 0.9786 - sparse_categorical_crossentropy: 0.0770 - val_loss: 0.1907 - val_sparse_categorical_accuracy: 0.9435 - val_sparse_categorical_crossentropy: 0.1907 - lr: 0.0025\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9801 - sparse_categorical_crossentropy: 0.0743 - val_loss: 0.1961 - val_sparse_categorical_accuracy: 0.9410 - val_sparse_categorical_crossentropy: 0.1961 - lr: 0.0025\n",
      "Epoch 36/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0705 - sparse_categorical_accuracy: 0.9815 - sparse_categorical_crossentropy: 0.0705\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9815 - sparse_categorical_crossentropy: 0.0705 - val_loss: 0.1928 - val_sparse_categorical_accuracy: 0.9432 - val_sparse_categorical_crossentropy: 0.1928 - lr: 0.0025\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9847 - sparse_categorical_crossentropy: 0.0618 - val_loss: 0.1890 - val_sparse_categorical_accuracy: 0.9441 - val_sparse_categorical_crossentropy: 0.1890 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 10s 101ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9861 - sparse_categorical_crossentropy: 0.0573 - val_loss: 0.1870 - val_sparse_categorical_accuracy: 0.9449 - val_sparse_categorical_crossentropy: 0.1870 - lr: 0.0012\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.9873 - sparse_categorical_crossentropy: 0.0545 - val_loss: 0.1895 - val_sparse_categorical_accuracy: 0.9444 - val_sparse_categorical_crossentropy: 0.1895 - lr: 0.0012\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 10s 103ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9880 - sparse_categorical_crossentropy: 0.0532 - val_loss: 0.1933 - val_sparse_categorical_accuracy: 0.9430 - val_sparse_categorical_crossentropy: 0.1933 - lr: 0.0012\n",
      "Epoch 41/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0497 - sparse_categorical_accuracy: 0.9892 - sparse_categorical_crossentropy: 0.0497\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 10s 101ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9892 - sparse_categorical_crossentropy: 0.0497 - val_loss: 0.1941 - val_sparse_categorical_accuracy: 0.9435 - val_sparse_categorical_crossentropy: 0.1941 - lr: 0.0012\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 10s 101ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9892 - sparse_categorical_crossentropy: 0.0493 - val_loss: 0.1952 - val_sparse_categorical_accuracy: 0.9432 - val_sparse_categorical_crossentropy: 0.1952 - lr: 6.2500e-04\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 10s 102ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9904 - sparse_categorical_crossentropy: 0.0456 - val_loss: 0.1933 - val_sparse_categorical_accuracy: 0.9438 - val_sparse_categorical_crossentropy: 0.1933 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.1848 - sparse_categorical_accuracy: 0.9450 - sparse_categorical_crossentropy: 0.1848\n",
      "26/26 [==============================] - 3s 88ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 14s 116ms/step - loss: 1.4787 - sparse_categorical_accuracy: 0.6260 - sparse_categorical_crossentropy: 1.4787 - val_loss: 1.3098 - val_sparse_categorical_accuracy: 0.6326 - val_sparse_categorical_crossentropy: 1.3098 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 13s 128ms/step - loss: 1.0862 - sparse_categorical_accuracy: 0.6734 - sparse_categorical_crossentropy: 1.0862 - val_loss: 0.8656 - val_sparse_categorical_accuracy: 0.7233 - val_sparse_categorical_crossentropy: 0.8656 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.7706 - sparse_categorical_accuracy: 0.7587 - sparse_categorical_crossentropy: 0.7706 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.7854 - val_sparse_categorical_crossentropy: 0.6738 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 12s 127ms/step - loss: 0.6026 - sparse_categorical_accuracy: 0.8117 - sparse_categorical_crossentropy: 0.6026 - val_loss: 0.5408 - val_sparse_categorical_accuracy: 0.8268 - val_sparse_categorical_crossentropy: 0.5408 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.6981 - sparse_categorical_accuracy: 0.7887 - sparse_categorical_crossentropy: 0.6981 - val_loss: 0.9365 - val_sparse_categorical_accuracy: 0.7144 - val_sparse_categorical_crossentropy: 0.9365 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.8091 - sparse_categorical_accuracy: 0.7531 - sparse_categorical_crossentropy: 0.8091 - val_loss: 0.7413 - val_sparse_categorical_accuracy: 0.7702 - val_sparse_categorical_crossentropy: 0.7413 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.6901 - sparse_categorical_accuracy: 0.7849 - sparse_categorical_crossentropy: 0.6901\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.6901 - sparse_categorical_accuracy: 0.7849 - sparse_categorical_crossentropy: 0.6901 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.7904 - val_sparse_categorical_crossentropy: 0.6549 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.5995 - sparse_categorical_accuracy: 0.8126 - sparse_categorical_crossentropy: 0.5995 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.8038 - val_sparse_categorical_crossentropy: 0.5990 - lr: 0.0050\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 12s 128ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.8254 - sparse_categorical_crossentropy: 0.5540 - val_loss: 0.5330 - val_sparse_categorical_accuracy: 0.8348 - val_sparse_categorical_crossentropy: 0.5330 - lr: 0.0050\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 11s 108ms/step - loss: 0.5225 - sparse_categorical_accuracy: 0.8368 - sparse_categorical_crossentropy: 0.5225 - val_loss: 0.5188 - val_sparse_categorical_accuracy: 0.8353 - val_sparse_categorical_crossentropy: 0.5188 - lr: 0.0050\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 10s 105ms/step - loss: 0.4951 - sparse_categorical_accuracy: 0.8432 - sparse_categorical_crossentropy: 0.4951 - val_loss: 0.5155 - val_sparse_categorical_accuracy: 0.8368 - val_sparse_categorical_crossentropy: 0.5155 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 0.4718 - sparse_categorical_accuracy: 0.8523 - sparse_categorical_crossentropy: 0.4718 - val_loss: 0.4872 - val_sparse_categorical_accuracy: 0.8443 - val_sparse_categorical_crossentropy: 0.4872 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 11s 112ms/step - loss: 0.4678 - sparse_categorical_accuracy: 0.8530 - sparse_categorical_crossentropy: 0.4678 - val_loss: 0.4601 - val_sparse_categorical_accuracy: 0.8524 - val_sparse_categorical_crossentropy: 0.4601 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 11s 112ms/step - loss: 0.4400 - sparse_categorical_accuracy: 0.8598 - sparse_categorical_crossentropy: 0.4400 - val_loss: 0.4657 - val_sparse_categorical_accuracy: 0.8501 - val_sparse_categorical_crossentropy: 0.4657 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 0.4301 - sparse_categorical_accuracy: 0.8659 - sparse_categorical_crossentropy: 0.4301 - val_loss: 0.4348 - val_sparse_categorical_accuracy: 0.8634 - val_sparse_categorical_crossentropy: 0.4348 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 13s 128ms/step - loss: 0.4138 - sparse_categorical_accuracy: 0.8698 - sparse_categorical_crossentropy: 0.4138 - val_loss: 0.4386 - val_sparse_categorical_accuracy: 0.8632 - val_sparse_categorical_crossentropy: 0.4386 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 12s 127ms/step - loss: 0.4395 - sparse_categorical_accuracy: 0.8606 - sparse_categorical_crossentropy: 0.4395 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.8663 - val_sparse_categorical_crossentropy: 0.4320 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 12s 127ms/step - loss: 0.3964 - sparse_categorical_accuracy: 0.8757 - sparse_categorical_crossentropy: 0.3964 - val_loss: 0.4191 - val_sparse_categorical_accuracy: 0.8652 - val_sparse_categorical_crossentropy: 0.4191 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 13s 130ms/step - loss: 0.3888 - sparse_categorical_accuracy: 0.8786 - sparse_categorical_crossentropy: 0.3888 - val_loss: 0.3956 - val_sparse_categorical_accuracy: 0.8716 - val_sparse_categorical_crossentropy: 0.3956 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 13s 131ms/step - loss: 0.3659 - sparse_categorical_accuracy: 0.8849 - sparse_categorical_crossentropy: 0.3659 - val_loss: 0.3906 - val_sparse_categorical_accuracy: 0.8766 - val_sparse_categorical_crossentropy: 0.3906 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.3483 - sparse_categorical_accuracy: 0.8897 - sparse_categorical_crossentropy: 0.3483 - val_loss: 0.3950 - val_sparse_categorical_accuracy: 0.8772 - val_sparse_categorical_crossentropy: 0.3950 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 12s 128ms/step - loss: 0.3422 - sparse_categorical_accuracy: 0.8923 - sparse_categorical_crossentropy: 0.3422 - val_loss: 0.3981 - val_sparse_categorical_accuracy: 0.8764 - val_sparse_categorical_crossentropy: 0.3981 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.3352 - sparse_categorical_accuracy: 0.8948 - sparse_categorical_crossentropy: 0.3352 - val_loss: 0.3921 - val_sparse_categorical_accuracy: 0.8766 - val_sparse_categorical_crossentropy: 0.3921 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.3381 - sparse_categorical_accuracy: 0.8948 - sparse_categorical_crossentropy: 0.3381 - val_loss: 0.3745 - val_sparse_categorical_accuracy: 0.8782 - val_sparse_categorical_crossentropy: 0.3745 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.3201 - sparse_categorical_accuracy: 0.9003 - sparse_categorical_crossentropy: 0.3201 - val_loss: 0.3479 - val_sparse_categorical_accuracy: 0.8865 - val_sparse_categorical_crossentropy: 0.3479 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.3054 - sparse_categorical_accuracy: 0.9031 - sparse_categorical_crossentropy: 0.3054 - val_loss: 0.3470 - val_sparse_categorical_accuracy: 0.8875 - val_sparse_categorical_crossentropy: 0.3470 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.9067 - sparse_categorical_crossentropy: 0.2935 - val_loss: 0.3533 - val_sparse_categorical_accuracy: 0.8828 - val_sparse_categorical_crossentropy: 0.3533 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2963 - sparse_categorical_accuracy: 0.9067 - sparse_categorical_crossentropy: 0.2963 - val_loss: 0.3506 - val_sparse_categorical_accuracy: 0.8895 - val_sparse_categorical_crossentropy: 0.3506 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2758 - sparse_categorical_accuracy: 0.9134 - sparse_categorical_crossentropy: 0.2758 - val_loss: 0.3462 - val_sparse_categorical_accuracy: 0.8907 - val_sparse_categorical_crossentropy: 0.3462 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2716 - sparse_categorical_accuracy: 0.9148 - sparse_categorical_crossentropy: 0.2716 - val_loss: 0.3219 - val_sparse_categorical_accuracy: 0.8953 - val_sparse_categorical_crossentropy: 0.3219 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.2698 - sparse_categorical_accuracy: 0.9147 - sparse_categorical_crossentropy: 0.2698 - val_loss: 0.3390 - val_sparse_categorical_accuracy: 0.8888 - val_sparse_categorical_crossentropy: 0.3390 - lr: 0.0050\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2719 - sparse_categorical_accuracy: 0.9135 - sparse_categorical_crossentropy: 0.2719 - val_loss: 0.3464 - val_sparse_categorical_accuracy: 0.8890 - val_sparse_categorical_crossentropy: 0.3464 - lr: 0.0050\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.9138 - sparse_categorical_crossentropy: 0.2715 - val_loss: 0.3090 - val_sparse_categorical_accuracy: 0.9025 - val_sparse_categorical_crossentropy: 0.3090 - lr: 0.0050\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2623 - sparse_categorical_accuracy: 0.9167 - sparse_categorical_crossentropy: 0.2623 - val_loss: 0.3238 - val_sparse_categorical_accuracy: 0.8981 - val_sparse_categorical_crossentropy: 0.3238 - lr: 0.0050\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.2539 - sparse_categorical_accuracy: 0.9203 - sparse_categorical_crossentropy: 0.2539 - val_loss: 0.3085 - val_sparse_categorical_accuracy: 0.9005 - val_sparse_categorical_crossentropy: 0.3085 - lr: 0.0050\n",
      "Epoch 36/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2295 - sparse_categorical_accuracy: 0.9290 - sparse_categorical_crossentropy: 0.2295\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2295 - sparse_categorical_accuracy: 0.9290 - sparse_categorical_crossentropy: 0.2295 - val_loss: 0.3154 - val_sparse_categorical_accuracy: 0.9002 - val_sparse_categorical_crossentropy: 0.3154 - lr: 0.0050\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 12s 127ms/step - loss: 0.2055 - sparse_categorical_accuracy: 0.9375 - sparse_categorical_crossentropy: 0.2055 - val_loss: 0.2918 - val_sparse_categorical_accuracy: 0.9094 - val_sparse_categorical_crossentropy: 0.2918 - lr: 0.0025\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1935 - sparse_categorical_accuracy: 0.9406 - sparse_categorical_crossentropy: 0.1935 - val_loss: 0.2948 - val_sparse_categorical_accuracy: 0.9097 - val_sparse_categorical_crossentropy: 0.2948 - lr: 0.0025\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1962 - sparse_categorical_accuracy: 0.9398 - sparse_categorical_crossentropy: 0.1962 - val_loss: 0.2910 - val_sparse_categorical_accuracy: 0.9091 - val_sparse_categorical_crossentropy: 0.2910 - lr: 0.0025\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9407 - sparse_categorical_crossentropy: 0.1949 - val_loss: 0.2866 - val_sparse_categorical_accuracy: 0.9094 - val_sparse_categorical_crossentropy: 0.2866 - lr: 0.0025\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1770 - sparse_categorical_accuracy: 0.9468 - sparse_categorical_crossentropy: 0.1770 - val_loss: 0.2888 - val_sparse_categorical_accuracy: 0.9119 - val_sparse_categorical_crossentropy: 0.2888 - lr: 0.0025\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1735 - sparse_categorical_accuracy: 0.9471 - sparse_categorical_crossentropy: 0.1735 - val_loss: 0.2855 - val_sparse_categorical_accuracy: 0.9106 - val_sparse_categorical_crossentropy: 0.2855 - lr: 0.0025\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9504 - sparse_categorical_crossentropy: 0.1659 - val_loss: 0.2879 - val_sparse_categorical_accuracy: 0.9125 - val_sparse_categorical_crossentropy: 0.2879 - lr: 0.0025\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9515 - sparse_categorical_crossentropy: 0.1625 - val_loss: 0.2856 - val_sparse_categorical_accuracy: 0.9133 - val_sparse_categorical_crossentropy: 0.2856 - lr: 0.0025\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1627 - sparse_categorical_accuracy: 0.9514 - sparse_categorical_crossentropy: 0.1627 - val_loss: 0.2772 - val_sparse_categorical_accuracy: 0.9140 - val_sparse_categorical_crossentropy: 0.2772 - lr: 0.0025\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1520 - sparse_categorical_accuracy: 0.9554 - sparse_categorical_crossentropy: 0.1520 - val_loss: 0.2751 - val_sparse_categorical_accuracy: 0.9134 - val_sparse_categorical_crossentropy: 0.2751 - lr: 0.0025\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1668 - sparse_categorical_accuracy: 0.9498 - sparse_categorical_crossentropy: 0.1668 - val_loss: 0.3009 - val_sparse_categorical_accuracy: 0.9073 - val_sparse_categorical_crossentropy: 0.3009 - lr: 0.0025\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1597 - sparse_categorical_accuracy: 0.9524 - sparse_categorical_crossentropy: 0.1597\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1597 - sparse_categorical_accuracy: 0.9524 - sparse_categorical_crossentropy: 0.1597 - val_loss: 0.2811 - val_sparse_categorical_accuracy: 0.9133 - val_sparse_categorical_crossentropy: 0.2811 - lr: 0.0025\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1365 - sparse_categorical_accuracy: 0.9608 - sparse_categorical_crossentropy: 0.1365 - val_loss: 0.2770 - val_sparse_categorical_accuracy: 0.9134 - val_sparse_categorical_crossentropy: 0.2770 - lr: 0.0012\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9638 - sparse_categorical_crossentropy: 0.1291 - val_loss: 0.2719 - val_sparse_categorical_accuracy: 0.9180 - val_sparse_categorical_crossentropy: 0.2719 - lr: 0.0012\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 12s 127ms/step - loss: 0.1265 - sparse_categorical_accuracy: 0.9656 - sparse_categorical_crossentropy: 0.1265 - val_loss: 0.2727 - val_sparse_categorical_accuracy: 0.9145 - val_sparse_categorical_crossentropy: 0.2727 - lr: 0.0012\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9653 - sparse_categorical_crossentropy: 0.1255 - val_loss: 0.2733 - val_sparse_categorical_accuracy: 0.9157 - val_sparse_categorical_crossentropy: 0.2733 - lr: 0.0012\n",
      "Epoch 53/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1222 - sparse_categorical_accuracy: 0.9671 - sparse_categorical_crossentropy: 0.1222\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9671 - sparse_categorical_crossentropy: 0.1222 - val_loss: 0.2712 - val_sparse_categorical_accuracy: 0.9145 - val_sparse_categorical_crossentropy: 0.2712 - lr: 0.0012\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9695 - sparse_categorical_crossentropy: 0.1156 - val_loss: 0.2688 - val_sparse_categorical_accuracy: 0.9160 - val_sparse_categorical_crossentropy: 0.2688 - lr: 6.2500e-04\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1131 - sparse_categorical_accuracy: 0.9701 - sparse_categorical_crossentropy: 0.1131 - val_loss: 0.2689 - val_sparse_categorical_accuracy: 0.9149 - val_sparse_categorical_crossentropy: 0.2689 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 107ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.9155 - sparse_categorical_crossentropy: 0.2877\n",
      "26/26 [==============================] - 4s 106ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 15s 128ms/step - loss: 1.4603 - sparse_categorical_accuracy: 0.6252 - sparse_categorical_crossentropy: 1.4603 - val_loss: 1.3514 - val_sparse_categorical_accuracy: 0.6372 - val_sparse_categorical_crossentropy: 1.3514 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 1.1468 - sparse_categorical_accuracy: 0.6663 - sparse_categorical_crossentropy: 1.1468 - val_loss: 1.0461 - val_sparse_categorical_accuracy: 0.6717 - val_sparse_categorical_crossentropy: 1.0461 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.8531 - sparse_categorical_accuracy: 0.7360 - sparse_categorical_crossentropy: 0.8531 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.7869 - val_sparse_categorical_crossentropy: 0.6952 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.6636 - sparse_categorical_accuracy: 0.7911 - sparse_categorical_crossentropy: 0.6636 - val_loss: 0.5960 - val_sparse_categorical_accuracy: 0.8148 - val_sparse_categorical_crossentropy: 0.5960 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 0.5491 - sparse_categorical_accuracy: 0.8308 - sparse_categorical_crossentropy: 0.5491 - val_loss: 0.4757 - val_sparse_categorical_accuracy: 0.8529 - val_sparse_categorical_crossentropy: 0.4757 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 13s 130ms/step - loss: 0.4332 - sparse_categorical_accuracy: 0.8668 - sparse_categorical_crossentropy: 0.4332 - val_loss: 0.4640 - val_sparse_categorical_accuracy: 0.8554 - val_sparse_categorical_crossentropy: 0.4640 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 0.4026 - sparse_categorical_accuracy: 0.8756 - sparse_categorical_crossentropy: 0.4026 - val_loss: 0.3701 - val_sparse_categorical_accuracy: 0.8864 - val_sparse_categorical_crossentropy: 0.3701 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 0.3521 - sparse_categorical_accuracy: 0.8916 - sparse_categorical_crossentropy: 0.3521 - val_loss: 0.3233 - val_sparse_categorical_accuracy: 0.8988 - val_sparse_categorical_crossentropy: 0.3233 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.3041 - sparse_categorical_accuracy: 0.9058 - sparse_categorical_crossentropy: 0.3041 - val_loss: 0.3210 - val_sparse_categorical_accuracy: 0.8979 - val_sparse_categorical_crossentropy: 0.3210 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 12s 129ms/step - loss: 0.3088 - sparse_categorical_accuracy: 0.9036 - sparse_categorical_crossentropy: 0.3088 - val_loss: 0.3293 - val_sparse_categorical_accuracy: 0.8971 - val_sparse_categorical_crossentropy: 0.3293 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 0.2812 - sparse_categorical_accuracy: 0.9125 - sparse_categorical_crossentropy: 0.2812 - val_loss: 0.3146 - val_sparse_categorical_accuracy: 0.9014 - val_sparse_categorical_crossentropy: 0.3146 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.3231 - sparse_categorical_accuracy: 0.8986 - sparse_categorical_crossentropy: 0.3231 - val_loss: 0.2709 - val_sparse_categorical_accuracy: 0.9172 - val_sparse_categorical_crossentropy: 0.2709 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.2500 - sparse_categorical_accuracy: 0.9221 - sparse_categorical_crossentropy: 0.2500 - val_loss: 0.2532 - val_sparse_categorical_accuracy: 0.9234 - val_sparse_categorical_crossentropy: 0.2532 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2511 - sparse_categorical_accuracy: 0.9223 - sparse_categorical_crossentropy: 0.2511 - val_loss: 0.2644 - val_sparse_categorical_accuracy: 0.9197 - val_sparse_categorical_crossentropy: 0.2644 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.2520 - sparse_categorical_accuracy: 0.9217 - sparse_categorical_crossentropy: 0.2520 - val_loss: 0.2463 - val_sparse_categorical_accuracy: 0.9218 - val_sparse_categorical_crossentropy: 0.2463 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2198 - sparse_categorical_accuracy: 0.9312 - sparse_categorical_crossentropy: 0.2198\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.2198 - sparse_categorical_accuracy: 0.9312 - sparse_categorical_crossentropy: 0.2198 - val_loss: 0.2447 - val_sparse_categorical_accuracy: 0.9218 - val_sparse_categorical_crossentropy: 0.2447 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.1861 - sparse_categorical_accuracy: 0.9419 - sparse_categorical_crossentropy: 0.1861 - val_loss: 0.2124 - val_sparse_categorical_accuracy: 0.9337 - val_sparse_categorical_crossentropy: 0.2124 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9480 - sparse_categorical_crossentropy: 0.1676 - val_loss: 0.2140 - val_sparse_categorical_accuracy: 0.9343 - val_sparse_categorical_crossentropy: 0.2140 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9445 - sparse_categorical_crossentropy: 0.1779 - val_loss: 0.1951 - val_sparse_categorical_accuracy: 0.9377 - val_sparse_categorical_crossentropy: 0.1951 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1413 - sparse_categorical_accuracy: 0.9566 - sparse_categorical_crossentropy: 0.1413 - val_loss: 0.1913 - val_sparse_categorical_accuracy: 0.9447 - val_sparse_categorical_crossentropy: 0.1913 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1327 - sparse_categorical_accuracy: 0.9592 - sparse_categorical_crossentropy: 0.1327 - val_loss: 0.1886 - val_sparse_categorical_accuracy: 0.9443 - val_sparse_categorical_crossentropy: 0.1886 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.1218 - sparse_categorical_accuracy: 0.9622 - sparse_categorical_crossentropy: 0.1218 - val_loss: 0.1752 - val_sparse_categorical_accuracy: 0.9464 - val_sparse_categorical_crossentropy: 0.1752 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.1146 - sparse_categorical_accuracy: 0.9648 - sparse_categorical_crossentropy: 0.1146 - val_loss: 0.1824 - val_sparse_categorical_accuracy: 0.9441 - val_sparse_categorical_crossentropy: 0.1824 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.1114 - sparse_categorical_accuracy: 0.9658 - sparse_categorical_crossentropy: 0.1114 - val_loss: 0.1869 - val_sparse_categorical_accuracy: 0.9430 - val_sparse_categorical_crossentropy: 0.1869 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1108 - sparse_categorical_accuracy: 0.9660 - sparse_categorical_crossentropy: 0.1108\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9660 - sparse_categorical_crossentropy: 0.1108 - val_loss: 0.1812 - val_sparse_categorical_accuracy: 0.9449 - val_sparse_categorical_crossentropy: 0.1812 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9757 - sparse_categorical_crossentropy: 0.0869 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9499 - val_sparse_categorical_crossentropy: 0.1684 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9785 - sparse_categorical_crossentropy: 0.0792 - val_loss: 0.1622 - val_sparse_categorical_accuracy: 0.9522 - val_sparse_categorical_crossentropy: 0.1622 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9813 - sparse_categorical_crossentropy: 0.0718 - val_loss: 0.1691 - val_sparse_categorical_accuracy: 0.9496 - val_sparse_categorical_crossentropy: 0.1691 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9770 - sparse_categorical_crossentropy: 0.0806 - val_loss: 0.1680 - val_sparse_categorical_accuracy: 0.9503 - val_sparse_categorical_crossentropy: 0.1680 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0661 - sparse_categorical_accuracy: 0.9830 - sparse_categorical_crossentropy: 0.0661\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9830 - sparse_categorical_crossentropy: 0.0660 - val_loss: 0.1657 - val_sparse_categorical_accuracy: 0.9518 - val_sparse_categorical_crossentropy: 0.1657 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.0563 - sparse_categorical_accuracy: 0.9864 - sparse_categorical_crossentropy: 0.0563 - val_loss: 0.1629 - val_sparse_categorical_accuracy: 0.9533 - val_sparse_categorical_crossentropy: 0.1629 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.0572 - sparse_categorical_accuracy: 0.9857 - sparse_categorical_crossentropy: 0.0572 - val_loss: 0.1605 - val_sparse_categorical_accuracy: 0.9524 - val_sparse_categorical_crossentropy: 0.1605 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9886 - sparse_categorical_crossentropy: 0.0510 - val_loss: 0.1628 - val_sparse_categorical_accuracy: 0.9527 - val_sparse_categorical_crossentropy: 0.1628 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0484 - sparse_categorical_accuracy: 0.9895 - sparse_categorical_crossentropy: 0.0484\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.0484 - sparse_categorical_accuracy: 0.9895 - sparse_categorical_crossentropy: 0.0484 - val_loss: 0.1645 - val_sparse_categorical_accuracy: 0.9527 - val_sparse_categorical_crossentropy: 0.1645 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9905 - sparse_categorical_crossentropy: 0.0451 - val_loss: 0.1623 - val_sparse_categorical_accuracy: 0.9524 - val_sparse_categorical_crossentropy: 0.1623 - lr: 6.2500e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9909 - sparse_categorical_crossentropy: 0.0442 - val_loss: 0.1647 - val_sparse_categorical_accuracy: 0.9518 - val_sparse_categorical_crossentropy: 0.1647 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 105ms/step - loss: 0.1852 - sparse_categorical_accuracy: 0.9466 - sparse_categorical_crossentropy: 0.1852\n",
      "26/26 [==============================] - 3s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(5))\n",
    "results = []\n",
    "for seed in TRAINING_SEEDS:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    model = CNN_LSTM(N_CLASS, 16000, 5)\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "        loss=losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(EXPERIMENT_NAME, f\"history_{seed}.pkl\"), \"wb\") as file:\n",
    "        pickle.dump(history.history, file)\n",
    "\n",
    "    eval_results = model.evaluate(test_ds)\n",
    "\n",
    "    predictions = model.predict(test_ds)\n",
    "    with open(os.path.join(EXPERIMENT_NAME, f\"predictions_{seed}.pkl\"), \"wb\") as file:\n",
    "        pickle.dump(predictions, file)\n",
    "\n",
    "    results += [{\n",
    "        'seed': seed,\n",
    "        'results': dict(zip(model.metrics_names, eval_results))\n",
    "    }]\n",
    "    gc.collect()\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results = pd.concat([results.drop([\"results\"], axis=1), results[\"results\"].apply(pd.Series)], axis=1)\n",
    "results.to_csv(os.path.join(EXPERIMENT_NAME, 'results.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:11:39.666752Z",
     "end_time": "2023-04-23T15:50:43.865334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T15:50:43.866334Z",
     "end_time": "2023-04-23T15:50:43.881334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   seed      loss  sparse_categorical_accuracy  \\\n0     0  0.202165                     0.942107   \n1     1  0.202767                     0.942644   \n2     2  0.184794                     0.945025   \n3     3  0.287714                     0.915464   \n4     4  0.185222                     0.946560   \n\n   sparse_categorical_crossentropy  \n0                         0.202165  \n1                         0.202767  \n2                         0.184794  \n3                         0.287714  \n4                         0.185222  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed</th>\n      <th>loss</th>\n      <th>sparse_categorical_accuracy</th>\n      <th>sparse_categorical_crossentropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.202165</td>\n      <td>0.942107</td>\n      <td>0.202165</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.202767</td>\n      <td>0.942644</td>\n      <td>0.202767</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.184794</td>\n      <td>0.945025</td>\n      <td>0.184794</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.287714</td>\n      <td>0.915464</td>\n      <td>0.287714</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.185222</td>\n      <td>0.946560</td>\n      <td>0.185222</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
