{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:15.510476Z",
     "end_time": "2023-04-23T02:52:15.529478Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import losses, optimizers, metrics, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:15.529478Z",
     "end_time": "2023-04-23T02:52:15.562477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:15.542476Z",
     "end_time": "2023-04-23T02:52:15.563477Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 12\n",
    "MAX_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:15.560476Z",
     "end_time": "2023-04-23T02:52:15.574476Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45586 files belonging to 12 classes.\n",
      "Found 6513 files belonging to 12 classes.\n",
      "Found 13024 files belonging to 12 classes.\n",
      "label names: ['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/train\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/val\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/test\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000)\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print(\"label names:\", label_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:15.574476Z",
     "end_time": "2023-04-23T02:52:21.285046Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(squeeze, tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:21.286046Z",
     "end_time": "2023-04-23T02:52:21.335045Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + LSTM Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " tf.signal.stft (TFOpLambda)    (None, 125, 513)     0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.abs (TFOpLambda)       (None, 125, 513)     0           ['tf.signal.stft[0][0]']         \n",
      "                                                                                                  \n",
      " tf.tensordot (TFOpLambda)      (None, 125, 80)      0           ['tf.math.abs[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 125, 80)     0           ['tf.tensordot[0][0]']           \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.log (TFOpLambda)       (None, 125, 80)      0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.math.log[0][0]']            \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 125, 80)      0           ['tf.math.log[0][0]',            \n",
      "                                                                  'tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.reduce_std (TFOpLambda  ()                  0           ['tf.math.log[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 125, 80)      0           ['tf.math.subtract[0][0]',       \n",
      "                                                                  'tf.math.reduce_std[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 125, 32)      12832       ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 256)          164864      ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 12)           3084        ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,780\n",
      "Trainable params: 180,780\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from SpeechModels import get_melspec_model\n",
    "import tensorflow.keras.layers as L\n",
    "from keras.models import Model\n",
    "\n",
    "def CNN_LSTM(n_out, input_length, kernel_size):\n",
    "\n",
    "    mel_spec_model = get_melspec_model(input_length)\n",
    "    inputs, outputs = mel_spec_model.inputs, mel_spec_model.outputs\n",
    "    o_shape = outputs[0].shape\n",
    "    y1 = L.Conv1D(32, kernel_size, activation='relu', padding='same', input_shape=o_shape[1:])(outputs[0])\n",
    "\n",
    "    x = L.Bidirectional(L.LSTM(128, return_sequences=False))(y1)  # [b_s, seq_len, vec_dim]\n",
    "\n",
    "    output = L.Dense(n_out, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = CNN_LSTM(N_CLASS, 16000, 5)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:21.337046Z",
     "end_time": "2023-04-23T02:52:22.488262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:22.462215Z",
     "end_time": "2023-04-23T02:52:22.495263Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    ")\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath=\"simple_cnn.h5\",\n",
    "    monitor=\"val_sparse_categorical_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=3, min_lr=0.00001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:22.491263Z",
     "end_time": "2023-04-23T02:52:56.775656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "90/90 [==============================] - 21s 113ms/step - loss: 1.4907 - sparse_categorical_accuracy: 0.6263 - sparse_categorical_crossentropy: 1.4907 - val_loss: 1.4373 - val_sparse_categorical_accuracy: 0.6258 - val_sparse_categorical_crossentropy: 1.4373 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 13s 132ms/step - loss: 1.2017 - sparse_categorical_accuracy: 0.6498 - sparse_categorical_crossentropy: 1.2017 - val_loss: 1.0147 - val_sparse_categorical_accuracy: 0.6754 - val_sparse_categorical_crossentropy: 1.0147 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=2,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Training will be repeated 5 times with different weights initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"cnn_lstm_simple\"\n",
    "if os.path.exists(EXPERIMENT_NAME):\n",
    "    shutil.rmtree(EXPERIMENT_NAME)\n",
    "    os.mkdir(EXPERIMENT_NAME)\n",
    "else:\n",
    "    os.mkdir(EXPERIMENT_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:56.779656Z",
     "end_time": "2023-04-23T02:52:56.805668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 16s 137ms/step - loss: 1.4761 - sparse_categorical_accuracy: 0.6255 - sparse_categorical_crossentropy: 1.4761 - val_loss: 1.3038 - val_sparse_categorical_accuracy: 0.6412 - val_sparse_categorical_crossentropy: 1.3038 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 13s 137ms/step - loss: 1.0846 - sparse_categorical_accuracy: 0.6791 - sparse_categorical_crossentropy: 1.0846 - val_loss: 0.8415 - val_sparse_categorical_accuracy: 0.7335 - val_sparse_categorical_crossentropy: 0.8415 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.7086 - sparse_categorical_accuracy: 0.7771 - sparse_categorical_crossentropy: 0.7086 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.7866 - val_sparse_categorical_crossentropy: 0.6487 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 13s 136ms/step - loss: 0.5677 - sparse_categorical_accuracy: 0.8238 - sparse_categorical_crossentropy: 0.5677 - val_loss: 0.6337 - val_sparse_categorical_accuracy: 0.8018 - val_sparse_categorical_crossentropy: 0.6337 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.4889 - sparse_categorical_accuracy: 0.8494 - sparse_categorical_crossentropy: 0.4889 - val_loss: 0.5138 - val_sparse_categorical_accuracy: 0.8326 - val_sparse_categorical_crossentropy: 0.5138 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.4296 - sparse_categorical_accuracy: 0.8677 - sparse_categorical_crossentropy: 0.4296 - val_loss: 0.3695 - val_sparse_categorical_accuracy: 0.8805 - val_sparse_categorical_crossentropy: 0.3695 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.3603 - sparse_categorical_accuracy: 0.8910 - sparse_categorical_crossentropy: 0.3603 - val_loss: 0.3705 - val_sparse_categorical_accuracy: 0.8841 - val_sparse_categorical_crossentropy: 0.3705 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.3489 - sparse_categorical_accuracy: 0.8921 - sparse_categorical_crossentropy: 0.3489 - val_loss: 0.4321 - val_sparse_categorical_accuracy: 0.8676 - val_sparse_categorical_crossentropy: 0.4321 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 13s 137ms/step - loss: 0.3636 - sparse_categorical_accuracy: 0.8878 - sparse_categorical_crossentropy: 0.3636 - val_loss: 0.2979 - val_sparse_categorical_accuracy: 0.9071 - val_sparse_categorical_crossentropy: 0.2979 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.3210 - sparse_categorical_accuracy: 0.9031 - sparse_categorical_crossentropy: 0.3210 - val_loss: 0.2992 - val_sparse_categorical_accuracy: 0.9100 - val_sparse_categorical_crossentropy: 0.2992 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.3069 - sparse_categorical_accuracy: 0.9056 - sparse_categorical_crossentropy: 0.3069 - val_loss: 0.3224 - val_sparse_categorical_accuracy: 0.9056 - val_sparse_categorical_crossentropy: 0.3224 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.9156 - sparse_categorical_crossentropy: 0.2759 - val_loss: 0.2847 - val_sparse_categorical_accuracy: 0.9085 - val_sparse_categorical_crossentropy: 0.2847 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.2858 - sparse_categorical_accuracy: 0.9128 - sparse_categorical_crossentropy: 0.2858 - val_loss: 0.2884 - val_sparse_categorical_accuracy: 0.9116 - val_sparse_categorical_crossentropy: 0.2884 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.2464 - sparse_categorical_accuracy: 0.9239 - sparse_categorical_crossentropy: 0.2464 - val_loss: 0.2869 - val_sparse_categorical_accuracy: 0.9133 - val_sparse_categorical_crossentropy: 0.2869 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.9258 - sparse_categorical_crossentropy: 0.2389 - val_loss: 0.3783 - val_sparse_categorical_accuracy: 0.8864 - val_sparse_categorical_crossentropy: 0.3783 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.2827 - sparse_categorical_accuracy: 0.9117 - sparse_categorical_crossentropy: 0.2827 - val_loss: 0.2829 - val_sparse_categorical_accuracy: 0.9094 - val_sparse_categorical_crossentropy: 0.2829 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2513 - sparse_categorical_accuracy: 0.9223 - sparse_categorical_crossentropy: 0.2513\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.9223 - sparse_categorical_crossentropy: 0.2513 - val_loss: 0.3298 - val_sparse_categorical_accuracy: 0.8997 - val_sparse_categorical_crossentropy: 0.3298 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.1995 - sparse_categorical_accuracy: 0.9383 - sparse_categorical_crossentropy: 0.1995 - val_loss: 0.2255 - val_sparse_categorical_accuracy: 0.9312 - val_sparse_categorical_crossentropy: 0.2255 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.1762 - sparse_categorical_accuracy: 0.9453 - sparse_categorical_crossentropy: 0.1762 - val_loss: 0.2120 - val_sparse_categorical_accuracy: 0.9346 - val_sparse_categorical_crossentropy: 0.2120 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1603 - sparse_categorical_accuracy: 0.9507 - sparse_categorical_crossentropy: 0.1603 - val_loss: 0.2063 - val_sparse_categorical_accuracy: 0.9369 - val_sparse_categorical_crossentropy: 0.2063 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.1527 - sparse_categorical_accuracy: 0.9531 - sparse_categorical_crossentropy: 0.1527 - val_loss: 0.2083 - val_sparse_categorical_accuracy: 0.9354 - val_sparse_categorical_crossentropy: 0.2083 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9549 - sparse_categorical_crossentropy: 0.1486 - val_loss: 0.2049 - val_sparse_categorical_accuracy: 0.9361 - val_sparse_categorical_crossentropy: 0.2049 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.1500 - sparse_categorical_accuracy: 0.9533 - sparse_categorical_crossentropy: 0.1500 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9380 - val_sparse_categorical_crossentropy: 0.2099 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.1678 - sparse_categorical_accuracy: 0.9473 - sparse_categorical_crossentropy: 0.1678 - val_loss: 0.2028 - val_sparse_categorical_accuracy: 0.9384 - val_sparse_categorical_crossentropy: 0.2028 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.1294 - sparse_categorical_accuracy: 0.9606 - sparse_categorical_crossentropy: 0.1294 - val_loss: 0.1863 - val_sparse_categorical_accuracy: 0.9449 - val_sparse_categorical_crossentropy: 0.1863 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.1228 - sparse_categorical_accuracy: 0.9631 - sparse_categorical_crossentropy: 0.1228 - val_loss: 0.1970 - val_sparse_categorical_accuracy: 0.9398 - val_sparse_categorical_crossentropy: 0.1970 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9642 - sparse_categorical_crossentropy: 0.1177 - val_loss: 0.1918 - val_sparse_categorical_accuracy: 0.9435 - val_sparse_categorical_crossentropy: 0.1918 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1119 - sparse_categorical_accuracy: 0.9667 - sparse_categorical_crossentropy: 0.1119\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.1119 - sparse_categorical_accuracy: 0.9667 - sparse_categorical_crossentropy: 0.1119 - val_loss: 0.1854 - val_sparse_categorical_accuracy: 0.9417 - val_sparse_categorical_crossentropy: 0.1854 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.0936 - sparse_categorical_accuracy: 0.9728 - sparse_categorical_crossentropy: 0.0936 - val_loss: 0.1879 - val_sparse_categorical_accuracy: 0.9444 - val_sparse_categorical_crossentropy: 0.1879 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9749 - sparse_categorical_crossentropy: 0.0865 - val_loss: 0.1840 - val_sparse_categorical_accuracy: 0.9472 - val_sparse_categorical_crossentropy: 0.1840 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.0761 - sparse_categorical_accuracy: 0.9792 - sparse_categorical_crossentropy: 0.0761 - val_loss: 0.1898 - val_sparse_categorical_accuracy: 0.9426 - val_sparse_categorical_crossentropy: 0.1898 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9764 - sparse_categorical_crossentropy: 0.0813 - val_loss: 0.1831 - val_sparse_categorical_accuracy: 0.9473 - val_sparse_categorical_crossentropy: 0.1831 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9812 - sparse_categorical_crossentropy: 0.0695 - val_loss: 0.1869 - val_sparse_categorical_accuracy: 0.9423 - val_sparse_categorical_crossentropy: 0.1869 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9811 - sparse_categorical_crossentropy: 0.0677 - val_loss: 0.1873 - val_sparse_categorical_accuracy: 0.9466 - val_sparse_categorical_crossentropy: 0.1873 - lr: 0.0025\n",
      "Epoch 35/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0614 - sparse_categorical_accuracy: 0.9841 - sparse_categorical_crossentropy: 0.0614\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9841 - sparse_categorical_crossentropy: 0.0614 - val_loss: 0.1887 - val_sparse_categorical_accuracy: 0.9460 - val_sparse_categorical_crossentropy: 0.1887 - lr: 0.0025\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9873 - sparse_categorical_crossentropy: 0.0532 - val_loss: 0.1807 - val_sparse_categorical_accuracy: 0.9498 - val_sparse_categorical_crossentropy: 0.1807 - lr: 0.0012\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.0499 - sparse_categorical_accuracy: 0.9885 - sparse_categorical_crossentropy: 0.0499 - val_loss: 0.1824 - val_sparse_categorical_accuracy: 0.9478 - val_sparse_categorical_crossentropy: 0.1824 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9893 - sparse_categorical_crossentropy: 0.0483 - val_loss: 0.1826 - val_sparse_categorical_accuracy: 0.9487 - val_sparse_categorical_crossentropy: 0.1826 - lr: 0.0012\n",
      "Epoch 39/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0484 - sparse_categorical_accuracy: 0.9889 - sparse_categorical_crossentropy: 0.0484\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.0484 - sparse_categorical_accuracy: 0.9889 - sparse_categorical_crossentropy: 0.0484 - val_loss: 0.1831 - val_sparse_categorical_accuracy: 0.9490 - val_sparse_categorical_crossentropy: 0.1831 - lr: 0.0012\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9905 - sparse_categorical_crossentropy: 0.0443 - val_loss: 0.1813 - val_sparse_categorical_accuracy: 0.9476 - val_sparse_categorical_crossentropy: 0.1813 - lr: 6.2500e-04\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0423 - sparse_categorical_accuracy: 0.9914 - sparse_categorical_crossentropy: 0.0423 - val_loss: 0.1842 - val_sparse_categorical_accuracy: 0.9484 - val_sparse_categorical_crossentropy: 0.1842 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 4s 96ms/step - loss: 0.1841 - sparse_categorical_accuracy: 0.9468 - sparse_categorical_crossentropy: 0.1841\n",
      "26/26 [==============================] - 4s 92ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 17s 148ms/step - loss: 1.4570 - sparse_categorical_accuracy: 0.6258 - sparse_categorical_crossentropy: 1.4570 - val_loss: 1.2861 - val_sparse_categorical_accuracy: 0.6442 - val_sparse_categorical_crossentropy: 1.2861 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 1.0989 - sparse_categorical_accuracy: 0.6699 - sparse_categorical_crossentropy: 1.0989 - val_loss: 0.8572 - val_sparse_categorical_accuracy: 0.7210 - val_sparse_categorical_crossentropy: 0.8572 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 0.7311 - sparse_categorical_accuracy: 0.7714 - sparse_categorical_crossentropy: 0.7311 - val_loss: 0.6071 - val_sparse_categorical_accuracy: 0.8053 - val_sparse_categorical_crossentropy: 0.6071 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 0.5648 - sparse_categorical_accuracy: 0.8216 - sparse_categorical_crossentropy: 0.5648 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.8177 - val_sparse_categorical_crossentropy: 0.5850 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.5031 - sparse_categorical_accuracy: 0.8425 - sparse_categorical_crossentropy: 0.5031 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.8133 - val_sparse_categorical_crossentropy: 0.6001 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.5148 - sparse_categorical_accuracy: 0.8405 - sparse_categorical_crossentropy: 0.5148 - val_loss: 0.4077 - val_sparse_categorical_accuracy: 0.8703 - val_sparse_categorical_crossentropy: 0.4077 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 14s 145ms/step - loss: 0.3816 - sparse_categorical_accuracy: 0.8826 - sparse_categorical_crossentropy: 0.3816 - val_loss: 0.3905 - val_sparse_categorical_accuracy: 0.8805 - val_sparse_categorical_crossentropy: 0.3905 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.8863 - sparse_categorical_crossentropy: 0.3728 - val_loss: 0.3431 - val_sparse_categorical_accuracy: 0.8945 - val_sparse_categorical_crossentropy: 0.3431 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 0.3472 - sparse_categorical_accuracy: 0.8931 - sparse_categorical_crossentropy: 0.3472 - val_loss: 0.3327 - val_sparse_categorical_accuracy: 0.8981 - val_sparse_categorical_crossentropy: 0.3327 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 0.3326 - sparse_categorical_accuracy: 0.8958 - sparse_categorical_crossentropy: 0.3326 - val_loss: 0.3226 - val_sparse_categorical_accuracy: 0.8991 - val_sparse_categorical_crossentropy: 0.3226 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 0.3221 - sparse_categorical_accuracy: 0.9001 - sparse_categorical_crossentropy: 0.3221 - val_loss: 0.3615 - val_sparse_categorical_accuracy: 0.8881 - val_sparse_categorical_crossentropy: 0.3615 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 14s 148ms/step - loss: 0.3319 - sparse_categorical_accuracy: 0.8977 - sparse_categorical_crossentropy: 0.3319 - val_loss: 0.2846 - val_sparse_categorical_accuracy: 0.9114 - val_sparse_categorical_crossentropy: 0.2846 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2821 - sparse_categorical_accuracy: 0.9148 - sparse_categorical_crossentropy: 0.2821 - val_loss: 0.3129 - val_sparse_categorical_accuracy: 0.9017 - val_sparse_categorical_crossentropy: 0.3129 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 14s 145ms/step - loss: 0.2720 - sparse_categorical_accuracy: 0.9152 - sparse_categorical_crossentropy: 0.2720 - val_loss: 0.2509 - val_sparse_categorical_accuracy: 0.9202 - val_sparse_categorical_crossentropy: 0.2509 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2656 - sparse_categorical_accuracy: 0.9160 - sparse_categorical_crossentropy: 0.2656 - val_loss: 0.2983 - val_sparse_categorical_accuracy: 0.9119 - val_sparse_categorical_crossentropy: 0.2983 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 14s 145ms/step - loss: 0.2476 - sparse_categorical_accuracy: 0.9232 - sparse_categorical_crossentropy: 0.2476 - val_loss: 0.2497 - val_sparse_categorical_accuracy: 0.9225 - val_sparse_categorical_crossentropy: 0.2497 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2429 - sparse_categorical_accuracy: 0.9242 - sparse_categorical_crossentropy: 0.2429 - val_loss: 0.2683 - val_sparse_categorical_accuracy: 0.9166 - val_sparse_categorical_crossentropy: 0.2683 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 14s 145ms/step - loss: 0.2308 - sparse_categorical_accuracy: 0.9274 - sparse_categorical_crossentropy: 0.2308 - val_loss: 0.2572 - val_sparse_categorical_accuracy: 0.9220 - val_sparse_categorical_crossentropy: 0.2572 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2324 - sparse_categorical_accuracy: 0.9265 - sparse_categorical_crossentropy: 0.2324 - val_loss: 0.2451 - val_sparse_categorical_accuracy: 0.9252 - val_sparse_categorical_crossentropy: 0.2451 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2172 - sparse_categorical_accuracy: 0.9325 - sparse_categorical_crossentropy: 0.2172 - val_loss: 0.3480 - val_sparse_categorical_accuracy: 0.8951 - val_sparse_categorical_crossentropy: 0.3480 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2791 - sparse_categorical_accuracy: 0.9133 - sparse_categorical_crossentropy: 0.2791 - val_loss: 0.3069 - val_sparse_categorical_accuracy: 0.9113 - val_sparse_categorical_crossentropy: 0.3069 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2782 - sparse_categorical_accuracy: 0.9141 - sparse_categorical_crossentropy: 0.2782 - val_loss: 0.2447 - val_sparse_categorical_accuracy: 0.9255 - val_sparse_categorical_crossentropy: 0.2447 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 14s 147ms/step - loss: 0.2159 - sparse_categorical_accuracy: 0.9330 - sparse_categorical_crossentropy: 0.2159 - val_loss: 0.3200 - val_sparse_categorical_accuracy: 0.8985 - val_sparse_categorical_crossentropy: 0.3200 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.3094 - sparse_categorical_accuracy: 0.9040 - sparse_categorical_crossentropy: 0.3094 - val_loss: 0.2594 - val_sparse_categorical_accuracy: 0.9188 - val_sparse_categorical_crossentropy: 0.2594 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 14s 147ms/step - loss: 0.2491 - sparse_categorical_accuracy: 0.9211 - sparse_categorical_crossentropy: 0.2491 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9263 - val_sparse_categorical_crossentropy: 0.2363 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 14s 145ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9293 - sparse_categorical_crossentropy: 0.2238 - val_loss: 0.2766 - val_sparse_categorical_accuracy: 0.9120 - val_sparse_categorical_crossentropy: 0.2766 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.1939 - sparse_categorical_accuracy: 0.9387 - sparse_categorical_crossentropy: 0.1939 - val_loss: 0.2303 - val_sparse_categorical_accuracy: 0.9306 - val_sparse_categorical_crossentropy: 0.2303 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2043 - sparse_categorical_accuracy: 0.9363 - sparse_categorical_crossentropy: 0.2043 - val_loss: 0.2644 - val_sparse_categorical_accuracy: 0.9211 - val_sparse_categorical_crossentropy: 0.2644 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 14s 147ms/step - loss: 0.1937 - sparse_categorical_accuracy: 0.9407 - sparse_categorical_crossentropy: 0.1937 - val_loss: 0.2416 - val_sparse_categorical_accuracy: 0.9280 - val_sparse_categorical_crossentropy: 0.2416 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.1868 - sparse_categorical_accuracy: 0.9420 - sparse_categorical_crossentropy: 0.1868 - val_loss: 0.2174 - val_sparse_categorical_accuracy: 0.9347 - val_sparse_categorical_crossentropy: 0.2174 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.1880 - sparse_categorical_accuracy: 0.9417 - sparse_categorical_crossentropy: 0.1880 - val_loss: 0.2190 - val_sparse_categorical_accuracy: 0.9352 - val_sparse_categorical_crossentropy: 0.2190 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.1747 - sparse_categorical_accuracy: 0.9447 - sparse_categorical_crossentropy: 0.1747 - val_loss: 0.2532 - val_sparse_categorical_accuracy: 0.9225 - val_sparse_categorical_crossentropy: 0.2532 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 14s 148ms/step - loss: 0.2926 - sparse_categorical_accuracy: 0.9073 - sparse_categorical_crossentropy: 0.2926 - val_loss: 0.2822 - val_sparse_categorical_accuracy: 0.9126 - val_sparse_categorical_crossentropy: 0.2822 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2740 - sparse_categorical_accuracy: 0.9119 - sparse_categorical_crossentropy: 0.2740\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.2739 - sparse_categorical_accuracy: 0.9119 - sparse_categorical_crossentropy: 0.2739 - val_loss: 0.2971 - val_sparse_categorical_accuracy: 0.9082 - val_sparse_categorical_crossentropy: 0.2971 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 14s 148ms/step - loss: 0.2018 - sparse_categorical_accuracy: 0.9349 - sparse_categorical_crossentropy: 0.2018 - val_loss: 0.2242 - val_sparse_categorical_accuracy: 0.9338 - val_sparse_categorical_crossentropy: 0.2242 - lr: 0.0050\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.1699 - sparse_categorical_accuracy: 0.9457 - sparse_categorical_crossentropy: 0.1699 - val_loss: 0.2249 - val_sparse_categorical_accuracy: 0.9311 - val_sparse_categorical_crossentropy: 0.2249 - lr: 0.0050\n",
      "26/26 [==============================] - 4s 97ms/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9315 - sparse_categorical_crossentropy: 0.2343\n",
      "26/26 [==============================] - 4s 96ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 17s 152ms/step - loss: 1.4775 - sparse_categorical_accuracy: 0.6253 - sparse_categorical_crossentropy: 1.4775 - val_loss: 1.3072 - val_sparse_categorical_accuracy: 0.6357 - val_sparse_categorical_crossentropy: 1.3072 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 1.1136 - sparse_categorical_accuracy: 0.6676 - sparse_categorical_crossentropy: 1.1136 - val_loss: 0.8597 - val_sparse_categorical_accuracy: 0.7362 - val_sparse_categorical_crossentropy: 0.8597 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.7547 - sparse_categorical_accuracy: 0.7641 - sparse_categorical_crossentropy: 0.7547 - val_loss: 0.6647 - val_sparse_categorical_accuracy: 0.7880 - val_sparse_categorical_crossentropy: 0.6647 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 15s 151ms/step - loss: 0.6251 - sparse_categorical_accuracy: 0.8036 - sparse_categorical_crossentropy: 0.6251 - val_loss: 0.5752 - val_sparse_categorical_accuracy: 0.8196 - val_sparse_categorical_crossentropy: 0.5752 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 15s 151ms/step - loss: 0.6249 - sparse_categorical_accuracy: 0.8049 - sparse_categorical_crossentropy: 0.6249 - val_loss: 0.5437 - val_sparse_categorical_accuracy: 0.8257 - val_sparse_categorical_crossentropy: 0.5437 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.5817 - sparse_categorical_accuracy: 0.8201 - sparse_categorical_crossentropy: 0.5817 - val_loss: 0.4754 - val_sparse_categorical_accuracy: 0.8506 - val_sparse_categorical_crossentropy: 0.4754 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.4501 - sparse_categorical_accuracy: 0.8597 - sparse_categorical_crossentropy: 0.4501 - val_loss: 0.4210 - val_sparse_categorical_accuracy: 0.8663 - val_sparse_categorical_crossentropy: 0.4210 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.4047 - sparse_categorical_accuracy: 0.8755 - sparse_categorical_crossentropy: 0.4047 - val_loss: 0.3712 - val_sparse_categorical_accuracy: 0.8782 - val_sparse_categorical_crossentropy: 0.3712 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.3758 - sparse_categorical_accuracy: 0.8834 - sparse_categorical_crossentropy: 0.3758 - val_loss: 0.3528 - val_sparse_categorical_accuracy: 0.8896 - val_sparse_categorical_crossentropy: 0.3528 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.3386 - sparse_categorical_accuracy: 0.8963 - sparse_categorical_crossentropy: 0.3386 - val_loss: 0.3324 - val_sparse_categorical_accuracy: 0.8970 - val_sparse_categorical_crossentropy: 0.3324 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 15s 154ms/step - loss: 0.3211 - sparse_categorical_accuracy: 0.8987 - sparse_categorical_crossentropy: 0.3211 - val_loss: 0.3249 - val_sparse_categorical_accuracy: 0.8987 - val_sparse_categorical_crossentropy: 0.3249 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 15s 151ms/step - loss: 0.2993 - sparse_categorical_accuracy: 0.9062 - sparse_categorical_crossentropy: 0.2993 - val_loss: 0.3263 - val_sparse_categorical_accuracy: 0.8981 - val_sparse_categorical_crossentropy: 0.3263 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 15s 154ms/step - loss: 0.2929 - sparse_categorical_accuracy: 0.9094 - sparse_categorical_crossentropy: 0.2929 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.8999 - val_sparse_categorical_crossentropy: 0.3343 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 15s 151ms/step - loss: 0.2968 - sparse_categorical_accuracy: 0.9077 - sparse_categorical_crossentropy: 0.2968 - val_loss: 0.2797 - val_sparse_categorical_accuracy: 0.9129 - val_sparse_categorical_crossentropy: 0.2797 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 15s 154ms/step - loss: 0.2961 - sparse_categorical_accuracy: 0.9075 - sparse_categorical_crossentropy: 0.2961 - val_loss: 0.3241 - val_sparse_categorical_accuracy: 0.9011 - val_sparse_categorical_crossentropy: 0.3241 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 15s 155ms/step - loss: 0.2553 - sparse_categorical_accuracy: 0.9212 - sparse_categorical_crossentropy: 0.2553 - val_loss: 0.3023 - val_sparse_categorical_accuracy: 0.9066 - val_sparse_categorical_crossentropy: 0.3023 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2750 - sparse_categorical_accuracy: 0.9142 - sparse_categorical_crossentropy: 0.2750\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.2750 - sparse_categorical_accuracy: 0.9142 - sparse_categorical_crossentropy: 0.2750 - val_loss: 0.3009 - val_sparse_categorical_accuracy: 0.9074 - val_sparse_categorical_crossentropy: 0.3009 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.2125 - sparse_categorical_accuracy: 0.9335 - sparse_categorical_crossentropy: 0.2125 - val_loss: 0.2217 - val_sparse_categorical_accuracy: 0.9301 - val_sparse_categorical_crossentropy: 0.2217 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.1770 - sparse_categorical_accuracy: 0.9454 - sparse_categorical_crossentropy: 0.1770 - val_loss: 0.2107 - val_sparse_categorical_accuracy: 0.9329 - val_sparse_categorical_crossentropy: 0.2107 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.1851 - sparse_categorical_accuracy: 0.9421 - sparse_categorical_crossentropy: 0.1851 - val_loss: 0.2469 - val_sparse_categorical_accuracy: 0.9225 - val_sparse_categorical_crossentropy: 0.2469 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 15s 155ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9394 - sparse_categorical_crossentropy: 0.1949 - val_loss: 0.1992 - val_sparse_categorical_accuracy: 0.9390 - val_sparse_categorical_crossentropy: 0.1992 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.1568 - sparse_categorical_accuracy: 0.9511 - sparse_categorical_crossentropy: 0.1568 - val_loss: 0.2009 - val_sparse_categorical_accuracy: 0.9364 - val_sparse_categorical_crossentropy: 0.2009 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.1498 - sparse_categorical_accuracy: 0.9545 - sparse_categorical_crossentropy: 0.1498 - val_loss: 0.1940 - val_sparse_categorical_accuracy: 0.9403 - val_sparse_categorical_crossentropy: 0.1940 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.1391 - sparse_categorical_accuracy: 0.9562 - sparse_categorical_crossentropy: 0.1391 - val_loss: 0.2080 - val_sparse_categorical_accuracy: 0.9346 - val_sparse_categorical_crossentropy: 0.2080 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.1556 - sparse_categorical_accuracy: 0.9507 - sparse_categorical_crossentropy: 0.1556 - val_loss: 0.2146 - val_sparse_categorical_accuracy: 0.9315 - val_sparse_categorical_crossentropy: 0.2146 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1502 - sparse_categorical_accuracy: 0.9526 - sparse_categorical_crossentropy: 0.1502\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 15s 151ms/step - loss: 0.1502 - sparse_categorical_accuracy: 0.9526 - sparse_categorical_crossentropy: 0.1502 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.9192 - val_sparse_categorical_crossentropy: 0.2528 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.1294 - sparse_categorical_accuracy: 0.9592 - sparse_categorical_crossentropy: 0.1294 - val_loss: 0.1893 - val_sparse_categorical_accuracy: 0.9410 - val_sparse_categorical_crossentropy: 0.1893 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 15s 154ms/step - loss: 0.1050 - sparse_categorical_accuracy: 0.9683 - sparse_categorical_crossentropy: 0.1050 - val_loss: 0.1842 - val_sparse_categorical_accuracy: 0.9430 - val_sparse_categorical_crossentropy: 0.1842 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 15s 154ms/step - loss: 0.1019 - sparse_categorical_accuracy: 0.9687 - sparse_categorical_crossentropy: 0.1019 - val_loss: 0.1830 - val_sparse_categorical_accuracy: 0.9433 - val_sparse_categorical_crossentropy: 0.1830 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9728 - sparse_categorical_crossentropy: 0.0921 - val_loss: 0.1826 - val_sparse_categorical_accuracy: 0.9441 - val_sparse_categorical_crossentropy: 0.1826 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9741 - sparse_categorical_crossentropy: 0.0885 - val_loss: 0.1815 - val_sparse_categorical_accuracy: 0.9447 - val_sparse_categorical_crossentropy: 0.1815 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.0814 - sparse_categorical_accuracy: 0.9761 - sparse_categorical_crossentropy: 0.0814 - val_loss: 0.2075 - val_sparse_categorical_accuracy: 0.9358 - val_sparse_categorical_crossentropy: 0.2075 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 15s 154ms/step - loss: 0.0900 - sparse_categorical_accuracy: 0.9728 - sparse_categorical_crossentropy: 0.0900 - val_loss: 0.1821 - val_sparse_categorical_accuracy: 0.9450 - val_sparse_categorical_crossentropy: 0.1821 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.1014 - sparse_categorical_accuracy: 0.9691 - sparse_categorical_crossentropy: 0.1014 - val_loss: 0.1813 - val_sparse_categorical_accuracy: 0.9437 - val_sparse_categorical_crossentropy: 0.1813 - lr: 0.0025\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 15s 151ms/step - loss: 0.0783 - sparse_categorical_accuracy: 0.9771 - sparse_categorical_crossentropy: 0.0783 - val_loss: 0.1826 - val_sparse_categorical_accuracy: 0.9444 - val_sparse_categorical_crossentropy: 0.1826 - lr: 0.0025\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.0702 - sparse_categorical_accuracy: 0.9806 - sparse_categorical_crossentropy: 0.0702 - val_loss: 0.1792 - val_sparse_categorical_accuracy: 0.9473 - val_sparse_categorical_crossentropy: 0.1792 - lr: 0.0025\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 15s 151ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9826 - sparse_categorical_crossentropy: 0.0639 - val_loss: 0.1811 - val_sparse_categorical_accuracy: 0.9475 - val_sparse_categorical_crossentropy: 0.1811 - lr: 0.0025\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9828 - sparse_categorical_crossentropy: 0.0636 - val_loss: 0.1820 - val_sparse_categorical_accuracy: 0.9433 - val_sparse_categorical_crossentropy: 0.1820 - lr: 0.0025\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9847 - sparse_categorical_crossentropy: 0.0591 - val_loss: 0.1767 - val_sparse_categorical_accuracy: 0.9475 - val_sparse_categorical_crossentropy: 0.1767 - lr: 0.0025\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0537 - sparse_categorical_accuracy: 0.9863 - sparse_categorical_crossentropy: 0.0537\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 15s 151ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9863 - sparse_categorical_crossentropy: 0.0537 - val_loss: 0.1824 - val_sparse_categorical_accuracy: 0.9450 - val_sparse_categorical_crossentropy: 0.1824 - lr: 0.0025\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 15s 153ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9885 - sparse_categorical_crossentropy: 0.0480 - val_loss: 0.1810 - val_sparse_categorical_accuracy: 0.9463 - val_sparse_categorical_crossentropy: 0.1810 - lr: 0.0012\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 15s 152ms/step - loss: 0.0430 - sparse_categorical_accuracy: 0.9905 - sparse_categorical_crossentropy: 0.0430 - val_loss: 0.1810 - val_sparse_categorical_accuracy: 0.9467 - val_sparse_categorical_crossentropy: 0.1810 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 103ms/step - loss: 0.2010 - sparse_categorical_accuracy: 0.9431 - sparse_categorical_crossentropy: 0.2010\n",
      "26/26 [==============================] - 4s 101ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 18s 161ms/step - loss: 1.4578 - sparse_categorical_accuracy: 0.6259 - sparse_categorical_crossentropy: 1.4578 - val_loss: 1.3004 - val_sparse_categorical_accuracy: 0.6367 - val_sparse_categorical_crossentropy: 1.3004 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 1.0806 - sparse_categorical_accuracy: 0.6753 - sparse_categorical_crossentropy: 1.0806 - val_loss: 0.8652 - val_sparse_categorical_accuracy: 0.7344 - val_sparse_categorical_crossentropy: 0.8652 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.7237 - sparse_categorical_accuracy: 0.7743 - sparse_categorical_crossentropy: 0.7237 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.8070 - val_sparse_categorical_crossentropy: 0.6349 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.5610 - sparse_categorical_accuracy: 0.8266 - sparse_categorical_crossentropy: 0.5610 - val_loss: 0.4675 - val_sparse_categorical_accuracy: 0.8526 - val_sparse_categorical_crossentropy: 0.4675 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 15s 160ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.8606 - sparse_categorical_crossentropy: 0.4470 - val_loss: 0.4032 - val_sparse_categorical_accuracy: 0.8764 - val_sparse_categorical_crossentropy: 0.4032 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.4629 - sparse_categorical_accuracy: 0.8588 - sparse_categorical_crossentropy: 0.4629 - val_loss: 0.3976 - val_sparse_categorical_accuracy: 0.8790 - val_sparse_categorical_crossentropy: 0.3976 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.3637 - sparse_categorical_accuracy: 0.8866 - sparse_categorical_crossentropy: 0.3637 - val_loss: 0.3566 - val_sparse_categorical_accuracy: 0.8884 - val_sparse_categorical_crossentropy: 0.3566 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.3140 - sparse_categorical_accuracy: 0.9041 - sparse_categorical_crossentropy: 0.3140 - val_loss: 0.3165 - val_sparse_categorical_accuracy: 0.9036 - val_sparse_categorical_crossentropy: 0.3165 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.2862 - sparse_categorical_accuracy: 0.9115 - sparse_categorical_crossentropy: 0.2862 - val_loss: 0.2872 - val_sparse_categorical_accuracy: 0.9096 - val_sparse_categorical_crossentropy: 0.2872 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.2590 - sparse_categorical_accuracy: 0.9189 - sparse_categorical_crossentropy: 0.2590 - val_loss: 0.3059 - val_sparse_categorical_accuracy: 0.9039 - val_sparse_categorical_crossentropy: 0.3059 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.9082 - sparse_categorical_crossentropy: 0.2935 - val_loss: 0.2779 - val_sparse_categorical_accuracy: 0.9119 - val_sparse_categorical_crossentropy: 0.2779 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.2693 - sparse_categorical_accuracy: 0.9150 - sparse_categorical_crossentropy: 0.2693 - val_loss: 0.2748 - val_sparse_categorical_accuracy: 0.9103 - val_sparse_categorical_crossentropy: 0.2748 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.2479 - sparse_categorical_accuracy: 0.9230 - sparse_categorical_crossentropy: 0.2479 - val_loss: 0.2728 - val_sparse_categorical_accuracy: 0.9159 - val_sparse_categorical_crossentropy: 0.2728 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.2659 - sparse_categorical_accuracy: 0.9177 - sparse_categorical_crossentropy: 0.2659 - val_loss: 0.3201 - val_sparse_categorical_accuracy: 0.8976 - val_sparse_categorical_crossentropy: 0.3201 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 15s 156ms/step - loss: 0.2526 - sparse_categorical_accuracy: 0.9220 - sparse_categorical_crossentropy: 0.2526 - val_loss: 0.2689 - val_sparse_categorical_accuracy: 0.9143 - val_sparse_categorical_crossentropy: 0.2689 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2229 - sparse_categorical_accuracy: 0.9288 - sparse_categorical_crossentropy: 0.2229\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.2229 - sparse_categorical_accuracy: 0.9288 - sparse_categorical_crossentropy: 0.2229 - val_loss: 0.2748 - val_sparse_categorical_accuracy: 0.9146 - val_sparse_categorical_crossentropy: 0.2748 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.1865 - sparse_categorical_accuracy: 0.9425 - sparse_categorical_crossentropy: 0.1865 - val_loss: 0.2216 - val_sparse_categorical_accuracy: 0.9303 - val_sparse_categorical_crossentropy: 0.2216 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.1657 - sparse_categorical_accuracy: 0.9494 - sparse_categorical_crossentropy: 0.1657 - val_loss: 0.2025 - val_sparse_categorical_accuracy: 0.9384 - val_sparse_categorical_crossentropy: 0.2025 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 15s 160ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9534 - sparse_categorical_crossentropy: 0.1537 - val_loss: 0.2027 - val_sparse_categorical_accuracy: 0.9372 - val_sparse_categorical_crossentropy: 0.2027 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9563 - sparse_categorical_crossentropy: 0.1431 - val_loss: 0.1982 - val_sparse_categorical_accuracy: 0.9410 - val_sparse_categorical_crossentropy: 0.1982 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.1341 - sparse_categorical_accuracy: 0.9586 - sparse_categorical_crossentropy: 0.1341 - val_loss: 0.2022 - val_sparse_categorical_accuracy: 0.9412 - val_sparse_categorical_crossentropy: 0.2022 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9608 - sparse_categorical_crossentropy: 0.1261 - val_loss: 0.1889 - val_sparse_categorical_accuracy: 0.9420 - val_sparse_categorical_crossentropy: 0.1889 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.1258 - sparse_categorical_accuracy: 0.9615 - sparse_categorical_crossentropy: 0.1258 - val_loss: 0.1955 - val_sparse_categorical_accuracy: 0.9426 - val_sparse_categorical_crossentropy: 0.1955 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.1185 - sparse_categorical_accuracy: 0.9633 - sparse_categorical_crossentropy: 0.1185 - val_loss: 0.1955 - val_sparse_categorical_accuracy: 0.9430 - val_sparse_categorical_crossentropy: 0.1955 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9685 - sparse_categorical_crossentropy: 0.1056 - val_loss: 0.1870 - val_sparse_categorical_accuracy: 0.9467 - val_sparse_categorical_crossentropy: 0.1870 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.1022 - sparse_categorical_accuracy: 0.9686 - sparse_categorical_crossentropy: 0.1022 - val_loss: 0.1893 - val_sparse_categorical_accuracy: 0.9437 - val_sparse_categorical_crossentropy: 0.1893 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 15s 160ms/step - loss: 0.1285 - sparse_categorical_accuracy: 0.9592 - sparse_categorical_crossentropy: 0.1285 - val_loss: 0.2172 - val_sparse_categorical_accuracy: 0.9344 - val_sparse_categorical_crossentropy: 0.2172 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1186 - sparse_categorical_accuracy: 0.9627 - sparse_categorical_crossentropy: 0.1186\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.1186 - sparse_categorical_accuracy: 0.9627 - sparse_categorical_crossentropy: 0.1186 - val_loss: 0.2030 - val_sparse_categorical_accuracy: 0.9383 - val_sparse_categorical_crossentropy: 0.2030 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9728 - sparse_categorical_crossentropy: 0.0920 - val_loss: 0.1716 - val_sparse_categorical_accuracy: 0.9506 - val_sparse_categorical_crossentropy: 0.1716 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9787 - sparse_categorical_crossentropy: 0.0749 - val_loss: 0.1765 - val_sparse_categorical_accuracy: 0.9478 - val_sparse_categorical_crossentropy: 0.1765 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9815 - sparse_categorical_crossentropy: 0.0672 - val_loss: 0.1739 - val_sparse_categorical_accuracy: 0.9501 - val_sparse_categorical_crossentropy: 0.1739 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0624 - sparse_categorical_accuracy: 0.9834 - sparse_categorical_crossentropy: 0.0624\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9834 - sparse_categorical_crossentropy: 0.0624 - val_loss: 0.1806 - val_sparse_categorical_accuracy: 0.9489 - val_sparse_categorical_crossentropy: 0.1806 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9871 - sparse_categorical_crossentropy: 0.0542 - val_loss: 0.1771 - val_sparse_categorical_accuracy: 0.9504 - val_sparse_categorical_crossentropy: 0.1771 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9868 - sparse_categorical_crossentropy: 0.0542 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9498 - val_sparse_categorical_crossentropy: 0.1796 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 109ms/step - loss: 0.1829 - sparse_categorical_accuracy: 0.9452 - sparse_categorical_crossentropy: 0.1829\n",
      "26/26 [==============================] - 4s 101ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 18s 163ms/step - loss: 1.4547 - sparse_categorical_accuracy: 0.6271 - sparse_categorical_crossentropy: 1.4547 - val_loss: 1.2792 - val_sparse_categorical_accuracy: 0.6439 - val_sparse_categorical_crossentropy: 1.2792 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 1.1094 - sparse_categorical_accuracy: 0.6715 - sparse_categorical_crossentropy: 1.1094 - val_loss: 0.9572 - val_sparse_categorical_accuracy: 0.6963 - val_sparse_categorical_crossentropy: 0.9572 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.8045 - sparse_categorical_accuracy: 0.7506 - sparse_categorical_crossentropy: 0.8045 - val_loss: 0.7395 - val_sparse_categorical_accuracy: 0.7672 - val_sparse_categorical_crossentropy: 0.7395 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.6158 - sparse_categorical_accuracy: 0.8073 - sparse_categorical_crossentropy: 0.6158 - val_loss: 0.5595 - val_sparse_categorical_accuracy: 0.8265 - val_sparse_categorical_crossentropy: 0.5595 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.5330 - sparse_categorical_accuracy: 0.8330 - sparse_categorical_crossentropy: 0.5330 - val_loss: 0.4853 - val_sparse_categorical_accuracy: 0.8437 - val_sparse_categorical_crossentropy: 0.4853 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.4838 - sparse_categorical_accuracy: 0.8485 - sparse_categorical_crossentropy: 0.4838 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.8586 - val_sparse_categorical_crossentropy: 0.4568 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.4219 - sparse_categorical_accuracy: 0.8697 - sparse_categorical_crossentropy: 0.4219 - val_loss: 0.4175 - val_sparse_categorical_accuracy: 0.8680 - val_sparse_categorical_crossentropy: 0.4175 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.4509 - sparse_categorical_accuracy: 0.8600 - sparse_categorical_crossentropy: 0.4509 - val_loss: 0.4164 - val_sparse_categorical_accuracy: 0.8735 - val_sparse_categorical_crossentropy: 0.4164 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.3630 - sparse_categorical_accuracy: 0.8884 - sparse_categorical_crossentropy: 0.3630 - val_loss: 0.3514 - val_sparse_categorical_accuracy: 0.8899 - val_sparse_categorical_crossentropy: 0.3514 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.3436 - sparse_categorical_accuracy: 0.8946 - sparse_categorical_crossentropy: 0.3436 - val_loss: 0.3263 - val_sparse_categorical_accuracy: 0.8990 - val_sparse_categorical_crossentropy: 0.3263 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.3413 - sparse_categorical_accuracy: 0.8953 - sparse_categorical_crossentropy: 0.3413 - val_loss: 0.3766 - val_sparse_categorical_accuracy: 0.8809 - val_sparse_categorical_crossentropy: 0.3766 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.3226 - sparse_categorical_accuracy: 0.8995 - sparse_categorical_crossentropy: 0.3226 - val_loss: 0.3029 - val_sparse_categorical_accuracy: 0.9047 - val_sparse_categorical_crossentropy: 0.3029 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.2844 - sparse_categorical_accuracy: 0.9121 - sparse_categorical_crossentropy: 0.2844 - val_loss: 0.3223 - val_sparse_categorical_accuracy: 0.9020 - val_sparse_categorical_crossentropy: 0.3223 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.2865 - sparse_categorical_accuracy: 0.9118 - sparse_categorical_crossentropy: 0.2865 - val_loss: 0.2729 - val_sparse_categorical_accuracy: 0.9151 - val_sparse_categorical_crossentropy: 0.2729 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.2606 - sparse_categorical_accuracy: 0.9186 - sparse_categorical_crossentropy: 0.2606 - val_loss: 0.2955 - val_sparse_categorical_accuracy: 0.9085 - val_sparse_categorical_crossentropy: 0.2955 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.2668 - sparse_categorical_accuracy: 0.9165 - sparse_categorical_crossentropy: 0.2668 - val_loss: 0.2746 - val_sparse_categorical_accuracy: 0.9114 - val_sparse_categorical_crossentropy: 0.2746 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2600 - sparse_categorical_accuracy: 0.9200 - sparse_categorical_crossentropy: 0.2600\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.2600 - sparse_categorical_accuracy: 0.9200 - sparse_categorical_crossentropy: 0.2600 - val_loss: 0.3358 - val_sparse_categorical_accuracy: 0.8974 - val_sparse_categorical_crossentropy: 0.3358 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.2133 - sparse_categorical_accuracy: 0.9342 - sparse_categorical_crossentropy: 0.2133 - val_loss: 0.2315 - val_sparse_categorical_accuracy: 0.9285 - val_sparse_categorical_crossentropy: 0.2315 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 16s 159ms/step - loss: 0.1956 - sparse_categorical_accuracy: 0.9387 - sparse_categorical_crossentropy: 0.1956 - val_loss: 0.2293 - val_sparse_categorical_accuracy: 0.9278 - val_sparse_categorical_crossentropy: 0.2293 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.1774 - sparse_categorical_accuracy: 0.9451 - sparse_categorical_crossentropy: 0.1774 - val_loss: 0.2136 - val_sparse_categorical_accuracy: 0.9320 - val_sparse_categorical_crossentropy: 0.2136 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.1621 - sparse_categorical_accuracy: 0.9509 - sparse_categorical_crossentropy: 0.1621 - val_loss: 0.2037 - val_sparse_categorical_accuracy: 0.9387 - val_sparse_categorical_crossentropy: 0.2037 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.1489 - sparse_categorical_accuracy: 0.9540 - sparse_categorical_crossentropy: 0.1489 - val_loss: 0.2074 - val_sparse_categorical_accuracy: 0.9363 - val_sparse_categorical_crossentropy: 0.2074 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 16s 159ms/step - loss: 0.1727 - sparse_categorical_accuracy: 0.9463 - sparse_categorical_crossentropy: 0.1727 - val_loss: 0.2034 - val_sparse_categorical_accuracy: 0.9377 - val_sparse_categorical_crossentropy: 0.2034 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1429 - sparse_categorical_accuracy: 0.9557 - sparse_categorical_crossentropy: 0.1429\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.1429 - sparse_categorical_accuracy: 0.9557 - sparse_categorical_crossentropy: 0.1429 - val_loss: 0.2007 - val_sparse_categorical_accuracy: 0.9383 - val_sparse_categorical_crossentropy: 0.2007 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.1260 - sparse_categorical_accuracy: 0.9619 - sparse_categorical_crossentropy: 0.1260 - val_loss: 0.1884 - val_sparse_categorical_accuracy: 0.9441 - val_sparse_categorical_crossentropy: 0.1884 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9643 - sparse_categorical_crossentropy: 0.1192 - val_loss: 0.1832 - val_sparse_categorical_accuracy: 0.9458 - val_sparse_categorical_crossentropy: 0.1832 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 15s 160ms/step - loss: 0.1038 - sparse_categorical_accuracy: 0.9700 - sparse_categorical_crossentropy: 0.1038 - val_loss: 0.1848 - val_sparse_categorical_accuracy: 0.9458 - val_sparse_categorical_crossentropy: 0.1848 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9731 - sparse_categorical_crossentropy: 0.0964 - val_loss: 0.1835 - val_sparse_categorical_accuracy: 0.9449 - val_sparse_categorical_crossentropy: 0.1835 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0893 - sparse_categorical_accuracy: 0.9748 - sparse_categorical_crossentropy: 0.0893\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9748 - sparse_categorical_crossentropy: 0.0893 - val_loss: 0.1869 - val_sparse_categorical_accuracy: 0.9440 - val_sparse_categorical_crossentropy: 0.1869 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9791 - sparse_categorical_crossentropy: 0.0789 - val_loss: 0.1821 - val_sparse_categorical_accuracy: 0.9450 - val_sparse_categorical_crossentropy: 0.1821 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9811 - sparse_categorical_crossentropy: 0.0742 - val_loss: 0.1842 - val_sparse_categorical_accuracy: 0.9456 - val_sparse_categorical_crossentropy: 0.1842 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 109ms/step - loss: 0.2086 - sparse_categorical_accuracy: 0.9390 - sparse_categorical_crossentropy: 0.2086\n",
      "26/26 [==============================] - 5s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(5))\n",
    "results = []\n",
    "for seed in TRAINING_SEEDS:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    model = CNN_LSTM(N_CLASS, 16000, 5)\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "        loss=losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(EXPERIMENT_NAME, f\"history_{seed}.pkl\"), \"wb\") as file:\n",
    "        pickle.dump(history.history, file)\n",
    "\n",
    "    eval_results = model.evaluate(test_ds)\n",
    "\n",
    "    predictions = model.predict(test_ds)\n",
    "    with open(os.path.join(EXPERIMENT_NAME, f\"predictions_{seed}.pkl\"), \"wb\") as file:\n",
    "        pickle.dump(predictions, file)\n",
    "\n",
    "    results += [{\n",
    "        'seed': seed,\n",
    "        'results': dict(zip(model.metrics_names, eval_results))\n",
    "    }]\n",
    "    gc.collect()\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results = pd.concat([results.drop([\"results\"], axis=1), results[\"results\"].apply(pd.Series)], axis=1)\n",
    "results.to_csv(os.path.join(EXPERIMENT_NAME, 'results.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T02:52:56.816668Z",
     "end_time": "2023-04-23T03:38:51.161222Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T03:38:51.163221Z",
     "end_time": "2023-04-23T03:38:51.176222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   seed      loss  sparse_categorical_accuracy  \\\n0     0  0.184072                     0.946791   \n1     1  0.234346                     0.931511   \n2     2  0.201025                     0.943105   \n3     3  0.182946                     0.945178   \n4     4  0.208616                     0.938959   \n\n   sparse_categorical_crossentropy  \n0                         0.184072  \n1                         0.234346  \n2                         0.201025  \n3                         0.182946  \n4                         0.208616  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed</th>\n      <th>loss</th>\n      <th>sparse_categorical_accuracy</th>\n      <th>sparse_categorical_crossentropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.184072</td>\n      <td>0.946791</td>\n      <td>0.184072</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.234346</td>\n      <td>0.931511</td>\n      <td>0.234346</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.201025</td>\n      <td>0.943105</td>\n      <td>0.201025</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.182946</td>\n      <td>0.945178</td>\n      <td>0.182946</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.208616</td>\n      <td>0.938959</td>\n      <td>0.208616</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
