{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T13:36:25.038618Z",
     "end_time": "2023-04-23T13:36:29.568473Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import losses, optimizers, metrics, callbacks, layers, Model\n",
    "from SpeechModels import get_melspec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T13:36:30.600469Z",
     "end_time": "2023-04-23T13:36:30.625469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T13:36:30.610469Z",
     "end_time": "2023-04-23T13:36:30.625469Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "N_CLASS = 12\n",
    "MAX_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-23T13:36:30.625469Z",
     "end_time": "2023-04-23T13:36:30.640469Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45586 files belonging to 12 classes.\n",
      "Found 6513 files belonging to 12 classes.\n",
      "Found 13024 files belonging to 12 classes.\n",
      "label names: ['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n",
      "Found 45586 files belonging to 12 classes.\n",
      "Found 6513 files belonging to 12 classes.\n",
      "Found 13024 files belonging to 12 classes.\n",
      "label names: ['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/train\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/val\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=\"data/test\",\n",
    "    batch_size=512,\n",
    "    output_sequence_length=16000)\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print(\"label names:\", label_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:36:36.128083Z",
     "end_time": "2023-04-23T13:37:18.527715Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio, labels\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(squeeze, tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:36:36.205083Z",
     "end_time": "2023-04-23T13:37:18.591514Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model stacked bidirectional lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " tf.signal.stft (TFOpLambda)    (None, 125, 513)     0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.abs (TFOpLambda)       (None, 125, 513)     0           ['tf.signal.stft[0][0]']         \n",
      "                                                                                                  \n",
      " tf.tensordot (TFOpLambda)      (None, 125, 80)      0           ['tf.math.abs[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 125, 80)     0           ['tf.tensordot[0][0]']           \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.log (TFOpLambda)       (None, 125, 80)      0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.math.log[0][0]']            \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 125, 80)      0           ['tf.math.log[0][0]',            \n",
      "                                                                  'tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.reduce_std (TFOpLambda  ()                  0           ['tf.math.log[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 125, 80)      0           ['tf.math.subtract[0][0]',       \n",
      "                                                                  'tf.math.reduce_std[0][0]']     \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 512)          690176      ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 12)           6156        ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 696,332\n",
      "Trainable params: 696,332\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " tf.signal.stft_2 (TFOpLambda)  (None, 125, 513)     0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.abs_2 (TFOpLambda)     (None, 125, 513)     0           ['tf.signal.stft_2[0][0]']       \n",
      "                                                                                                  \n",
      " tf.tensordot_2 (TFOpLambda)    (None, 125, 80)      0           ['tf.math.abs_2[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 125, 80)     0           ['tf.tensordot_2[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.log_2 (TFOpLambda)     (None, 125, 80)      0           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  ()                  0           ['tf.math.log_2[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 125, 80)     0           ['tf.math.log_2[0][0]',          \n",
      " )                                                                'tf.math.reduce_mean_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.reduce_std_2 (TFOpLamb  ()                  0           ['tf.math.log_2[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLambda)  (None, 125, 80)     0           ['tf.math.subtract_2[0][0]',     \n",
      "                                                                  'tf.math.reduce_std_2[0][0]']   \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 512)         690176      ['tf.math.truediv_2[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 12)           6156        ['bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 696,332\n",
      "Trainable params: 696,332\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_bidirectional_model(number_of_layers):\n",
    "    mel_spec_model = get_melspec_model(16000)\n",
    "    inputs, outputs = mel_spec_model.inputs, mel_spec_model.outputs\n",
    "    x = outputs[0]\n",
    "    for i in range(0, number_of_layers):\n",
    "        if i != number_of_layers - 1:\n",
    "            x = layers.Bidirectional(layers.LSTM(2 ** (8 - i), return_sequences=True))(x)\n",
    "        else:\n",
    "            x = layers.Bidirectional(layers.LSTM(2 ** (8 - i)))(x)\n",
    "    out = layers.Dense(N_CLASS, activation=\"softmax\")(x)\n",
    "    return Model(inputs=inputs, outputs=out)\n",
    "\n",
    "\n",
    "model = create_bidirectional_model(1)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:36:36.977575Z",
     "end_time": "2023-04-23T13:37:19.159440Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=3,\n",
    "                                        min_lr=0.00001, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:36:37.037574Z",
     "end_time": "2023-04-23T13:37:19.175444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "90/90 [==============================] - 22s 118ms/step - loss: 1.3559 - sparse_categorical_accuracy: 0.6361 - sparse_categorical_crossentropy: 1.3559 - val_loss: 1.1359 - val_sparse_categorical_accuracy: 0.6596 - val_sparse_categorical_crossentropy: 1.1359 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 13s 135ms/step - loss: 0.8997 - sparse_categorical_accuracy: 0.7275 - sparse_categorical_crossentropy: 0.8997 - val_loss: 0.7248 - val_sparse_categorical_accuracy: 0.7723 - val_sparse_categorical_crossentropy: 0.7248 - lr: 0.0010\n",
      "Epoch 1/2\n",
      "90/90 [==============================] - 16s 136ms/step - loss: 1.3674 - sparse_categorical_accuracy: 0.6372 - sparse_categorical_crossentropy: 1.3674 - val_loss: 1.1060 - val_sparse_categorical_accuracy: 0.6538 - val_sparse_categorical_crossentropy: 1.1060 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.8651 - sparse_categorical_accuracy: 0.7297 - sparse_categorical_crossentropy: 0.8651 - val_loss: 0.7289 - val_sparse_categorical_accuracy: 0.7758 - val_sparse_categorical_crossentropy: 0.7289 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=2,\n",
    "    validation_data=val_ds,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:37:12.128002Z",
     "end_time": "2023-04-23T13:37:47.712594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " tf.signal.stft_1 (TFOpLambda)  (None, 125, 513)     0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.abs_1 (TFOpLambda)     (None, 125, 513)     0           ['tf.signal.stft_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.tensordot_1 (TFOpLambda)    (None, 125, 80)      0           ['tf.math.abs_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 125, 80)     0           ['tf.tensordot_1[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.log_1 (TFOpLambda)     (None, 125, 80)      0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  ()                  0           ['tf.math.log_1[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 125, 80)     0           ['tf.math.log_1[0][0]',          \n",
      " )                                                                'tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.reduce_std_1 (TFOpLamb  ()                  0           ['tf.math.log_1[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLambda)  (None, 125, 80)     0           ['tf.math.subtract_1[0][0]',     \n",
      "                                                                  'tf.math.reduce_std_1[0][0]']   \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 125, 512)    690176      ['tf.math.truediv_1[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 256)         656384      ['bidirectional_1[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 12)           3084        ['bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,349,644\n",
      "Trainable params: 1,349,644\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000)]      0           []                               \n",
      "                                                                                                  \n",
      " tf.signal.stft_3 (TFOpLambda)  (None, 125, 513)     0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.abs_3 (TFOpLambda)     (None, 125, 513)     0           ['tf.signal.stft_3[0][0]']       \n",
      "                                                                                                  \n",
      " tf.tensordot_3 (TFOpLambda)    (None, 125, 80)      0           ['tf.math.abs_3[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 125, 80)     0           ['tf.tensordot_3[0][0]']         \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.log_3 (TFOpLambda)     (None, 125, 80)      0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  ()                  0           ['tf.math.log_3[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 125, 80)     0           ['tf.math.log_3[0][0]',          \n",
      " )                                                                'tf.math.reduce_mean_3[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.reduce_std_3 (TFOpLamb  ()                  0           ['tf.math.log_3[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.truediv_3 (TFOpLambda)  (None, 125, 80)     0           ['tf.math.subtract_3[0][0]',     \n",
      "                                                                  'tf.math.reduce_std_3[0][0]']   \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 125, 512)    690176      ['tf.math.truediv_3[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  (None, 256)         656384      ['bidirectional_4[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 12)           3084        ['bidirectional_5[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,349,644\n",
      "Trainable params: 1,349,644\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_bidirectional_model(2)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:37:13.089002Z",
     "end_time": "2023-04-23T13:37:49.053593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', factor=0.5, patience=3,\n",
    "                                        min_lr=0.00001, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:37:13.098002Z",
     "end_time": "2023-04-23T13:37:49.054595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "14815"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "58351"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:37:13.203001Z",
     "end_time": "2023-04-23T13:37:49.055593Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Training will be repeated 5 times with different weights initialization. For each number of layers, we created another directory with results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 16s 135ms/step - loss: 1.3750 - sparse_categorical_accuracy: 0.6385 - sparse_categorical_crossentropy: 1.3750 - val_loss: 0.9802 - val_sparse_categorical_accuracy: 0.7080 - val_sparse_categorical_crossentropy: 0.9802 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 13s 134ms/step - loss: 0.7746 - sparse_categorical_accuracy: 0.7592 - sparse_categorical_crossentropy: 0.7746 - val_loss: 0.6281 - val_sparse_categorical_accuracy: 0.8082 - val_sparse_categorical_crossentropy: 0.6281 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 13s 137ms/step - loss: 0.6181 - sparse_categorical_accuracy: 0.8077 - sparse_categorical_crossentropy: 0.6181 - val_loss: 0.5875 - val_sparse_categorical_accuracy: 0.8156 - val_sparse_categorical_crossentropy: 0.5875 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.5863 - sparse_categorical_accuracy: 0.8187 - sparse_categorical_crossentropy: 0.5863 - val_loss: 0.5299 - val_sparse_categorical_accuracy: 0.8279 - val_sparse_categorical_crossentropy: 0.5299 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.5121 - sparse_categorical_accuracy: 0.8419 - sparse_categorical_crossentropy: 0.5121 - val_loss: 0.5141 - val_sparse_categorical_accuracy: 0.8349 - val_sparse_categorical_crossentropy: 0.5141 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.4653 - sparse_categorical_accuracy: 0.8561 - sparse_categorical_crossentropy: 0.4653 - val_loss: 0.4655 - val_sparse_categorical_accuracy: 0.8508 - val_sparse_categorical_crossentropy: 0.4655 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.4140 - sparse_categorical_accuracy: 0.8718 - sparse_categorical_crossentropy: 0.4140 - val_loss: 0.4849 - val_sparse_categorical_accuracy: 0.8498 - val_sparse_categorical_crossentropy: 0.4849 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.4621 - sparse_categorical_accuracy: 0.8555 - sparse_categorical_crossentropy: 0.4621 - val_loss: 0.4378 - val_sparse_categorical_accuracy: 0.8618 - val_sparse_categorical_crossentropy: 0.4378 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.4053 - sparse_categorical_accuracy: 0.8738 - sparse_categorical_crossentropy: 0.4053 - val_loss: 0.4219 - val_sparse_categorical_accuracy: 0.8675 - val_sparse_categorical_crossentropy: 0.4219 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.8563 - sparse_categorical_crossentropy: 0.4543 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8644 - val_sparse_categorical_crossentropy: 0.4322 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.8660 - sparse_categorical_crossentropy: 0.4295 - val_loss: 0.4203 - val_sparse_categorical_accuracy: 0.8649 - val_sparse_categorical_crossentropy: 0.4203 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4307 - sparse_categorical_accuracy: 0.8648 - sparse_categorical_crossentropy: 0.4307\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8648 - sparse_categorical_crossentropy: 0.4307 - val_loss: 0.4418 - val_sparse_categorical_accuracy: 0.8653 - val_sparse_categorical_crossentropy: 0.4418 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.3796 - sparse_categorical_accuracy: 0.8812 - sparse_categorical_crossentropy: 0.3796 - val_loss: 0.3438 - val_sparse_categorical_accuracy: 0.8925 - val_sparse_categorical_crossentropy: 0.3438 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.2968 - sparse_categorical_accuracy: 0.9078 - sparse_categorical_crossentropy: 0.2968 - val_loss: 0.3064 - val_sparse_categorical_accuracy: 0.8988 - val_sparse_categorical_crossentropy: 0.3064 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.2750 - sparse_categorical_accuracy: 0.9151 - sparse_categorical_crossentropy: 0.2750 - val_loss: 0.3120 - val_sparse_categorical_accuracy: 0.9030 - val_sparse_categorical_crossentropy: 0.3120 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.2720 - sparse_categorical_accuracy: 0.9158 - sparse_categorical_crossentropy: 0.2720 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.9031 - val_sparse_categorical_crossentropy: 0.3000 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.2517 - sparse_categorical_accuracy: 0.9217 - sparse_categorical_crossentropy: 0.2517 - val_loss: 0.2741 - val_sparse_categorical_accuracy: 0.9175 - val_sparse_categorical_crossentropy: 0.2741 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.2352 - sparse_categorical_accuracy: 0.9263 - sparse_categorical_crossentropy: 0.2352 - val_loss: 0.2945 - val_sparse_categorical_accuracy: 0.9060 - val_sparse_categorical_crossentropy: 0.2945 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.2379 - sparse_categorical_accuracy: 0.9245 - sparse_categorical_crossentropy: 0.2379 - val_loss: 0.3043 - val_sparse_categorical_accuracy: 0.9068 - val_sparse_categorical_crossentropy: 0.3043 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2367 - sparse_categorical_accuracy: 0.9255 - sparse_categorical_crossentropy: 0.2367\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 13s 137ms/step - loss: 0.2367 - sparse_categorical_accuracy: 0.9255 - sparse_categorical_crossentropy: 0.2367 - val_loss: 0.2901 - val_sparse_categorical_accuracy: 0.9108 - val_sparse_categorical_crossentropy: 0.2901 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 13s 137ms/step - loss: 0.2009 - sparse_categorical_accuracy: 0.9385 - sparse_categorical_crossentropy: 0.2009 - val_loss: 0.2820 - val_sparse_categorical_accuracy: 0.9166 - val_sparse_categorical_crossentropy: 0.2820 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9403 - sparse_categorical_crossentropy: 0.1949 - val_loss: 0.2531 - val_sparse_categorical_accuracy: 0.9220 - val_sparse_categorical_crossentropy: 0.2531 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 14s 138ms/step - loss: 0.1718 - sparse_categorical_accuracy: 0.9468 - sparse_categorical_crossentropy: 0.1718 - val_loss: 0.2500 - val_sparse_categorical_accuracy: 0.9231 - val_sparse_categorical_crossentropy: 0.2500 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.1673 - sparse_categorical_accuracy: 0.9475 - sparse_categorical_crossentropy: 0.1673 - val_loss: 0.2389 - val_sparse_categorical_accuracy: 0.9266 - val_sparse_categorical_crossentropy: 0.2389 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1500 - sparse_categorical_accuracy: 0.9549 - sparse_categorical_crossentropy: 0.1500 - val_loss: 0.2364 - val_sparse_categorical_accuracy: 0.9277 - val_sparse_categorical_crossentropy: 0.2364 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9593 - sparse_categorical_crossentropy: 0.1356 - val_loss: 0.2277 - val_sparse_categorical_accuracy: 0.9306 - val_sparse_categorical_crossentropy: 0.2277 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1456 - sparse_categorical_accuracy: 0.9555 - sparse_categorical_crossentropy: 0.1456 - val_loss: 0.2449 - val_sparse_categorical_accuracy: 0.9255 - val_sparse_categorical_crossentropy: 0.2449 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1406 - sparse_categorical_accuracy: 0.9572 - sparse_categorical_crossentropy: 0.1406 - val_loss: 0.2350 - val_sparse_categorical_accuracy: 0.9257 - val_sparse_categorical_crossentropy: 0.2350 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1225 - sparse_categorical_accuracy: 0.9636 - sparse_categorical_crossentropy: 0.1225\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1225 - sparse_categorical_accuracy: 0.9636 - sparse_categorical_crossentropy: 0.1225 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9280 - val_sparse_categorical_crossentropy: 0.2363 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1103 - sparse_categorical_accuracy: 0.9678 - sparse_categorical_crossentropy: 0.1103 - val_loss: 0.2252 - val_sparse_categorical_accuracy: 0.9338 - val_sparse_categorical_crossentropy: 0.2252 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1022 - sparse_categorical_accuracy: 0.9707 - sparse_categorical_crossentropy: 0.1022 - val_loss: 0.2293 - val_sparse_categorical_accuracy: 0.9291 - val_sparse_categorical_crossentropy: 0.2293 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.1327 - sparse_categorical_accuracy: 0.9604 - sparse_categorical_crossentropy: 0.1327 - val_loss: 0.3118 - val_sparse_categorical_accuracy: 0.9066 - val_sparse_categorical_crossentropy: 0.3118 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1597 - sparse_categorical_accuracy: 0.9501 - sparse_categorical_crossentropy: 0.1597\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1597 - sparse_categorical_accuracy: 0.9501 - sparse_categorical_crossentropy: 0.1597 - val_loss: 0.2596 - val_sparse_categorical_accuracy: 0.9229 - val_sparse_categorical_crossentropy: 0.2596 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.1230 - sparse_categorical_accuracy: 0.9641 - sparse_categorical_crossentropy: 0.1230 - val_loss: 0.2524 - val_sparse_categorical_accuracy: 0.9231 - val_sparse_categorical_crossentropy: 0.2524 - lr: 6.2500e-04\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9679 - sparse_categorical_crossentropy: 0.1134 - val_loss: 0.2487 - val_sparse_categorical_accuracy: 0.9252 - val_sparse_categorical_crossentropy: 0.2487 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 4s 99ms/step - loss: 0.2205 - sparse_categorical_accuracy: 0.9324 - sparse_categorical_crossentropy: 0.2205\n",
      "26/26 [==============================] - 4s 98ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 18s 158ms/step - loss: 1.3880 - sparse_categorical_accuracy: 0.6357 - sparse_categorical_crossentropy: 1.3880 - val_loss: 1.0906 - val_sparse_categorical_accuracy: 0.6725 - val_sparse_categorical_crossentropy: 1.0906 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.8824 - sparse_categorical_accuracy: 0.7304 - sparse_categorical_crossentropy: 0.8824 - val_loss: 0.7639 - val_sparse_categorical_accuracy: 0.7626 - val_sparse_categorical_crossentropy: 0.7639 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 15s 156ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.7864 - sparse_categorical_crossentropy: 0.6807 - val_loss: 0.6439 - val_sparse_categorical_accuracy: 0.7936 - val_sparse_categorical_crossentropy: 0.6439 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.5771 - sparse_categorical_accuracy: 0.8186 - sparse_categorical_crossentropy: 0.5771 - val_loss: 0.5206 - val_sparse_categorical_accuracy: 0.8270 - val_sparse_categorical_crossentropy: 0.5206 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.5050 - sparse_categorical_accuracy: 0.8414 - sparse_categorical_crossentropy: 0.5050 - val_loss: 0.5338 - val_sparse_categorical_accuracy: 0.8214 - val_sparse_categorical_crossentropy: 0.5338 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.4836 - sparse_categorical_accuracy: 0.8469 - sparse_categorical_crossentropy: 0.4836 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.7606 - val_sparse_categorical_crossentropy: 0.7306 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.4983 - sparse_categorical_accuracy: 0.8435 - sparse_categorical_crossentropy: 0.4983 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.8546 - val_sparse_categorical_crossentropy: 0.4575 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.4404 - sparse_categorical_accuracy: 0.8620 - sparse_categorical_crossentropy: 0.4404 - val_loss: 0.5427 - val_sparse_categorical_accuracy: 0.8271 - val_sparse_categorical_crossentropy: 0.5427 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8662 - sparse_categorical_crossentropy: 0.4327 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.8736 - val_sparse_categorical_crossentropy: 0.3917 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.3539 - sparse_categorical_accuracy: 0.8896 - sparse_categorical_crossentropy: 0.3539 - val_loss: 0.3906 - val_sparse_categorical_accuracy: 0.8793 - val_sparse_categorical_crossentropy: 0.3906 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.3946 - sparse_categorical_accuracy: 0.8767 - sparse_categorical_crossentropy: 0.3946 - val_loss: 0.3914 - val_sparse_categorical_accuracy: 0.8775 - val_sparse_categorical_crossentropy: 0.3914 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 15s 155ms/step - loss: 0.4790 - sparse_categorical_accuracy: 0.8510 - sparse_categorical_crossentropy: 0.4790 - val_loss: 0.4834 - val_sparse_categorical_accuracy: 0.8471 - val_sparse_categorical_crossentropy: 0.4834 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.4718 - sparse_categorical_accuracy: 0.8511 - sparse_categorical_crossentropy: 0.4718\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 15s 154ms/step - loss: 0.4718 - sparse_categorical_accuracy: 0.8511 - sparse_categorical_crossentropy: 0.4718 - val_loss: 0.5076 - val_sparse_categorical_accuracy: 0.8396 - val_sparse_categorical_crossentropy: 0.5076 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.4170 - sparse_categorical_accuracy: 0.8687 - sparse_categorical_crossentropy: 0.4170 - val_loss: 0.3802 - val_sparse_categorical_accuracy: 0.8809 - val_sparse_categorical_crossentropy: 0.3802 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.3446 - sparse_categorical_accuracy: 0.8930 - sparse_categorical_crossentropy: 0.3446 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8902 - val_sparse_categorical_crossentropy: 0.3494 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 15s 155ms/step - loss: 0.3055 - sparse_categorical_accuracy: 0.9048 - sparse_categorical_crossentropy: 0.3055 - val_loss: 0.3213 - val_sparse_categorical_accuracy: 0.8994 - val_sparse_categorical_crossentropy: 0.3213 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.2896 - sparse_categorical_accuracy: 0.9091 - sparse_categorical_crossentropy: 0.2896 - val_loss: 0.3210 - val_sparse_categorical_accuracy: 0.9013 - val_sparse_categorical_crossentropy: 0.3210 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 15s 155ms/step - loss: 0.2811 - sparse_categorical_accuracy: 0.9116 - sparse_categorical_crossentropy: 0.2811 - val_loss: 0.3203 - val_sparse_categorical_accuracy: 0.8982 - val_sparse_categorical_crossentropy: 0.3203 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 15s 156ms/step - loss: 0.2869 - sparse_categorical_accuracy: 0.9092 - sparse_categorical_crossentropy: 0.2869 - val_loss: 0.3126 - val_sparse_categorical_accuracy: 0.9007 - val_sparse_categorical_crossentropy: 0.3126 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.2417 - sparse_categorical_accuracy: 0.9244 - sparse_categorical_crossentropy: 0.2417 - val_loss: 0.3020 - val_sparse_categorical_accuracy: 0.9080 - val_sparse_categorical_crossentropy: 0.3020 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.2209 - sparse_categorical_accuracy: 0.9303 - sparse_categorical_crossentropy: 0.2209 - val_loss: 0.2647 - val_sparse_categorical_accuracy: 0.9175 - val_sparse_categorical_crossentropy: 0.2647 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.2021 - sparse_categorical_accuracy: 0.9360 - sparse_categorical_crossentropy: 0.2021 - val_loss: 0.2865 - val_sparse_categorical_accuracy: 0.9136 - val_sparse_categorical_crossentropy: 0.2865 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.1941 - sparse_categorical_accuracy: 0.9384 - sparse_categorical_crossentropy: 0.1941 - val_loss: 0.2929 - val_sparse_categorical_accuracy: 0.9097 - val_sparse_categorical_crossentropy: 0.2929 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2059 - sparse_categorical_accuracy: 0.9345 - sparse_categorical_crossentropy: 0.2059\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 15s 156ms/step - loss: 0.2059 - sparse_categorical_accuracy: 0.9345 - sparse_categorical_crossentropy: 0.2059 - val_loss: 0.2784 - val_sparse_categorical_accuracy: 0.9131 - val_sparse_categorical_crossentropy: 0.2784 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 15s 156ms/step - loss: 0.1751 - sparse_categorical_accuracy: 0.9442 - sparse_categorical_crossentropy: 0.1751 - val_loss: 0.2572 - val_sparse_categorical_accuracy: 0.9223 - val_sparse_categorical_crossentropy: 0.2572 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.1433 - sparse_categorical_accuracy: 0.9569 - sparse_categorical_crossentropy: 0.1433 - val_loss: 0.3015 - val_sparse_categorical_accuracy: 0.9096 - val_sparse_categorical_crossentropy: 0.3015 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.1757 - sparse_categorical_accuracy: 0.9450 - sparse_categorical_crossentropy: 0.1757 - val_loss: 0.2622 - val_sparse_categorical_accuracy: 0.9200 - val_sparse_categorical_crossentropy: 0.2622 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.1383 - sparse_categorical_accuracy: 0.9585 - sparse_categorical_crossentropy: 0.1383 - val_loss: 0.2563 - val_sparse_categorical_accuracy: 0.9228 - val_sparse_categorical_crossentropy: 0.2563 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.1285 - sparse_categorical_accuracy: 0.9617 - sparse_categorical_crossentropy: 0.1285 - val_loss: 0.2570 - val_sparse_categorical_accuracy: 0.9222 - val_sparse_categorical_crossentropy: 0.2570 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.1235 - sparse_categorical_accuracy: 0.9631 - sparse_categorical_crossentropy: 0.1235 - val_loss: 0.2577 - val_sparse_categorical_accuracy: 0.9251 - val_sparse_categorical_crossentropy: 0.2577 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9675 - sparse_categorical_crossentropy: 0.1099 - val_loss: 0.2488 - val_sparse_categorical_accuracy: 0.9275 - val_sparse_categorical_crossentropy: 0.2488 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.0984 - sparse_categorical_accuracy: 0.9714 - sparse_categorical_crossentropy: 0.0984 - val_loss: 0.2523 - val_sparse_categorical_accuracy: 0.9257 - val_sparse_categorical_crossentropy: 0.2523 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9740 - sparse_categorical_crossentropy: 0.0932 - val_loss: 0.2609 - val_sparse_categorical_accuracy: 0.9240 - val_sparse_categorical_crossentropy: 0.2609 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.0938 - sparse_categorical_accuracy: 0.9728 - sparse_categorical_crossentropy: 0.0938 - val_loss: 0.2494 - val_sparse_categorical_accuracy: 0.9303 - val_sparse_categorical_crossentropy: 0.2494 - lr: 0.0025\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9773 - sparse_categorical_crossentropy: 0.0809 - val_loss: 0.2499 - val_sparse_categorical_accuracy: 0.9297 - val_sparse_categorical_crossentropy: 0.2499 - lr: 0.0025\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 15s 156ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9773 - sparse_categorical_crossentropy: 0.0804 - val_loss: 0.2497 - val_sparse_categorical_accuracy: 0.9271 - val_sparse_categorical_crossentropy: 0.2497 - lr: 0.0025\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0741 - sparse_categorical_accuracy: 0.9799 - sparse_categorical_crossentropy: 0.0741\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9799 - sparse_categorical_crossentropy: 0.0741 - val_loss: 0.2540 - val_sparse_categorical_accuracy: 0.9291 - val_sparse_categorical_crossentropy: 0.2540 - lr: 0.0025\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.0629 - sparse_categorical_accuracy: 0.9841 - sparse_categorical_crossentropy: 0.0629 - val_loss: 0.2428 - val_sparse_categorical_accuracy: 0.9317 - val_sparse_categorical_crossentropy: 0.2428 - lr: 0.0012\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9881 - sparse_categorical_crossentropy: 0.0524 - val_loss: 0.2491 - val_sparse_categorical_accuracy: 0.9315 - val_sparse_categorical_crossentropy: 0.2491 - lr: 0.0012\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.0541 - sparse_categorical_accuracy: 0.9871 - sparse_categorical_crossentropy: 0.0541 - val_loss: 0.2483 - val_sparse_categorical_accuracy: 0.9309 - val_sparse_categorical_crossentropy: 0.2483 - lr: 0.0012\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9893 - sparse_categorical_crossentropy: 0.0474 - val_loss: 0.2497 - val_sparse_categorical_accuracy: 0.9321 - val_sparse_categorical_crossentropy: 0.2497 - lr: 0.0012\n",
      "Epoch 42/200\n",
      "29/90 [========>.....................] - ETA: 8s - loss: 0.0508 - sparse_categorical_accuracy: 0.9873 - sparse_categorical_crossentropy: 0.0508"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(5))\n",
    "for i in range(1, 3):\n",
    "    results = []\n",
    "    EXPERIMENT_NAME = f\"stacked_{i}_lstm\"\n",
    "    if os.path.exists(EXPERIMENT_NAME):\n",
    "        shutil.rmtree(EXPERIMENT_NAME)\n",
    "        os.mkdir(EXPERIMENT_NAME)\n",
    "    else:\n",
    "        os.mkdir(EXPERIMENT_NAME)\n",
    "\n",
    "    for seed in TRAINING_SEEDS:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        model = create_bidirectional_model(i)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "            loss=losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=MAX_EPOCHS,\n",
    "            validation_data=val_ds,\n",
    "            shuffle=True,\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "\n",
    "        with open(os.path.join(EXPERIMENT_NAME, f\"history_{seed}.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(history.history, file)\n",
    "\n",
    "        eval_results = model.evaluate(test_ds)\n",
    "\n",
    "        predictions = model.predict(test_ds)\n",
    "        with open(os.path.join(EXPERIMENT_NAME, f\"predictions_{seed}.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(predictions, file)\n",
    "\n",
    "        results += [{\n",
    "            'seed': seed,\n",
    "            'results': dict(zip(model.metrics_names, eval_results))\n",
    "        }]\n",
    "        gc.collect()\n",
    "\n",
    "    results_temp = pd.DataFrame(results)\n",
    "    results_df = pd.concat([results_temp.drop([\"results\"], axis=1), results_temp[\"results\"].apply(pd.Series)], axis=1)\n",
    "    results_df.to_csv(os.path.join(EXPERIMENT_NAME, 'results.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T00:42:25.366425Z",
     "end_time": "2023-04-23T01:51:37.322586Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T13:08:12.328441Z",
     "end_time": "2023-04-23T13:08:12.352441Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Disconnected with kernel. That's why restart."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:37:48.929593Z",
     "end_time": "2023-04-23T13:37:49.055593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 22s 151ms/step - loss: 1.4706 - sparse_categorical_accuracy: 0.6252 - sparse_categorical_crossentropy: 1.4706 - val_loss: 1.3146 - val_sparse_categorical_accuracy: 0.6321 - val_sparse_categorical_crossentropy: 1.3146 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 1.1493 - sparse_categorical_accuracy: 0.6632 - sparse_categorical_crossentropy: 1.1493 - val_loss: 0.9343 - val_sparse_categorical_accuracy: 0.7129 - val_sparse_categorical_crossentropy: 0.9343 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 13s 129ms/step - loss: 0.8016 - sparse_categorical_accuracy: 0.7493 - sparse_categorical_crossentropy: 0.8016 - val_loss: 0.7085 - val_sparse_categorical_accuracy: 0.7705 - val_sparse_categorical_crossentropy: 0.7085 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 13s 130ms/step - loss: 0.6252 - sparse_categorical_accuracy: 0.8020 - sparse_categorical_crossentropy: 0.6252 - val_loss: 0.6299 - val_sparse_categorical_accuracy: 0.7878 - val_sparse_categorical_crossentropy: 0.6299 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 14s 145ms/step - loss: 0.5740 - sparse_categorical_accuracy: 0.8194 - sparse_categorical_crossentropy: 0.5740 - val_loss: 0.6045 - val_sparse_categorical_accuracy: 0.8072 - val_sparse_categorical_crossentropy: 0.6045 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 13s 130ms/step - loss: 0.5115 - sparse_categorical_accuracy: 0.8379 - sparse_categorical_crossentropy: 0.5115 - val_loss: 0.4889 - val_sparse_categorical_accuracy: 0.8442 - val_sparse_categorical_crossentropy: 0.4889 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 13s 130ms/step - loss: 0.4553 - sparse_categorical_accuracy: 0.8594 - sparse_categorical_crossentropy: 0.4553 - val_loss: 0.4690 - val_sparse_categorical_accuracy: 0.8417 - val_sparse_categorical_crossentropy: 0.4690 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 13s 129ms/step - loss: 0.4070 - sparse_categorical_accuracy: 0.8719 - sparse_categorical_crossentropy: 0.4070 - val_loss: 0.4258 - val_sparse_categorical_accuracy: 0.8594 - val_sparse_categorical_crossentropy: 0.4258 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 12s 129ms/step - loss: 0.4327 - sparse_categorical_accuracy: 0.8633 - sparse_categorical_crossentropy: 0.4327 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8626 - val_sparse_categorical_crossentropy: 0.4267 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 15s 158ms/step - loss: 0.4044 - sparse_categorical_accuracy: 0.8724 - sparse_categorical_crossentropy: 0.4044 - val_loss: 0.4010 - val_sparse_categorical_accuracy: 0.8698 - val_sparse_categorical_crossentropy: 0.4010 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 13s 128ms/step - loss: 0.3560 - sparse_categorical_accuracy: 0.8878 - sparse_categorical_crossentropy: 0.3560 - val_loss: 0.3442 - val_sparse_categorical_accuracy: 0.8882 - val_sparse_categorical_crossentropy: 0.3442 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.3207 - sparse_categorical_accuracy: 0.8997 - sparse_categorical_crossentropy: 0.3207 - val_loss: 0.3248 - val_sparse_categorical_accuracy: 0.8976 - val_sparse_categorical_crossentropy: 0.3248 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.3097 - sparse_categorical_accuracy: 0.9024 - sparse_categorical_crossentropy: 0.3097 - val_loss: 0.3112 - val_sparse_categorical_accuracy: 0.9013 - val_sparse_categorical_crossentropy: 0.3112 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2936 - sparse_categorical_accuracy: 0.9071 - sparse_categorical_crossentropy: 0.2936 - val_loss: 0.2796 - val_sparse_categorical_accuracy: 0.9120 - val_sparse_categorical_crossentropy: 0.2796 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.2812 - sparse_categorical_accuracy: 0.9121 - sparse_categorical_crossentropy: 0.2812 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.9013 - val_sparse_categorical_crossentropy: 0.3096 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 0.3038 - sparse_categorical_accuracy: 0.9041 - sparse_categorical_crossentropy: 0.3038 - val_loss: 0.3186 - val_sparse_categorical_accuracy: 0.9011 - val_sparse_categorical_crossentropy: 0.3186 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.3071 - sparse_categorical_accuracy: 0.9025 - sparse_categorical_crossentropy: 0.3071\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.3072 - sparse_categorical_accuracy: 0.9024 - sparse_categorical_crossentropy: 0.3072 - val_loss: 0.3167 - val_sparse_categorical_accuracy: 0.9016 - val_sparse_categorical_crossentropy: 0.3167 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 12s 127ms/step - loss: 0.2570 - sparse_categorical_accuracy: 0.9189 - sparse_categorical_crossentropy: 0.2570 - val_loss: 0.2526 - val_sparse_categorical_accuracy: 0.9215 - val_sparse_categorical_crossentropy: 0.2526 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.2007 - sparse_categorical_accuracy: 0.9377 - sparse_categorical_crossentropy: 0.2007 - val_loss: 0.2293 - val_sparse_categorical_accuracy: 0.9312 - val_sparse_categorical_crossentropy: 0.2293 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 12s 127ms/step - loss: 0.1831 - sparse_categorical_accuracy: 0.9425 - sparse_categorical_crossentropy: 0.1831 - val_loss: 0.2377 - val_sparse_categorical_accuracy: 0.9248 - val_sparse_categorical_crossentropy: 0.2377 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9469 - sparse_categorical_crossentropy: 0.1676 - val_loss: 0.2319 - val_sparse_categorical_accuracy: 0.9309 - val_sparse_categorical_crossentropy: 0.2319 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1514 - sparse_categorical_accuracy: 0.9528 - sparse_categorical_crossentropy: 0.1514\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9527 - sparse_categorical_crossentropy: 0.1514 - val_loss: 0.2279 - val_sparse_categorical_accuracy: 0.9278 - val_sparse_categorical_crossentropy: 0.2279 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.1355 - sparse_categorical_accuracy: 0.9577 - sparse_categorical_crossentropy: 0.1355 - val_loss: 0.2052 - val_sparse_categorical_accuracy: 0.9361 - val_sparse_categorical_crossentropy: 0.2052 - lr: 0.0025\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.1143 - sparse_categorical_accuracy: 0.9655 - sparse_categorical_crossentropy: 0.1143 - val_loss: 0.2304 - val_sparse_categorical_accuracy: 0.9285 - val_sparse_categorical_crossentropy: 0.2304 - lr: 0.0025\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 13s 131ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9526 - sparse_categorical_crossentropy: 0.1494 - val_loss: 0.2123 - val_sparse_categorical_accuracy: 0.9347 - val_sparse_categorical_crossentropy: 0.2123 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1111 - sparse_categorical_accuracy: 0.9661 - sparse_categorical_crossentropy: 0.1111\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 12s 128ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9661 - sparse_categorical_crossentropy: 0.1111 - val_loss: 0.2114 - val_sparse_categorical_accuracy: 0.9357 - val_sparse_categorical_crossentropy: 0.2114 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 12s 127ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9727 - sparse_categorical_crossentropy: 0.0916 - val_loss: 0.2068 - val_sparse_categorical_accuracy: 0.9381 - val_sparse_categorical_crossentropy: 0.2068 - lr: 0.0012\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9761 - sparse_categorical_crossentropy: 0.0831 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9369 - val_sparse_categorical_crossentropy: 0.2099 - lr: 0.0012\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0867 - sparse_categorical_accuracy: 0.9744 - sparse_categorical_crossentropy: 0.0867 - val_loss: 0.2077 - val_sparse_categorical_accuracy: 0.9384 - val_sparse_categorical_crossentropy: 0.2077 - lr: 0.0012\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9786 - sparse_categorical_crossentropy: 0.0754 - val_loss: 0.2033 - val_sparse_categorical_accuracy: 0.9389 - val_sparse_categorical_crossentropy: 0.2033 - lr: 0.0012\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9815 - sparse_categorical_crossentropy: 0.0691 - val_loss: 0.2064 - val_sparse_categorical_accuracy: 0.9401 - val_sparse_categorical_crossentropy: 0.2064 - lr: 0.0012\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 0.0632 - sparse_categorical_accuracy: 0.9835 - sparse_categorical_crossentropy: 0.0632 - val_loss: 0.2087 - val_sparse_categorical_accuracy: 0.9401 - val_sparse_categorical_crossentropy: 0.2087 - lr: 0.0012\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 12s 126ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9843 - sparse_categorical_crossentropy: 0.0587 - val_loss: 0.2083 - val_sparse_categorical_accuracy: 0.9420 - val_sparse_categorical_crossentropy: 0.2083 - lr: 0.0012\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 12s 122ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9856 - sparse_categorical_crossentropy: 0.0552 - val_loss: 0.2085 - val_sparse_categorical_accuracy: 0.9404 - val_sparse_categorical_crossentropy: 0.2085 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 12s 123ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9872 - sparse_categorical_crossentropy: 0.0514 - val_loss: 0.2106 - val_sparse_categorical_accuracy: 0.9394 - val_sparse_categorical_crossentropy: 0.2106 - lr: 0.0012\n",
      "Epoch 36/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0658 - sparse_categorical_accuracy: 0.9808 - sparse_categorical_crossentropy: 0.0658\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0658 - sparse_categorical_accuracy: 0.9808 - sparse_categorical_crossentropy: 0.0658 - val_loss: 0.2072 - val_sparse_categorical_accuracy: 0.9417 - val_sparse_categorical_crossentropy: 0.2072 - lr: 0.0012\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9878 - sparse_categorical_crossentropy: 0.0482 - val_loss: 0.2120 - val_sparse_categorical_accuracy: 0.9392 - val_sparse_categorical_crossentropy: 0.2120 - lr: 6.2500e-04\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 12s 124ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9901 - sparse_categorical_crossentropy: 0.0429 - val_loss: 0.2063 - val_sparse_categorical_accuracy: 0.9409 - val_sparse_categorical_crossentropy: 0.2063 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 3s 89ms/step - loss: 0.2303 - sparse_categorical_accuracy: 0.9367 - sparse_categorical_crossentropy: 0.2303\n",
      "26/26 [==============================] - 4s 78ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 19s 146ms/step - loss: 1.5299 - sparse_categorical_accuracy: 0.6247 - sparse_categorical_crossentropy: 1.5299 - val_loss: 1.4894 - val_sparse_categorical_accuracy: 0.6329 - val_sparse_categorical_crossentropy: 1.4894 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 1.3623 - sparse_categorical_accuracy: 0.6342 - sparse_categorical_crossentropy: 1.3623 - val_loss: 1.6469 - val_sparse_categorical_accuracy: 0.4990 - val_sparse_categorical_crossentropy: 1.6469 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 13s 137ms/step - loss: 1.0683 - sparse_categorical_accuracy: 0.6674 - sparse_categorical_crossentropy: 1.0683 - val_loss: 1.1998 - val_sparse_categorical_accuracy: 0.5593 - val_sparse_categorical_crossentropy: 1.1998 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.8076 - sparse_categorical_accuracy: 0.7392 - sparse_categorical_crossentropy: 0.8076 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.7659 - val_sparse_categorical_crossentropy: 0.6888 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 13s 140ms/step - loss: 0.6612 - sparse_categorical_accuracy: 0.7880 - sparse_categorical_crossentropy: 0.6612 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.7577 - val_sparse_categorical_crossentropy: 0.7225 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.5809 - sparse_categorical_accuracy: 0.8163 - sparse_categorical_crossentropy: 0.5809 - val_loss: 0.5479 - val_sparse_categorical_accuracy: 0.8256 - val_sparse_categorical_crossentropy: 0.5479 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.5432 - sparse_categorical_accuracy: 0.8290 - sparse_categorical_crossentropy: 0.5432 - val_loss: 0.5004 - val_sparse_categorical_accuracy: 0.8409 - val_sparse_categorical_crossentropy: 0.5004 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.4942 - sparse_categorical_accuracy: 0.8458 - sparse_categorical_crossentropy: 0.4942 - val_loss: 0.4875 - val_sparse_categorical_accuracy: 0.8397 - val_sparse_categorical_crossentropy: 0.4875 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.4483 - sparse_categorical_accuracy: 0.8595 - sparse_categorical_crossentropy: 0.4483 - val_loss: 0.4399 - val_sparse_categorical_accuracy: 0.8557 - val_sparse_categorical_crossentropy: 0.4399 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.3974 - sparse_categorical_accuracy: 0.8749 - sparse_categorical_crossentropy: 0.3974 - val_loss: 0.4201 - val_sparse_categorical_accuracy: 0.8706 - val_sparse_categorical_crossentropy: 0.4201 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 13s 140ms/step - loss: 0.3644 - sparse_categorical_accuracy: 0.8845 - sparse_categorical_crossentropy: 0.3644 - val_loss: 0.3761 - val_sparse_categorical_accuracy: 0.8786 - val_sparse_categorical_crossentropy: 0.3761 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.3455 - sparse_categorical_accuracy: 0.8915 - sparse_categorical_crossentropy: 0.3455 - val_loss: 0.3195 - val_sparse_categorical_accuracy: 0.8999 - val_sparse_categorical_crossentropy: 0.3195 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.3243 - sparse_categorical_accuracy: 0.8978 - sparse_categorical_crossentropy: 0.3243 - val_loss: 0.3409 - val_sparse_categorical_accuracy: 0.8907 - val_sparse_categorical_crossentropy: 0.3409 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.3130 - sparse_categorical_accuracy: 0.8999 - sparse_categorical_crossentropy: 0.3130 - val_loss: 0.3753 - val_sparse_categorical_accuracy: 0.8762 - val_sparse_categorical_crossentropy: 0.3753 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.3159 - sparse_categorical_accuracy: 0.8985 - sparse_categorical_crossentropy: 0.3159\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.3158 - sparse_categorical_accuracy: 0.8985 - sparse_categorical_crossentropy: 0.3158 - val_loss: 0.3277 - val_sparse_categorical_accuracy: 0.8961 - val_sparse_categorical_crossentropy: 0.3277 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.2467 - sparse_categorical_accuracy: 0.9214 - sparse_categorical_crossentropy: 0.2467 - val_loss: 0.2671 - val_sparse_categorical_accuracy: 0.9133 - val_sparse_categorical_crossentropy: 0.2671 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 13s 137ms/step - loss: 0.2123 - sparse_categorical_accuracy: 0.9334 - sparse_categorical_crossentropy: 0.2123 - val_loss: 0.2526 - val_sparse_categorical_accuracy: 0.9203 - val_sparse_categorical_crossentropy: 0.2526 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.1937 - sparse_categorical_accuracy: 0.9382 - sparse_categorical_crossentropy: 0.1937 - val_loss: 0.2680 - val_sparse_categorical_accuracy: 0.9172 - val_sparse_categorical_crossentropy: 0.2680 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 14s 139ms/step - loss: 0.1805 - sparse_categorical_accuracy: 0.9427 - sparse_categorical_crossentropy: 0.1805 - val_loss: 0.2459 - val_sparse_categorical_accuracy: 0.9205 - val_sparse_categorical_crossentropy: 0.2459 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.1630 - sparse_categorical_accuracy: 0.9488 - sparse_categorical_crossentropy: 0.1630 - val_loss: 0.2560 - val_sparse_categorical_accuracy: 0.9146 - val_sparse_categorical_crossentropy: 0.2560 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.1815 - sparse_categorical_accuracy: 0.9426 - sparse_categorical_crossentropy: 0.1815 - val_loss: 0.2431 - val_sparse_categorical_accuracy: 0.9218 - val_sparse_categorical_crossentropy: 0.2431 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9493 - sparse_categorical_crossentropy: 0.1602 - val_loss: 0.2386 - val_sparse_categorical_accuracy: 0.9266 - val_sparse_categorical_crossentropy: 0.2386 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.1626 - sparse_categorical_accuracy: 0.9479 - sparse_categorical_crossentropy: 0.1626 - val_loss: 0.2735 - val_sparse_categorical_accuracy: 0.9157 - val_sparse_categorical_crossentropy: 0.2735 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 13s 138ms/step - loss: 0.1694 - sparse_categorical_accuracy: 0.9462 - sparse_categorical_crossentropy: 0.1694 - val_loss: 0.2370 - val_sparse_categorical_accuracy: 0.9260 - val_sparse_categorical_crossentropy: 0.2370 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9512 - sparse_categorical_crossentropy: 0.1508 - val_loss: 0.2442 - val_sparse_categorical_accuracy: 0.9285 - val_sparse_categorical_crossentropy: 0.2442 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 14s 140ms/step - loss: 0.1457 - sparse_categorical_accuracy: 0.9534 - sparse_categorical_crossentropy: 0.1457 - val_loss: 0.2472 - val_sparse_categorical_accuracy: 0.9203 - val_sparse_categorical_crossentropy: 0.2472 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9509 - sparse_categorical_crossentropy: 0.1521 - val_loss: 0.2607 - val_sparse_categorical_accuracy: 0.9246 - val_sparse_categorical_crossentropy: 0.2607 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.1574 - sparse_categorical_accuracy: 0.9499 - sparse_categorical_crossentropy: 0.1574 - val_loss: 0.2547 - val_sparse_categorical_accuracy: 0.9291 - val_sparse_categorical_crossentropy: 0.2547 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9611 - sparse_categorical_crossentropy: 0.1211 - val_loss: 0.2232 - val_sparse_categorical_accuracy: 0.9347 - val_sparse_categorical_crossentropy: 0.2232 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.0972 - sparse_categorical_accuracy: 0.9697 - sparse_categorical_crossentropy: 0.0972 - val_loss: 0.2286 - val_sparse_categorical_accuracy: 0.9326 - val_sparse_categorical_crossentropy: 0.2286 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.0931 - sparse_categorical_accuracy: 0.9710 - sparse_categorical_crossentropy: 0.0931 - val_loss: 0.2329 - val_sparse_categorical_accuracy: 0.9304 - val_sparse_categorical_crossentropy: 0.2329 - lr: 0.0050\n",
      "Epoch 32/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0973 - sparse_categorical_accuracy: 0.9692 - sparse_categorical_crossentropy: 0.0973\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0973 - sparse_categorical_accuracy: 0.9692 - sparse_categorical_crossentropy: 0.0973 - val_loss: 0.2250 - val_sparse_categorical_accuracy: 0.9344 - val_sparse_categorical_crossentropy: 0.2250 - lr: 0.0050\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9780 - sparse_categorical_crossentropy: 0.0730 - val_loss: 0.2196 - val_sparse_categorical_accuracy: 0.9375 - val_sparse_categorical_crossentropy: 0.2196 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9844 - sparse_categorical_crossentropy: 0.0571 - val_loss: 0.2267 - val_sparse_categorical_accuracy: 0.9358 - val_sparse_categorical_crossentropy: 0.2267 - lr: 0.0025\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9852 - sparse_categorical_crossentropy: 0.0546 - val_loss: 0.2297 - val_sparse_categorical_accuracy: 0.9361 - val_sparse_categorical_crossentropy: 0.2297 - lr: 0.0025\n",
      "Epoch 36/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0505 - sparse_categorical_accuracy: 0.9862 - sparse_categorical_crossentropy: 0.0505\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 13s 137ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9862 - sparse_categorical_crossentropy: 0.0506 - val_loss: 0.2220 - val_sparse_categorical_accuracy: 0.9346 - val_sparse_categorical_crossentropy: 0.2220 - lr: 0.0025\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 13s 139ms/step - loss: 0.0407 - sparse_categorical_accuracy: 0.9895 - sparse_categorical_crossentropy: 0.0407 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9381 - val_sparse_categorical_crossentropy: 0.2271 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 14s 145ms/step - loss: 0.0343 - sparse_categorical_accuracy: 0.9920 - sparse_categorical_crossentropy: 0.0343 - val_loss: 0.2332 - val_sparse_categorical_accuracy: 0.9370 - val_sparse_categorical_crossentropy: 0.2332 - lr: 0.0012\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 14s 145ms/step - loss: 0.0319 - sparse_categorical_accuracy: 0.9928 - sparse_categorical_crossentropy: 0.0319 - val_loss: 0.2350 - val_sparse_categorical_accuracy: 0.9358 - val_sparse_categorical_crossentropy: 0.2350 - lr: 0.0012\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 14s 146ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9934 - sparse_categorical_crossentropy: 0.0296 - val_loss: 0.2320 - val_sparse_categorical_accuracy: 0.9400 - val_sparse_categorical_crossentropy: 0.2320 - lr: 0.0012\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0311 - sparse_categorical_accuracy: 0.9925 - sparse_categorical_crossentropy: 0.0311 - val_loss: 0.2362 - val_sparse_categorical_accuracy: 0.9351 - val_sparse_categorical_crossentropy: 0.2362 - lr: 0.0012\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0265 - sparse_categorical_accuracy: 0.9944 - sparse_categorical_crossentropy: 0.0265 - val_loss: 0.2334 - val_sparse_categorical_accuracy: 0.9374 - val_sparse_categorical_crossentropy: 0.2334 - lr: 0.0012\n",
      "Epoch 43/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0256 - sparse_categorical_accuracy: 0.9948 - sparse_categorical_crossentropy: 0.0256\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0256 - sparse_categorical_accuracy: 0.9948 - sparse_categorical_crossentropy: 0.0256 - val_loss: 0.2338 - val_sparse_categorical_accuracy: 0.9387 - val_sparse_categorical_crossentropy: 0.2338 - lr: 0.0012\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 14s 143ms/step - loss: 0.0228 - sparse_categorical_accuracy: 0.9953 - sparse_categorical_crossentropy: 0.0228 - val_loss: 0.2329 - val_sparse_categorical_accuracy: 0.9403 - val_sparse_categorical_crossentropy: 0.2329 - lr: 6.2500e-04\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9958 - sparse_categorical_crossentropy: 0.0219 - val_loss: 0.2359 - val_sparse_categorical_accuracy: 0.9398 - val_sparse_categorical_crossentropy: 0.2359 - lr: 6.2500e-04\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 14s 141ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9959 - sparse_categorical_crossentropy: 0.0210 - val_loss: 0.2391 - val_sparse_categorical_accuracy: 0.9387 - val_sparse_categorical_crossentropy: 0.2391 - lr: 6.2500e-04\n",
      "Epoch 47/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0221 - sparse_categorical_accuracy: 0.9955 - sparse_categorical_crossentropy: 0.0221\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9955 - sparse_categorical_crossentropy: 0.0221 - val_loss: 0.2411 - val_sparse_categorical_accuracy: 0.9387 - val_sparse_categorical_crossentropy: 0.2411 - lr: 6.2500e-04\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 14s 144ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9960 - sparse_categorical_crossentropy: 0.0202 - val_loss: 0.2398 - val_sparse_categorical_accuracy: 0.9387 - val_sparse_categorical_crossentropy: 0.2398 - lr: 3.1250e-04\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 14s 142ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9959 - sparse_categorical_crossentropy: 0.0198 - val_loss: 0.2421 - val_sparse_categorical_accuracy: 0.9398 - val_sparse_categorical_crossentropy: 0.2421 - lr: 3.1250e-04\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.2520 - sparse_categorical_accuracy: 0.9393 - sparse_categorical_crossentropy: 0.2520\n",
      "26/26 [==============================] - 5s 96ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 20s 160ms/step - loss: 1.4948 - sparse_categorical_accuracy: 0.6275 - sparse_categorical_crossentropy: 1.4948 - val_loss: 1.3265 - val_sparse_categorical_accuracy: 0.6329 - val_sparse_categorical_crossentropy: 1.3265 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 1.1457 - sparse_categorical_accuracy: 0.6658 - sparse_categorical_crossentropy: 1.1457 - val_loss: 1.0005 - val_sparse_categorical_accuracy: 0.6945 - val_sparse_categorical_crossentropy: 1.0005 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 16s 163ms/step - loss: 0.8375 - sparse_categorical_accuracy: 0.7355 - sparse_categorical_crossentropy: 0.8375 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.7569 - val_sparse_categorical_crossentropy: 0.7495 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.7865 - sparse_categorical_crossentropy: 0.6738 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.7717 - val_sparse_categorical_crossentropy: 0.6905 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.6232 - sparse_categorical_accuracy: 0.8046 - sparse_categorical_crossentropy: 0.6232 - val_loss: 0.5245 - val_sparse_categorical_accuracy: 0.8354 - val_sparse_categorical_crossentropy: 0.5245 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 16s 160ms/step - loss: 0.5387 - sparse_categorical_accuracy: 0.8298 - sparse_categorical_crossentropy: 0.5387 - val_loss: 0.5474 - val_sparse_categorical_accuracy: 0.8237 - val_sparse_categorical_crossentropy: 0.5474 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 15s 159ms/step - loss: 0.5215 - sparse_categorical_accuracy: 0.8364 - sparse_categorical_crossentropy: 0.5215 - val_loss: 0.4464 - val_sparse_categorical_accuracy: 0.8604 - val_sparse_categorical_crossentropy: 0.4464 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 16s 166ms/step - loss: 0.4472 - sparse_categorical_accuracy: 0.8588 - sparse_categorical_crossentropy: 0.4472 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8537 - val_sparse_categorical_crossentropy: 0.4569 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.4267 - sparse_categorical_accuracy: 0.8660 - sparse_categorical_crossentropy: 0.4267 - val_loss: 0.3970 - val_sparse_categorical_accuracy: 0.8739 - val_sparse_categorical_crossentropy: 0.3970 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.3983 - sparse_categorical_accuracy: 0.8756 - sparse_categorical_crossentropy: 0.3983 - val_loss: 0.3702 - val_sparse_categorical_accuracy: 0.8813 - val_sparse_categorical_crossentropy: 0.3702 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.3800 - sparse_categorical_accuracy: 0.8786 - sparse_categorical_crossentropy: 0.3800 - val_loss: 0.4026 - val_sparse_categorical_accuracy: 0.8641 - val_sparse_categorical_crossentropy: 0.4026 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.3520 - sparse_categorical_accuracy: 0.8873 - sparse_categorical_crossentropy: 0.3520 - val_loss: 0.3528 - val_sparse_categorical_accuracy: 0.8879 - val_sparse_categorical_crossentropy: 0.3528 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.3393 - sparse_categorical_accuracy: 0.8935 - sparse_categorical_crossentropy: 0.3393 - val_loss: 0.3764 - val_sparse_categorical_accuracy: 0.8804 - val_sparse_categorical_crossentropy: 0.3764 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 15s 161ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.8917 - sparse_categorical_crossentropy: 0.3401 - val_loss: 0.3434 - val_sparse_categorical_accuracy: 0.8893 - val_sparse_categorical_crossentropy: 0.3434 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 16s 166ms/step - loss: 0.3422 - sparse_categorical_accuracy: 0.8911 - sparse_categorical_crossentropy: 0.3422 - val_loss: 0.3564 - val_sparse_categorical_accuracy: 0.8809 - val_sparse_categorical_crossentropy: 0.3564 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.3367 - sparse_categorical_accuracy: 0.8928 - sparse_categorical_crossentropy: 0.3367 - val_loss: 0.3321 - val_sparse_categorical_accuracy: 0.8919 - val_sparse_categorical_crossentropy: 0.3321 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 16s 163ms/step - loss: 0.3204 - sparse_categorical_accuracy: 0.8990 - sparse_categorical_crossentropy: 0.3204 - val_loss: 0.3830 - val_sparse_categorical_accuracy: 0.8781 - val_sparse_categorical_crossentropy: 0.3830 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.3145 - sparse_categorical_accuracy: 0.9000 - sparse_categorical_crossentropy: 0.3145 - val_loss: 0.3115 - val_sparse_categorical_accuracy: 0.9007 - val_sparse_categorical_crossentropy: 0.3115 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.2873 - sparse_categorical_accuracy: 0.9087 - sparse_categorical_crossentropy: 0.2873 - val_loss: 0.3181 - val_sparse_categorical_accuracy: 0.9034 - val_sparse_categorical_crossentropy: 0.3181 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.2793 - sparse_categorical_accuracy: 0.9137 - sparse_categorical_crossentropy: 0.2793 - val_loss: 0.3120 - val_sparse_categorical_accuracy: 0.9002 - val_sparse_categorical_crossentropy: 0.3120 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 15s 160ms/step - loss: 0.2994 - sparse_categorical_accuracy: 0.9059 - sparse_categorical_crossentropy: 0.2994 - val_loss: 0.3470 - val_sparse_categorical_accuracy: 0.8907 - val_sparse_categorical_crossentropy: 0.3470 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 15s 160ms/step - loss: 0.2632 - sparse_categorical_accuracy: 0.9170 - sparse_categorical_crossentropy: 0.2632 - val_loss: 0.2945 - val_sparse_categorical_accuracy: 0.9073 - val_sparse_categorical_crossentropy: 0.2945 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.9236 - sparse_categorical_crossentropy: 0.2389 - val_loss: 0.2675 - val_sparse_categorical_accuracy: 0.9154 - val_sparse_categorical_crossentropy: 0.2675 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 15s 157ms/step - loss: 0.2291 - sparse_categorical_accuracy: 0.9268 - sparse_categorical_crossentropy: 0.2291 - val_loss: 0.2851 - val_sparse_categorical_accuracy: 0.9108 - val_sparse_categorical_crossentropy: 0.2851 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.2450 - sparse_categorical_accuracy: 0.9205 - sparse_categorical_crossentropy: 0.2450 - val_loss: 0.2824 - val_sparse_categorical_accuracy: 0.9113 - val_sparse_categorical_crossentropy: 0.2824 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2481 - sparse_categorical_accuracy: 0.9209 - sparse_categorical_crossentropy: 0.2481\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.2481 - sparse_categorical_accuracy: 0.9209 - sparse_categorical_crossentropy: 0.2481 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.9039 - val_sparse_categorical_crossentropy: 0.2964 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.2089 - sparse_categorical_accuracy: 0.9339 - sparse_categorical_crossentropy: 0.2089 - val_loss: 0.2601 - val_sparse_categorical_accuracy: 0.9169 - val_sparse_categorical_crossentropy: 0.2601 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.1879 - sparse_categorical_accuracy: 0.9410 - sparse_categorical_crossentropy: 0.1879 - val_loss: 0.2417 - val_sparse_categorical_accuracy: 0.9240 - val_sparse_categorical_crossentropy: 0.2417 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.1601 - sparse_categorical_accuracy: 0.9490 - sparse_categorical_crossentropy: 0.1601 - val_loss: 0.2491 - val_sparse_categorical_accuracy: 0.9232 - val_sparse_categorical_crossentropy: 0.2491 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9525 - sparse_categorical_crossentropy: 0.1523 - val_loss: 0.2240 - val_sparse_categorical_accuracy: 0.9303 - val_sparse_categorical_crossentropy: 0.2240 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.1443 - sparse_categorical_accuracy: 0.9544 - sparse_categorical_crossentropy: 0.1443 - val_loss: 0.2307 - val_sparse_categorical_accuracy: 0.9306 - val_sparse_categorical_crossentropy: 0.2307 - lr: 0.0050\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9576 - sparse_categorical_crossentropy: 0.1350 - val_loss: 0.2301 - val_sparse_categorical_accuracy: 0.9304 - val_sparse_categorical_crossentropy: 0.2301 - lr: 0.0050\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.1340 - sparse_categorical_accuracy: 0.9574 - sparse_categorical_crossentropy: 0.1340 - val_loss: 0.2369 - val_sparse_categorical_accuracy: 0.9318 - val_sparse_categorical_crossentropy: 0.2369 - lr: 0.0050\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.1299 - sparse_categorical_accuracy: 0.9578 - sparse_categorical_crossentropy: 0.1299 - val_loss: 0.2265 - val_sparse_categorical_accuracy: 0.9303 - val_sparse_categorical_crossentropy: 0.2265 - lr: 0.0050\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.1026 - sparse_categorical_accuracy: 0.9686 - sparse_categorical_crossentropy: 0.1026 - val_loss: 0.2278 - val_sparse_categorical_accuracy: 0.9311 - val_sparse_categorical_crossentropy: 0.2278 - lr: 0.0050\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.1226 - sparse_categorical_accuracy: 0.9610 - sparse_categorical_crossentropy: 0.1226 - val_loss: 0.2266 - val_sparse_categorical_accuracy: 0.9321 - val_sparse_categorical_crossentropy: 0.2266 - lr: 0.0050\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9694 - sparse_categorical_crossentropy: 0.0979 - val_loss: 0.2162 - val_sparse_categorical_accuracy: 0.9352 - val_sparse_categorical_crossentropy: 0.2162 - lr: 0.0050\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.1024 - sparse_categorical_accuracy: 0.9676 - sparse_categorical_crossentropy: 0.1024 - val_loss: 0.2711 - val_sparse_categorical_accuracy: 0.9225 - val_sparse_categorical_crossentropy: 0.2711 - lr: 0.0050\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.1174 - sparse_categorical_accuracy: 0.9624 - sparse_categorical_crossentropy: 0.1174 - val_loss: 0.2567 - val_sparse_categorical_accuracy: 0.9269 - val_sparse_categorical_crossentropy: 0.2567 - lr: 0.0050\n",
      "Epoch 40/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1114 - sparse_categorical_accuracy: 0.9642 - sparse_categorical_crossentropy: 0.1114\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 16s 166ms/step - loss: 0.1114 - sparse_categorical_accuracy: 0.9642 - sparse_categorical_crossentropy: 0.1114 - val_loss: 0.2284 - val_sparse_categorical_accuracy: 0.9308 - val_sparse_categorical_crossentropy: 0.2284 - lr: 0.0050\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 16s 163ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9774 - sparse_categorical_crossentropy: 0.0765 - val_loss: 0.2135 - val_sparse_categorical_accuracy: 0.9367 - val_sparse_categorical_crossentropy: 0.2135 - lr: 0.0025\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9809 - sparse_categorical_crossentropy: 0.0657 - val_loss: 0.2168 - val_sparse_categorical_accuracy: 0.9390 - val_sparse_categorical_crossentropy: 0.2168 - lr: 0.0025\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9856 - sparse_categorical_crossentropy: 0.0543 - val_loss: 0.2148 - val_sparse_categorical_accuracy: 0.9409 - val_sparse_categorical_crossentropy: 0.2148 - lr: 0.0025\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 16s 163ms/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9889 - sparse_categorical_crossentropy: 0.0457 - val_loss: 0.2212 - val_sparse_categorical_accuracy: 0.9364 - val_sparse_categorical_crossentropy: 0.2212 - lr: 0.0025\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9896 - sparse_categorical_crossentropy: 0.0442 - val_loss: 0.2262 - val_sparse_categorical_accuracy: 0.9374 - val_sparse_categorical_crossentropy: 0.2262 - lr: 0.0025\n",
      "Epoch 46/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0374 - sparse_categorical_accuracy: 0.9916 - sparse_categorical_crossentropy: 0.0374\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 16s 161ms/step - loss: 0.0375 - sparse_categorical_accuracy: 0.9916 - sparse_categorical_crossentropy: 0.0375 - val_loss: 0.2291 - val_sparse_categorical_accuracy: 0.9389 - val_sparse_categorical_crossentropy: 0.2291 - lr: 0.0025\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.0382 - sparse_categorical_accuracy: 0.9909 - sparse_categorical_crossentropy: 0.0382 - val_loss: 0.2217 - val_sparse_categorical_accuracy: 0.9395 - val_sparse_categorical_crossentropy: 0.2217 - lr: 0.0012\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 16s 162ms/step - loss: 0.0301 - sparse_categorical_accuracy: 0.9940 - sparse_categorical_crossentropy: 0.0301 - val_loss: 0.2214 - val_sparse_categorical_accuracy: 0.9400 - val_sparse_categorical_crossentropy: 0.2214 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 112ms/step - loss: 0.2066 - sparse_categorical_accuracy: 0.9426 - sparse_categorical_crossentropy: 0.2066\n",
      "26/26 [==============================] - 5s 106ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 20s 166ms/step - loss: 1.5169 - sparse_categorical_accuracy: 0.6236 - sparse_categorical_crossentropy: 1.5169 - val_loss: 1.4262 - val_sparse_categorical_accuracy: 0.6323 - val_sparse_categorical_crossentropy: 1.4262 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 16s 166ms/step - loss: 1.1769 - sparse_categorical_accuracy: 0.6608 - sparse_categorical_crossentropy: 1.1769 - val_loss: 1.0218 - val_sparse_categorical_accuracy: 0.6747 - val_sparse_categorical_crossentropy: 1.0218 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.8395 - sparse_categorical_accuracy: 0.7345 - sparse_categorical_crossentropy: 0.8395 - val_loss: 0.7786 - val_sparse_categorical_accuracy: 0.7477 - val_sparse_categorical_crossentropy: 0.7786 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.6886 - sparse_categorical_accuracy: 0.7820 - sparse_categorical_crossentropy: 0.6886 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.7778 - val_sparse_categorical_crossentropy: 0.6756 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 16s 163ms/step - loss: 0.5995 - sparse_categorical_accuracy: 0.8106 - sparse_categorical_crossentropy: 0.5995 - val_loss: 0.5938 - val_sparse_categorical_accuracy: 0.8081 - val_sparse_categorical_crossentropy: 0.5938 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 16s 163ms/step - loss: 0.5246 - sparse_categorical_accuracy: 0.8328 - sparse_categorical_crossentropy: 0.5246 - val_loss: 0.4867 - val_sparse_categorical_accuracy: 0.8480 - val_sparse_categorical_crossentropy: 0.4867 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 16s 163ms/step - loss: 0.4660 - sparse_categorical_accuracy: 0.8520 - sparse_categorical_crossentropy: 0.4660 - val_loss: 0.4729 - val_sparse_categorical_accuracy: 0.8480 - val_sparse_categorical_crossentropy: 0.4729 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.8539 - sparse_categorical_crossentropy: 0.4670 - val_loss: 0.4345 - val_sparse_categorical_accuracy: 0.8635 - val_sparse_categorical_crossentropy: 0.4345 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.4310 - sparse_categorical_accuracy: 0.8646 - sparse_categorical_crossentropy: 0.4310 - val_loss: 0.4164 - val_sparse_categorical_accuracy: 0.8623 - val_sparse_categorical_crossentropy: 0.4164 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.4056 - sparse_categorical_accuracy: 0.8734 - sparse_categorical_crossentropy: 0.4056 - val_loss: 0.4453 - val_sparse_categorical_accuracy: 0.8538 - val_sparse_categorical_crossentropy: 0.4453 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 16s 166ms/step - loss: 0.3746 - sparse_categorical_accuracy: 0.8841 - sparse_categorical_crossentropy: 0.3746 - val_loss: 0.3680 - val_sparse_categorical_accuracy: 0.8838 - val_sparse_categorical_crossentropy: 0.3680 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 16s 165ms/step - loss: 0.3337 - sparse_categorical_accuracy: 0.8948 - sparse_categorical_crossentropy: 0.3337 - val_loss: 0.3785 - val_sparse_categorical_accuracy: 0.8778 - val_sparse_categorical_crossentropy: 0.3785 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.3702 - sparse_categorical_accuracy: 0.8834 - sparse_categorical_crossentropy: 0.3702 - val_loss: 0.3476 - val_sparse_categorical_accuracy: 0.8925 - val_sparse_categorical_crossentropy: 0.3476 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 16s 164ms/step - loss: 0.3276 - sparse_categorical_accuracy: 0.8963 - sparse_categorical_crossentropy: 0.3276 - val_loss: 0.3094 - val_sparse_categorical_accuracy: 0.8996 - val_sparse_categorical_crossentropy: 0.3094 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 16s 167ms/step - loss: 0.2855 - sparse_categorical_accuracy: 0.9104 - sparse_categorical_crossentropy: 0.2855 - val_loss: 0.2874 - val_sparse_categorical_accuracy: 0.9122 - val_sparse_categorical_crossentropy: 0.2874 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 16s 168ms/step - loss: 0.2551 - sparse_categorical_accuracy: 0.9204 - sparse_categorical_crossentropy: 0.2551 - val_loss: 0.2827 - val_sparse_categorical_accuracy: 0.9102 - val_sparse_categorical_crossentropy: 0.2827 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 17s 173ms/step - loss: 0.2700 - sparse_categorical_accuracy: 0.9143 - sparse_categorical_crossentropy: 0.2700 - val_loss: 0.2921 - val_sparse_categorical_accuracy: 0.9105 - val_sparse_categorical_crossentropy: 0.2921 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2606 - sparse_categorical_accuracy: 0.9181 - sparse_categorical_crossentropy: 0.2606\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 0.2606 - sparse_categorical_accuracy: 0.9181 - sparse_categorical_crossentropy: 0.2606 - val_loss: 0.2953 - val_sparse_categorical_accuracy: 0.9079 - val_sparse_categorical_crossentropy: 0.2953 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.2361 - sparse_categorical_accuracy: 0.9249 - sparse_categorical_crossentropy: 0.2361 - val_loss: 0.2604 - val_sparse_categorical_accuracy: 0.9189 - val_sparse_categorical_crossentropy: 0.2604 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.2135 - sparse_categorical_accuracy: 0.9327 - sparse_categorical_crossentropy: 0.2135 - val_loss: 0.2456 - val_sparse_categorical_accuracy: 0.9223 - val_sparse_categorical_crossentropy: 0.2456 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 17s 171ms/step - loss: 0.1769 - sparse_categorical_accuracy: 0.9449 - sparse_categorical_crossentropy: 0.1769 - val_loss: 0.2330 - val_sparse_categorical_accuracy: 0.9301 - val_sparse_categorical_crossentropy: 0.2330 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 0.2007 - sparse_categorical_accuracy: 0.9362 - sparse_categorical_crossentropy: 0.2007 - val_loss: 0.2500 - val_sparse_categorical_accuracy: 0.9242 - val_sparse_categorical_crossentropy: 0.2500 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 17s 171ms/step - loss: 0.1877 - sparse_categorical_accuracy: 0.9420 - sparse_categorical_crossentropy: 0.1877 - val_loss: 0.2366 - val_sparse_categorical_accuracy: 0.9295 - val_sparse_categorical_crossentropy: 0.2366 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1747 - sparse_categorical_accuracy: 0.9449 - sparse_categorical_crossentropy: 0.1747\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 0.1746 - sparse_categorical_accuracy: 0.9449 - sparse_categorical_crossentropy: 0.1746 - val_loss: 0.2387 - val_sparse_categorical_accuracy: 0.9231 - val_sparse_categorical_crossentropy: 0.2387 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.1362 - sparse_categorical_accuracy: 0.9575 - sparse_categorical_crossentropy: 0.1362 - val_loss: 0.2117 - val_sparse_categorical_accuracy: 0.9361 - val_sparse_categorical_crossentropy: 0.2117 - lr: 0.0025\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 17s 171ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9667 - sparse_categorical_crossentropy: 0.1137 - val_loss: 0.2096 - val_sparse_categorical_accuracy: 0.9361 - val_sparse_categorical_crossentropy: 0.2096 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.1117 - sparse_categorical_accuracy: 0.9667 - sparse_categorical_crossentropy: 0.1117 - val_loss: 0.2086 - val_sparse_categorical_accuracy: 0.9374 - val_sparse_categorical_crossentropy: 0.2086 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9704 - sparse_categorical_crossentropy: 0.1008 - val_loss: 0.2070 - val_sparse_categorical_accuracy: 0.9380 - val_sparse_categorical_crossentropy: 0.2070 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9746 - sparse_categorical_crossentropy: 0.0888 - val_loss: 0.2096 - val_sparse_categorical_accuracy: 0.9389 - val_sparse_categorical_crossentropy: 0.2096 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 17s 173ms/step - loss: 0.0887 - sparse_categorical_accuracy: 0.9746 - sparse_categorical_crossentropy: 0.0887 - val_loss: 0.2081 - val_sparse_categorical_accuracy: 0.9390 - val_sparse_categorical_crossentropy: 0.2081 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 17s 171ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9786 - sparse_categorical_crossentropy: 0.0757 - val_loss: 0.2064 - val_sparse_categorical_accuracy: 0.9389 - val_sparse_categorical_crossentropy: 0.2064 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 16s 169ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9816 - sparse_categorical_crossentropy: 0.0676 - val_loss: 0.2017 - val_sparse_categorical_accuracy: 0.9406 - val_sparse_categorical_crossentropy: 0.2017 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9839 - sparse_categorical_crossentropy: 0.0615 - val_loss: 0.2074 - val_sparse_categorical_accuracy: 0.9417 - val_sparse_categorical_crossentropy: 0.2074 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9854 - sparse_categorical_crossentropy: 0.0562 - val_loss: 0.2118 - val_sparse_categorical_accuracy: 0.9418 - val_sparse_categorical_crossentropy: 0.2118 - lr: 0.0025\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 17s 171ms/step - loss: 0.0563 - sparse_categorical_accuracy: 0.9845 - sparse_categorical_crossentropy: 0.0563 - val_loss: 0.2137 - val_sparse_categorical_accuracy: 0.9404 - val_sparse_categorical_crossentropy: 0.2137 - lr: 0.0025\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 0.0480 - sparse_categorical_accuracy: 0.9878 - sparse_categorical_crossentropy: 0.0480 - val_loss: 0.2173 - val_sparse_categorical_accuracy: 0.9410 - val_sparse_categorical_crossentropy: 0.2173 - lr: 0.0025\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 17s 175ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9895 - sparse_categorical_crossentropy: 0.0431 - val_loss: 0.2178 - val_sparse_categorical_accuracy: 0.9429 - val_sparse_categorical_crossentropy: 0.2178 - lr: 0.0025\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 17s 179ms/step - loss: 0.0408 - sparse_categorical_accuracy: 0.9900 - sparse_categorical_crossentropy: 0.0408 - val_loss: 0.2266 - val_sparse_categorical_accuracy: 0.9398 - val_sparse_categorical_crossentropy: 0.2266 - lr: 0.0025\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 17s 174ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9834 - sparse_categorical_crossentropy: 0.0555 - val_loss: 0.2308 - val_sparse_categorical_accuracy: 0.9380 - val_sparse_categorical_crossentropy: 0.2308 - lr: 0.0025\n",
      "Epoch 40/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0587 - sparse_categorical_accuracy: 0.9828 - sparse_categorical_crossentropy: 0.0587\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 17s 173ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9828 - sparse_categorical_crossentropy: 0.0587 - val_loss: 0.2306 - val_sparse_categorical_accuracy: 0.9384 - val_sparse_categorical_crossentropy: 0.2306 - lr: 0.0025\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 17s 172ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9913 - sparse_categorical_crossentropy: 0.0365 - val_loss: 0.2295 - val_sparse_categorical_accuracy: 0.9400 - val_sparse_categorical_crossentropy: 0.2295 - lr: 0.0012\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 17s 176ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9921 - sparse_categorical_crossentropy: 0.0334 - val_loss: 0.2349 - val_sparse_categorical_accuracy: 0.9375 - val_sparse_categorical_crossentropy: 0.2349 - lr: 0.0012\n",
      "26/26 [==============================] - 4s 120ms/step - loss: 0.2286 - sparse_categorical_accuracy: 0.9378 - sparse_categorical_crossentropy: 0.2286\n",
      "26/26 [==============================] - 6s 113ms/step\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 23s 189ms/step - loss: 1.5035 - sparse_categorical_accuracy: 0.6230 - sparse_categorical_crossentropy: 1.5035 - val_loss: 1.3202 - val_sparse_categorical_accuracy: 0.6369 - val_sparse_categorical_crossentropy: 1.3202 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 18s 181ms/step - loss: 1.1614 - sparse_categorical_accuracy: 0.6625 - sparse_categorical_crossentropy: 1.1614 - val_loss: 0.9529 - val_sparse_categorical_accuracy: 0.7066 - val_sparse_categorical_crossentropy: 0.9529 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 18s 189ms/step - loss: 0.8749 - sparse_categorical_accuracy: 0.7267 - sparse_categorical_crossentropy: 0.8749 - val_loss: 0.8480 - val_sparse_categorical_accuracy: 0.7264 - val_sparse_categorical_crossentropy: 0.8480 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 18s 187ms/step - loss: 0.6980 - sparse_categorical_accuracy: 0.7802 - sparse_categorical_crossentropy: 0.6980 - val_loss: 0.6215 - val_sparse_categorical_accuracy: 0.7975 - val_sparse_categorical_crossentropy: 0.6215 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 18s 190ms/step - loss: 0.5605 - sparse_categorical_accuracy: 0.8247 - sparse_categorical_crossentropy: 0.5605 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.8201 - val_sparse_categorical_crossentropy: 0.5746 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 18s 186ms/step - loss: 0.5228 - sparse_categorical_accuracy: 0.8354 - sparse_categorical_crossentropy: 0.5228 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8469 - val_sparse_categorical_crossentropy: 0.4852 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 18s 192ms/step - loss: 0.4447 - sparse_categorical_accuracy: 0.8613 - sparse_categorical_crossentropy: 0.4447 - val_loss: 0.4541 - val_sparse_categorical_accuracy: 0.8543 - val_sparse_categorical_crossentropy: 0.4541 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 19s 195ms/step - loss: 0.4027 - sparse_categorical_accuracy: 0.8734 - sparse_categorical_crossentropy: 0.4027 - val_loss: 0.4027 - val_sparse_categorical_accuracy: 0.8718 - val_sparse_categorical_crossentropy: 0.4027 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 18s 190ms/step - loss: 0.4039 - sparse_categorical_accuracy: 0.8726 - sparse_categorical_crossentropy: 0.4039 - val_loss: 0.3942 - val_sparse_categorical_accuracy: 0.8776 - val_sparse_categorical_crossentropy: 0.3942 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 18s 188ms/step - loss: 0.3780 - sparse_categorical_accuracy: 0.8807 - sparse_categorical_crossentropy: 0.3780 - val_loss: 0.4329 - val_sparse_categorical_accuracy: 0.8610 - val_sparse_categorical_crossentropy: 0.4329 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 18s 191ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8628 - sparse_categorical_crossentropy: 0.4307 - val_loss: 0.3839 - val_sparse_categorical_accuracy: 0.8764 - val_sparse_categorical_crossentropy: 0.3839 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 18s 191ms/step - loss: 0.3431 - sparse_categorical_accuracy: 0.8914 - sparse_categorical_crossentropy: 0.3431 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.8930 - val_sparse_categorical_crossentropy: 0.3343 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 18s 188ms/step - loss: 0.3161 - sparse_categorical_accuracy: 0.9012 - sparse_categorical_crossentropy: 0.3161 - val_loss: 0.3437 - val_sparse_categorical_accuracy: 0.8871 - val_sparse_categorical_crossentropy: 0.3437 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 19s 197ms/step - loss: 0.3247 - sparse_categorical_accuracy: 0.8978 - sparse_categorical_crossentropy: 0.3247 - val_loss: 0.4400 - val_sparse_categorical_accuracy: 0.8583 - val_sparse_categorical_crossentropy: 0.4400 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.4024 - sparse_categorical_accuracy: 0.8718 - sparse_categorical_crossentropy: 0.4024\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "90/90 [==============================] - 19s 197ms/step - loss: 0.4024 - sparse_categorical_accuracy: 0.8718 - sparse_categorical_crossentropy: 0.4024 - val_loss: 0.4062 - val_sparse_categorical_accuracy: 0.8715 - val_sparse_categorical_crossentropy: 0.4062 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 19s 191ms/step - loss: 0.3328 - sparse_categorical_accuracy: 0.8966 - sparse_categorical_crossentropy: 0.3328 - val_loss: 0.3441 - val_sparse_categorical_accuracy: 0.8919 - val_sparse_categorical_crossentropy: 0.3441 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 18s 182ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.9071 - sparse_categorical_crossentropy: 0.2935 - val_loss: 0.2978 - val_sparse_categorical_accuracy: 0.9080 - val_sparse_categorical_crossentropy: 0.2978 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 18s 186ms/step - loss: 0.2828 - sparse_categorical_accuracy: 0.9086 - sparse_categorical_crossentropy: 0.2828 - val_loss: 0.3119 - val_sparse_categorical_accuracy: 0.8987 - val_sparse_categorical_crossentropy: 0.3119 - lr: 0.0050\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 18s 188ms/step - loss: 0.2448 - sparse_categorical_accuracy: 0.9239 - sparse_categorical_crossentropy: 0.2448 - val_loss: 0.2653 - val_sparse_categorical_accuracy: 0.9154 - val_sparse_categorical_crossentropy: 0.2653 - lr: 0.0050\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 18s 191ms/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9313 - sparse_categorical_crossentropy: 0.2232 - val_loss: 0.2613 - val_sparse_categorical_accuracy: 0.9175 - val_sparse_categorical_crossentropy: 0.2613 - lr: 0.0050\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 18s 186ms/step - loss: 0.2037 - sparse_categorical_accuracy: 0.9365 - sparse_categorical_crossentropy: 0.2037 - val_loss: 0.2707 - val_sparse_categorical_accuracy: 0.9151 - val_sparse_categorical_crossentropy: 0.2707 - lr: 0.0050\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 18s 185ms/step - loss: 0.1903 - sparse_categorical_accuracy: 0.9398 - sparse_categorical_crossentropy: 0.1903 - val_loss: 0.2503 - val_sparse_categorical_accuracy: 0.9220 - val_sparse_categorical_crossentropy: 0.2503 - lr: 0.0050\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 18s 192ms/step - loss: 0.1731 - sparse_categorical_accuracy: 0.9461 - sparse_categorical_crossentropy: 0.1731 - val_loss: 0.2721 - val_sparse_categorical_accuracy: 0.9171 - val_sparse_categorical_crossentropy: 0.2721 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 18s 188ms/step - loss: 0.2387 - sparse_categorical_accuracy: 0.9240 - sparse_categorical_crossentropy: 0.2387 - val_loss: 0.2483 - val_sparse_categorical_accuracy: 0.9214 - val_sparse_categorical_crossentropy: 0.2483 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.2645 - sparse_categorical_accuracy: 0.9142 - sparse_categorical_crossentropy: 0.2645\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "90/90 [==============================] - 18s 187ms/step - loss: 0.2645 - sparse_categorical_accuracy: 0.9142 - sparse_categorical_crossentropy: 0.2645 - val_loss: 0.2756 - val_sparse_categorical_accuracy: 0.9136 - val_sparse_categorical_crossentropy: 0.2756 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 19s 195ms/step - loss: 0.1918 - sparse_categorical_accuracy: 0.9389 - sparse_categorical_crossentropy: 0.1918 - val_loss: 0.2481 - val_sparse_categorical_accuracy: 0.9237 - val_sparse_categorical_crossentropy: 0.2481 - lr: 0.0025\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 18s 191ms/step - loss: 0.1605 - sparse_categorical_accuracy: 0.9500 - sparse_categorical_crossentropy: 0.1605 - val_loss: 0.2426 - val_sparse_categorical_accuracy: 0.9261 - val_sparse_categorical_crossentropy: 0.2426 - lr: 0.0025\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 18s 191ms/step - loss: 0.1491 - sparse_categorical_accuracy: 0.9536 - sparse_categorical_crossentropy: 0.1491 - val_loss: 0.2471 - val_sparse_categorical_accuracy: 0.9228 - val_sparse_categorical_crossentropy: 0.2471 - lr: 0.0025\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 18s 190ms/step - loss: 0.1553 - sparse_categorical_accuracy: 0.9512 - sparse_categorical_crossentropy: 0.1553 - val_loss: 0.2336 - val_sparse_categorical_accuracy: 0.9275 - val_sparse_categorical_crossentropy: 0.2336 - lr: 0.0025\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 18s 190ms/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9623 - sparse_categorical_crossentropy: 0.1252 - val_loss: 0.2274 - val_sparse_categorical_accuracy: 0.9297 - val_sparse_categorical_crossentropy: 0.2274 - lr: 0.0025\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 19s 193ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9641 - sparse_categorical_crossentropy: 0.1173 - val_loss: 0.2230 - val_sparse_categorical_accuracy: 0.9297 - val_sparse_categorical_crossentropy: 0.2230 - lr: 0.0025\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 19s 193ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9700 - sparse_categorical_crossentropy: 0.1041 - val_loss: 0.2382 - val_sparse_categorical_accuracy: 0.9272 - val_sparse_categorical_crossentropy: 0.2382 - lr: 0.0025\n",
      "Epoch 33/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.1019 - sparse_categorical_accuracy: 0.9695 - sparse_categorical_crossentropy: 0.1019\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "90/90 [==============================] - 19s 192ms/step - loss: 0.1019 - sparse_categorical_accuracy: 0.9696 - sparse_categorical_crossentropy: 0.1019 - val_loss: 0.2274 - val_sparse_categorical_accuracy: 0.9294 - val_sparse_categorical_crossentropy: 0.2274 - lr: 0.0025\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 19s 193ms/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9767 - sparse_categorical_crossentropy: 0.0842 - val_loss: 0.2188 - val_sparse_categorical_accuracy: 0.9363 - val_sparse_categorical_crossentropy: 0.2188 - lr: 0.0012\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 19s 193ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9798 - sparse_categorical_crossentropy: 0.0754 - val_loss: 0.2203 - val_sparse_categorical_accuracy: 0.9351 - val_sparse_categorical_crossentropy: 0.2203 - lr: 0.0012\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 18s 190ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9801 - sparse_categorical_crossentropy: 0.0734 - val_loss: 0.2168 - val_sparse_categorical_accuracy: 0.9381 - val_sparse_categorical_crossentropy: 0.2168 - lr: 0.0012\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 18s 189ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9819 - sparse_categorical_crossentropy: 0.0695 - val_loss: 0.2287 - val_sparse_categorical_accuracy: 0.9335 - val_sparse_categorical_crossentropy: 0.2287 - lr: 0.0012\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 18s 190ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9801 - sparse_categorical_crossentropy: 0.0733 - val_loss: 0.2222 - val_sparse_categorical_accuracy: 0.9347 - val_sparse_categorical_crossentropy: 0.2222 - lr: 0.0012\n",
      "Epoch 39/200\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0608 - sparse_categorical_accuracy: 0.9846 - sparse_categorical_crossentropy: 0.0608\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "90/90 [==============================] - 18s 192ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9846 - sparse_categorical_crossentropy: 0.0608 - val_loss: 0.2216 - val_sparse_categorical_accuracy: 0.9338 - val_sparse_categorical_crossentropy: 0.2216 - lr: 0.0012\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 19s 192ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9875 - sparse_categorical_crossentropy: 0.0533 - val_loss: 0.2206 - val_sparse_categorical_accuracy: 0.9352 - val_sparse_categorical_crossentropy: 0.2206 - lr: 6.2500e-04\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 18s 191ms/step - loss: 0.0501 - sparse_categorical_accuracy: 0.9885 - sparse_categorical_crossentropy: 0.0501 - val_loss: 0.2225 - val_sparse_categorical_accuracy: 0.9357 - val_sparse_categorical_crossentropy: 0.2225 - lr: 6.2500e-04\n",
      "26/26 [==============================] - 5s 129ms/step - loss: 0.2355 - sparse_categorical_accuracy: 0.9311 - sparse_categorical_crossentropy: 0.2355\n",
      "26/26 [==============================] - 6s 129ms/step\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SEEDS = list(range(5))\n",
    "for i in range(2, 3):\n",
    "    results = []\n",
    "    EXPERIMENT_NAME = f\"stacked_{i}_lstm\"\n",
    "    if os.path.exists(EXPERIMENT_NAME):\n",
    "        shutil.rmtree(EXPERIMENT_NAME)\n",
    "        os.mkdir(EXPERIMENT_NAME)\n",
    "    else:\n",
    "        os.mkdir(EXPERIMENT_NAME)\n",
    "\n",
    "    for seed in TRAINING_SEEDS:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        model = create_bidirectional_model(i)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "            loss=losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseCategoricalCrossentropy()]\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=MAX_EPOCHS,\n",
    "            validation_data=val_ds,\n",
    "            shuffle=True,\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "\n",
    "        with open(os.path.join(EXPERIMENT_NAME, f\"history_{seed}.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(history.history, file)\n",
    "\n",
    "        eval_results = model.evaluate(test_ds)\n",
    "\n",
    "        predictions = model.predict(test_ds)\n",
    "        with open(os.path.join(EXPERIMENT_NAME, f\"predictions_{seed}.pkl\"), \"wb\") as file:\n",
    "            pickle.dump(predictions, file)\n",
    "\n",
    "        results += [{\n",
    "            'seed': seed,\n",
    "            'results': dict(zip(model.metrics_names, eval_results))\n",
    "        }]\n",
    "        gc.collect()\n",
    "\n",
    "    results_temp = pd.DataFrame(results)\n",
    "    results_df = pd.concat([results_temp.drop([\"results\"], axis=1), results_temp[\"results\"].apply(pd.Series)], axis=1)\n",
    "    results_df.to_csv(os.path.join(EXPERIMENT_NAME, 'results.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:37:49.039594Z",
     "end_time": "2023-04-23T14:34:44.506769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "   seed      loss  sparse_categorical_accuracy  \\\n0     0  0.230268                     0.936655   \n1     1  0.252013                     0.939266   \n2     2  0.206601                     0.942568   \n3     3  0.228562                     0.937807   \n4     4  0.235467                     0.931050   \n\n   sparse_categorical_crossentropy  \n0                         0.230268  \n1                         0.252013  \n2                         0.206601  \n3                         0.228562  \n4                         0.235467  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed</th>\n      <th>loss</th>\n      <th>sparse_categorical_accuracy</th>\n      <th>sparse_categorical_crossentropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.230268</td>\n      <td>0.936655</td>\n      <td>0.230268</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.252013</td>\n      <td>0.939266</td>\n      <td>0.252013</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.206601</td>\n      <td>0.942568</td>\n      <td>0.206601</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.228562</td>\n      <td>0.937807</td>\n      <td>0.228562</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.235467</td>\n      <td>0.931050</td>\n      <td>0.235467</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T14:34:44.498769Z",
     "end_time": "2023-04-23T14:34:44.510767Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
